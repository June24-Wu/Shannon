{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4517731a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T10:56:03.355968Z",
     "start_time": "2022-01-30T10:56:00.909956Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da363f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T10:56:03.372829Z",
     "start_time": "2022-01-30T10:56:03.359284Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer_LSTM(nn.Module):\n",
    "    def __init__(self, dimention, factor_num, sequence, fully_connect_layer_neural, layer_num=2,transformer = False):\n",
    "        super(Transformer_LSTM, self).__init__()\n",
    "        self.factor_num = factor_num  # 108\n",
    "        self.sequence = sequence  #\n",
    "        self.dimention = dimention  #\n",
    "        self.fc2_neuron = fully_connect_layer_neural  # 32\n",
    "        self.transformer = transformer\n",
    "\n",
    "        # Layer\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.dimention * self.factor_num * self.sequence)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(self.fc2_neuron * 2 * self.sequence)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(self.fc2_neuron * 2)\n",
    "        if self.transformer == True:\n",
    "            self.q_metrix = nn.Linear(self.factor_num, self.factor_num)\n",
    "            self.k_metrix = nn.Linear(self.factor_num, self.factor_num)\n",
    "            self.v_metrix = nn.Linear(self.factor_num, self.factor_num)\n",
    "            self.MultiheadAttention = nn.MultiheadAttention(self.factor_num, layer_num, batch_first=True)\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.factor_num, self.fc2_neuron, layer_num, batch_first=True, bidirectional=True,\n",
    "                            dropout=0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.LeakyReLU = nn.LeakyReLU()\n",
    "        self.out = nn.Linear(self.fc2_neuron * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm_1(x)\n",
    "        x = torch.transpose(x, 0, 1)  # x.shape: torch.Size([3, 512, 20, 108])\n",
    "\n",
    "        final, (hn, cn) = self.transformer_lstm(x[0], 2)  # torch.Size([512, 20, 128])\n",
    "        for i in range(1, x.shape[0]):\n",
    "            add, _ = self.transformer_lstm(x[i], 2)\n",
    "            final = self.skip_connection(final, add)\n",
    "        # start = torch.Size([512, 20, 128])\n",
    "\n",
    "        x, _ = self.attention_net(final, hn)\n",
    "        x = self.bn3(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred\n",
    "\n",
    "    def norm_1(self, x):\n",
    "        batch_num, original_shape = x.shape[0], x.shape\n",
    "        x = x.reshape(batch_num, -1)\n",
    "        x = self.bn1(x)\n",
    "        x = x.reshape(original_shape)\n",
    "        return x\n",
    "\n",
    "    def norm_2(self, x):\n",
    "        batch_num, original_shape = x.shape[0], x.shape\n",
    "        x = x.reshape(batch_num, -1)\n",
    "        x = self.bn2(x)\n",
    "        x = x.reshape(original_shape)\n",
    "        return x\n",
    "\n",
    "    def transformer_lstm(self, x, layer_num):\n",
    "        if self.transformer == True:\n",
    "            q = self.q_metrix(x)\n",
    "            k = self.k_metrix(x)\n",
    "            v = self.v_metrix(x)\n",
    "            x, x_weight = self.MultiheadAttention(q, k, v)  # attn_output = torch.Size([512, 20, 128])\n",
    "        else:\n",
    "            continue\n",
    "        # out = torch.Size([512, 20, 128])\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        return out, (hn, cn)\n",
    "\n",
    "    def skip_connection(self, origin, add):\n",
    "        return self.norm_2(origin + add)\n",
    "\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        # lstm_output : [batch_size, n_step, n_hidden * num_directions(=2)], F matrix\n",
    "        # final_state : [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "\n",
    "        hidden = torch.cat((final_state[0], final_state[1]), dim=1).unsqueeze(\n",
    "            2)  # hidden : [batch_size, n_hidden * num_directions(=2), n_layer(=1)]\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)  # [batch_size,sequence]\n",
    "        attn_weights = torch.nn.functional.softmax(attn_weights, 1)  # [batch_size,sequence]   # torch.Size([512, 20])\n",
    "        # context: [batch_size, n_hidden * num_directions(=2)]\n",
    "        output = torch.bmm(lstm_output.transpose(1, 2), attn_weights.unsqueeze(2)).squeeze(\n",
    "            2)  # [batch_size, n_hidden * num_directions(=2)]\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ddddf5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T10:59:07.534083Z",
     "start_time": "2022-01-30T10:59:07.500684Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlphaNet_LSTM_V1(nn.Module):\n",
    "    def __init__(self, factor_num, sequence, fully_connect_layer_neural, attention=False,transformer = False):\n",
    "        super(AlphaNet_LSTM_V1, self).__init__()\n",
    "        self.factor_num = factor_num  # 108\n",
    "        self.sequence = sequence\n",
    "        self.fc2_neuron = fully_connect_layer_neural  # 32\n",
    "        self.attention = attention\n",
    "        self.transformer = transformer\n",
    "        # Layer\n",
    "        self.batch = torch.nn.BatchNorm1d(self.sequence * self.factor_num)\n",
    "        self.lstm = nn.LSTM(self.factor_num, self.fc2_neuron, 3, batch_first=True, bidirectional=True, dropout=0.2)\n",
    "        self.lstm2 = nn.LSTM(int(self.fc2_neuron * 2), int(self.fc2_neuron / 2), 3, batch_first=True,\n",
    "                             bidirectional=True, dropout=0.2)\n",
    "        self.batch2 = torch.nn.BatchNorm1d(int(self.fc2_neuron * 2))\n",
    "        self.batch3 = torch.nn.BatchNorm1d(self.fc2_neuron)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.LeakyReLU = nn.LeakyReLU()\n",
    "        self.out = nn.Linear(self.fc2_neuron, 1)\n",
    "        if self.transformer == True:\n",
    "            self.q_metrix = nn.Linear(self.fc2_neuron * 2, self.fc2_neuron * 2)\n",
    "            self.k_metrix = nn.Linear(self.fc2_neuron * 2, self.fc2_neuron * 2)\n",
    "            self.v_metrix = nn.Linear(self.fc2_neuron * 2, self.fc2_neuron * 2)\n",
    "            self.MultiheadAttention = nn.MultiheadAttention(self.fc2_neuron * 2, 2, batch_first=True)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1).float()\n",
    "        x = self.batch(x)\n",
    "        x = x.reshape(x.shape[0], self.sequence, self.factor_num)\n",
    "        \n",
    "        \n",
    "        x, _ = self.lstm(x)  # x.shape: torch.Size([6182, 10, 128])\n",
    "        if self.transformer == True:\n",
    "            q = self.q_metrix(x)\n",
    "            k = self.k_metrix(x)\n",
    "            v = self.v_metrix(x)\n",
    "            x, _ = self.MultiheadAttention(q, k, v)  # attn_output = torch.Size([512, 20, 128])\n",
    "        else:\n",
    "            x = self.LeakyReLU(x)\n",
    "        \n",
    "        x = torch.transpose(x, 1, 2)  # x.shape: torch.Size([6182, 128, 10])\n",
    "        x = self.batch2(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "\n",
    "        x, (hn, cn) = self.lstm2(x)  # torch.Size([6182, 10, 64])\n",
    "        if self.attention == True:\n",
    "            x, _ = self.attention_net(x, hn)\n",
    "        else:\n",
    "            x = x[:, -1]  # torch.Size([6182, 64])\n",
    "        x = self.batch3(x)  # torch.Size([6182, 64])\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred\n",
    "\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        # lstm_output : [batch_size, n_step, n_hidden * num_directions(=2)], F matrix\n",
    "        # final_state : [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "\n",
    "        hidden = torch.cat((final_state[0], final_state[1]), dim=1).unsqueeze(\n",
    "            2)  # hidden : [batch_size, n_hidden * num_directions(=2), n_layer(=1)]\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)  # [batch_size,sequence]\n",
    "        attn_weights = torch.nn.functional.softmax(attn_weights, 1)  # [batch_size,sequence]   # torch.Size([512, 20])\n",
    "        # context: [batch_size, n_hidden * num_directions(=2)]\n",
    "        output = torch.bmm(lstm_output.transpose(1, 2), attn_weights.unsqueeze(2)).squeeze(\n",
    "            2)  # [batch_size, n_hidden * num_directions(=2)]\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a73d237",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T10:56:04.918165Z",
     "start_time": "2022-01-30T10:56:03.391878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainx.shape:  torch.Size([10000, 20, 108])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from progressbar import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "# trainx = torch.randn(10000,3,20,108)\n",
    "trainx = torch.randn(10000,20,108)\n",
    "trainy = torch.randn(10000,1)\n",
    "print(\"trainx.shape: \" , trainx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89897b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T10:56:05.096339Z",
     "start_time": "2022-01-30T10:56:04.925178Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(trainx, trainy)\n",
    "batch_size = 1024\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d31b69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T10:57:41.545051Z",
     "start_time": "2022-01-30T10:56:05.102378Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet_LSTM_V1(\n",
      "  (batch): BatchNorm1d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lstm): LSTM(108, 64, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (lstm2): LSTM(128, 32, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (batch2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batch3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (LeakyReLU): LeakyReLU(negative_slope=0.01)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [00:04<04:03,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  loss:  1.1018763671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:08<03:23,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  loss:  1.0418413024902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [00:12<03:08,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  loss:  1.033728106689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [00:15<02:55,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  loss:  1.016056024169922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [00:22<03:33,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5  loss:  0.9731095764160156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:26<03:17,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6  loss:  0.8978715881347656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [00:31<03:16,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7  loss:  0.7369903503417968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:34<03:01,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8  loss:  0.57525751953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:39<02:56,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9  loss:  0.41289476013183596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [00:45<03:13,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10  loss:  0.28321459655761716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:50<03:16,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11  loss:  0.1937798370361328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:54<03:01,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12  loss:  0.14945919189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [00:58<02:43,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13  loss:  0.11800237731933594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [01:03<02:48,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14  loss:  0.1004978385925293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [01:07<02:38,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15  loss:  0.08560333938598633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [01:11<02:28,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16  loss:  0.07583615112304687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [01:15<02:17,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17  loss:  0.06886293754577637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [01:18<02:01,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18  loss:  0.061893176651000976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [01:21<01:49,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19  loss:  0.06322058448791504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [01:23<01:29,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20  loss:  0.05671741981506347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:24<02:06,  4.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-569f63167d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-jupyter/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-jupyter/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-jupyter/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-jupyter/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alphanet = AlphaNet_LSTM_V1(108,20,64,attention=True)\n",
    "alphanet = alphanet.cuda()\n",
    "# alphanet = torch.nn.parallel.DataParallel(alphanet)\n",
    "print(alphanet)\n",
    "total_length = trainx.shape[0]\n",
    "LR = 0.01\n",
    "loss_function = nn.MSELoss().cuda()\n",
    "optimizer = optim.Adam(alphanet.parameters(), lr=LR)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma = 0.5)\n",
    "epoch_num = 50\n",
    "loss_list = []\n",
    "\n",
    "min_loss = float(\"inf\")\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    total_loss = 0\n",
    "    for _, (inputs, outputs) in enumerate(train_loader):\n",
    "        inputs = Variable(inputs).float().cuda()\n",
    "        outputs = Variable(outputs).float().cuda()\n",
    "        optimizer.zero_grad() # noticed:  the grad return to zero before starting the loop\n",
    "        \n",
    "        # forward + backward +update\n",
    "        pred = alphanet(inputs.cuda())\n",
    "        pred = pred.cuda()\n",
    "        loss = loss_function(pred, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        total_loss += loss.item()\n",
    "    total_loss = total_loss * batch_size / total_length\n",
    "    print('Epoch: ', epoch + 1, ' loss: ', total_loss)\n",
    "    loss_list.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32508a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T10:59:50.810172Z",
     "start_time": "2022-01-30T10:59:11.998747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet_LSTM_V1(\n",
      "  (batch): BatchNorm1d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lstm): LSTM(108, 64, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (lstm2): LSTM(128, 32, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (batch2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batch3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (LeakyReLU): LeakyReLU(negative_slope=0.01)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (q_metrix): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (k_metrix): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (v_metrix): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (MultiheadAttention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:02<00:41,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  loss:  1.1139741821289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:04<00:37,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  loss:  1.0530594177246093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:06<00:33,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  loss:  1.0436497802734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:07<00:30,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  loss:  1.0428310607910156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:09<00:28,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5  loss:  1.0397243041992188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:11<00:26,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6  loss:  1.0409728332519532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:13<00:24,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7  loss:  1.0375355712890626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:15<00:22,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8  loss:  1.0361664855957031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:17<00:20,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9  loss:  1.039566162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [00:19<00:18,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10  loss:  1.0366649475097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [00:21<00:17,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11  loss:  1.0397498291015626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [00:23<00:15,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12  loss:  1.0372514404296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [00:25<00:14,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13  loss:  1.0388130310058594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [00:27<00:11,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14  loss:  1.0365106384277343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [00:29<00:09,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15  loss:  1.0349675048828124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [00:30<00:07,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16  loss:  1.0379776245117187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [00:32<00:05,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17  loss:  1.0362622131347656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [00:34<00:03,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18  loss:  1.0362174621582032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [00:36<00:01,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19  loss:  1.0369715270996094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:38<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20  loss:  1.0387520568847657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphanet = AlphaNet_LSTM_V1(108,20,64,attention=True,transformer = True)\n",
    "alphanet = alphanet.cuda()\n",
    "# alphanet = torch.nn.parallel.DataParallel(alphanet)\n",
    "print(alphanet)\n",
    "total_length = trainx.shape[0]\n",
    "LR = 0.01\n",
    "loss_function = nn.MSELoss().cuda()\n",
    "optimizer = optim.Adam(alphanet.parameters(), lr=LR)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma = 0.5)\n",
    "epoch_num = 20\n",
    "loss_list = []\n",
    "\n",
    "min_loss = float(\"inf\")\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    total_loss = 0\n",
    "    for _, (inputs, outputs) in enumerate(train_loader):\n",
    "        inputs = Variable(inputs).float().cuda()\n",
    "        outputs = Variable(outputs).float().cuda()\n",
    "        optimizer.zero_grad() # noticed:  the grad return to zero before starting the loop\n",
    "        \n",
    "        # forward + backward +update\n",
    "        pred = alphanet(inputs.cuda())\n",
    "        pred = pred.cuda()\n",
    "        loss = loss_function(pred, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        total_loss += loss.item()\n",
    "    total_loss = total_loss * batch_size / total_length\n",
    "    print('Epoch: ', epoch + 1, ' loss: ', total_loss)\n",
    "    loss_list.append(total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
