{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e6c7e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T08:26:01.239034Z",
     "start_time": "2021-12-15T08:26:01.230133Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from progressbar import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from os import walk\n",
    "day = 30\n",
    "stride = 10\n",
    "feat_num = 9\n",
    "conv_num = int(feat_num * (feat_num - 1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc625edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T08:26:01.630039Z",
     "start_time": "2021-12-15T08:26:01.613833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 179067.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2015-01-01_2015-03-01.par',\n",
       " '2015-03-01_2015-06-01.par',\n",
       " '2015-06-01_2015-09-01.par',\n",
       " '2015-09-01_2016-01-01.par',\n",
       " '2016-01-01_2016-03-01.par',\n",
       " '2016-03-01_2016-06-01.par',\n",
       " '2016-06-01_2016-09-01.par',\n",
       " '2016-09-01_2017-01-01.par',\n",
       " '2017-01-01_2017-03-01.par',\n",
       " '2017-03-01_2017-06-01.par',\n",
       " '2017-06-01_2017-09-01.par',\n",
       " '2017-09-01_2018-01-01.par',\n",
       " '2018-01-01_2018-03-01.par',\n",
       " '2018-03-01_2018-06-01.par',\n",
       " '2018-06-01_2018-09-01.par',\n",
       " '2018-09-01_2019-01-01.par',\n",
       " '2019-01-01_2019-03-01.par',\n",
       " '2019-03-01_2019-06-01.par',\n",
       " '2019-06-01_2019-09-01.par',\n",
       " '2019-09-01_2020-01-01.par',\n",
       " '2020-01-01_2020-03-01.par',\n",
       " '2020-03-01_2020-06-01.par',\n",
       " '2020-06-01_2020-09-01.par',\n",
       " '2020-09-01_2021-01-01.par',\n",
       " '2021-01-01_2021-03-01.par',\n",
       " '2021-03-01_2021-06-01.par']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_list = []\n",
    "path = \"/home/wuwenjun/Data/AlphaNet_Original_Input_12.14/\"\n",
    "data_path = path + \"Data/\"\n",
    "dataframe_list = pd.DataFrame()\n",
    "for f, _, i in walk(data_path):\n",
    "    for j in tqdm(i):\n",
    "        time_list.append(j)\n",
    "time_list.sort()     \n",
    "time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b3d63f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T08:09:41.976920Z",
     "start_time": "2021-12-15T08:09:35.807191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01_2020-09-01.par\n",
      "Cov\n",
      "Corr\n",
      "Std\n",
      "Zscore\n",
      "Return\n",
      "Decay\n",
      "2020-09-01_2021-01-01.par\n",
      "Cov\n",
      "Corr\n",
      "Std\n",
      "Zscore\n",
      "Return\n",
      "Decay\n",
      "2021-01-01_2021-03-01.par\n",
      "Cov\n",
      "Corr\n",
      "Std\n",
      "Zscore\n",
      "Return\n",
      "Decay\n",
      "trainx.shape:  torch.Size([715587, 108, 3])\n",
      "trainy.shape:  torch.Size([715587, 1])\n"
     ]
    }
   ],
   "source": [
    "data_time = time_list[-4:-1]\n",
    "path_list = ['Cov','Corr','Std','Zscore','Return','Decay']\n",
    "def reshape(data_path,feat_num):\n",
    "    data = pd.read_parquet(data_path)\n",
    "    data = np.array(data.set_index([\"timestamp\",\"ticker\"]))\n",
    "    data = data.reshape(data.shape[0],feat_num,-1)\n",
    "    return torch.from_numpy(data)\n",
    "\n",
    "trainx = []\n",
    "for j in data_time:\n",
    "    print(j)\n",
    "    feat_cat = []\n",
    "    for i in path_list:\n",
    "        print(i)\n",
    "        if i in [\"Cov\",\"Corr\"]:\n",
    "            feat_cat.append(reshape(path + i +\"/\" + j,conv_num))\n",
    "        else:\n",
    "            feat_cat.append(reshape(path + i +\"/\" + j,feat_num))\n",
    "    feat_cat = torch.cat(feat_cat, axis=1)\n",
    "    trainx.append(feat_cat)\n",
    "trainx = torch.cat(trainx, axis=0)\n",
    "\n",
    "trainy = []\n",
    "for j in data_time:\n",
    "    target = pd.read_parquet(path +\"Data/\" + j)\n",
    "    target = np.array(target[\"target\"])\n",
    "    target = torch.from_numpy(target.reshape(-1,1))\n",
    "    trainy.append(target)\n",
    "trainy = torch.cat(trainy, axis=0)\n",
    "\n",
    "print(\"trainx.shape: \", trainx.shape)\n",
    "print(\"trainy.shape: \", trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1aa1c238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T08:09:51.513714Z",
     "start_time": "2021-12-15T08:09:49.310155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-01_2021-06-01.par\n",
      "Cov\n",
      "Corr\n",
      "Std\n",
      "Zscore\n",
      "Return\n",
      "Decay\n",
      "testx.shape:  torch.Size([259340, 108, 3])\n",
      "testy.shape:  torch.Size([259340, 1])\n"
     ]
    }
   ],
   "source": [
    "data_time = time_list[-1:]\n",
    "path_list = ['Cov','Corr','Std','Zscore','Return','Decay']\n",
    "def reshape(data_path,feat_num):\n",
    "    data = pd.read_parquet(data_path)\n",
    "    data = np.array(data.set_index([\"timestamp\",\"ticker\"]))\n",
    "    data = data.reshape(data.shape[0],feat_num,-1)\n",
    "    return torch.from_numpy(data)\n",
    "\n",
    "testx = []\n",
    "for j in data_time:\n",
    "    print(j)\n",
    "    feat_cat = []\n",
    "    for i in path_list:\n",
    "        print(i)\n",
    "        if i in [\"Cov\",\"Corr\"]:\n",
    "            feat_cat.append(reshape(path + i +\"/\" + j,conv_num))\n",
    "        else:\n",
    "            feat_cat.append(reshape(path + i +\"/\" + j,feat_num))\n",
    "    feat_cat = torch.cat(feat_cat, axis=1)\n",
    "    testx.append(feat_cat)\n",
    "testx = torch.cat(testx, axis=0)\n",
    "\n",
    "testy = []\n",
    "for j in data_time:\n",
    "    target = pd.read_parquet(path +\"Data/\" + j)\n",
    "    target = np.array(target[\"target\"])\n",
    "    target = torch.from_numpy(target.reshape(-1,1))\n",
    "    testy.append(target)\n",
    "testy = torch.cat(testy, axis=0)\n",
    "\n",
    "print(\"testx.shape: \", testx.shape)\n",
    "print(\"testy.shape: \", testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f72c4e69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T07:35:11.418953Z",
     "start_time": "2021-12-15T07:35:10.974913Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = nn.BatchNorm1d(feat_cat.shape[1], affine=True)\n",
    "bc = batch(feat_cat.to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c5044dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T07:35:15.109582Z",
     "start_time": "2021-12-15T07:35:15.095256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9064e-02, -1.9568e-02, -1.9655e-02],\n",
       "        [-1.9080e-02, -1.9857e-02, -1.9857e-02],\n",
       "        [-1.8350e-02, -1.9099e-02, -1.9162e-02],\n",
       "        [-1.8831e-02, -1.9491e-02, -1.9550e-02],\n",
       "        [-1.4207e-01,  5.5922e-02, -3.4986e-02],\n",
       "        [ 9.7686e-02,  2.9972e-02,  3.9200e-03],\n",
       "        [-3.7238e-02, -1.6006e-02, -2.5755e-02],\n",
       "        [-4.9007e-02, -1.1330e-02, -2.8629e-02],\n",
       "        [-1.9201e-02, -1.9850e-02, -1.9856e-02],\n",
       "        [-1.9659e-02, -2.0294e-02, -2.0335e-02],\n",
       "        [-1.9607e-02, -2.0166e-02, -2.0207e-02],\n",
       "        [-7.9127e-02,  3.3255e-02, -2.5667e-02],\n",
       "        [ 7.7355e-02,  4.2561e-03, -1.6837e-02],\n",
       "        [-3.4569e-02, -2.2951e-02, -2.9043e-02],\n",
       "        [-4.1371e-02, -2.0717e-02, -3.1545e-02],\n",
       "        [-1.8955e-02, -1.9736e-02, -1.9796e-02],\n",
       "        [-1.9164e-02, -1.9946e-02, -1.9926e-02],\n",
       "        [-1.8097e-01,  2.6206e-03, -4.0132e-02],\n",
       "        [ 1.3646e-01,  1.7383e-02, -2.5272e-02],\n",
       "        [-4.2392e-02, -2.0586e-02, -2.5665e-02],\n",
       "        [-5.8689e-02, -2.0138e-02, -2.9114e-02],\n",
       "        [-1.9508e-02, -2.0247e-02, -2.0276e-02],\n",
       "        [-1.3297e-01, -1.6990e-02, -2.1663e-02],\n",
       "        [ 1.7831e-01, -1.2465e-02, -3.4215e-02],\n",
       "        [-4.3226e-02, -2.9206e-02, -2.9772e-02],\n",
       "        [-5.5858e-02, -3.1072e-02, -3.2070e-02],\n",
       "        [-1.2361e-01,  2.3186e-02, -2.9173e-02],\n",
       "        [ 1.2357e-01, -6.4440e-04, -2.5273e-02],\n",
       "        [-3.9731e-02, -2.2958e-02, -2.8941e-02],\n",
       "        [-5.0777e-02, -2.1045e-02, -3.1649e-02],\n",
       "        [-1.2839e+00, -6.3198e-02, -7.2183e-02],\n",
       "        [-9.0376e-02, -1.2938e-01, -2.3329e-01],\n",
       "        [-5.6390e-02, -1.0258e-01, -2.2564e-01],\n",
       "        [-4.7880e-01, -3.3325e-01, -3.3433e-01],\n",
       "        [-6.2913e-01, -3.9859e-01, -4.0029e-01],\n",
       "        [-3.2168e-01, -3.2485e-01, -3.3331e-01],\n",
       "        [-1.9064e-02, -1.9568e-02, -1.9655e-02],\n",
       "        [-1.9080e-02, -1.9857e-02, -1.9857e-02],\n",
       "        [-1.8350e-02, -1.9099e-02, -1.9162e-02],\n",
       "        [-1.8831e-02, -1.9491e-02, -1.9550e-02],\n",
       "        [-1.4207e-01,  5.5922e-02, -3.4986e-02],\n",
       "        [ 9.7686e-02,  2.9972e-02,  3.9200e-03],\n",
       "        [-3.7238e-02, -1.6006e-02, -2.5755e-02],\n",
       "        [-4.9007e-02, -1.1330e-02, -2.8629e-02],\n",
       "        [-1.9201e-02, -1.9850e-02, -1.9856e-02],\n",
       "        [-1.9659e-02, -2.0294e-02, -2.0335e-02],\n",
       "        [-1.9607e-02, -2.0166e-02, -2.0207e-02],\n",
       "        [-7.9127e-02,  3.3255e-02, -2.5667e-02],\n",
       "        [ 7.7355e-02,  4.2561e-03, -1.6837e-02],\n",
       "        [-3.4569e-02, -2.2951e-02, -2.9043e-02],\n",
       "        [-4.1371e-02, -2.0717e-02, -3.1545e-02],\n",
       "        [-1.8955e-02, -1.9736e-02, -1.9796e-02],\n",
       "        [-1.9164e-02, -1.9946e-02, -1.9926e-02],\n",
       "        [-1.8097e-01,  2.6206e-03, -4.0132e-02],\n",
       "        [ 1.3646e-01,  1.7383e-02, -2.5272e-02],\n",
       "        [-4.2392e-02, -2.0586e-02, -2.5665e-02],\n",
       "        [-5.8689e-02, -2.0138e-02, -2.9114e-02],\n",
       "        [-1.9508e-02, -2.0247e-02, -2.0276e-02],\n",
       "        [-1.3297e-01, -1.6990e-02, -2.1663e-02],\n",
       "        [ 1.7831e-01, -1.2465e-02, -3.4215e-02],\n",
       "        [-4.3226e-02, -2.9206e-02, -2.9772e-02],\n",
       "        [-5.5858e-02, -3.1072e-02, -3.2070e-02],\n",
       "        [-1.2361e-01,  2.3186e-02, -2.9173e-02],\n",
       "        [ 1.2357e-01, -6.4440e-04, -2.5273e-02],\n",
       "        [-3.9731e-02, -2.2958e-02, -2.8941e-02],\n",
       "        [-5.0777e-02, -2.1045e-02, -3.1649e-02],\n",
       "        [-1.2839e+00, -6.3198e-02, -7.2183e-02],\n",
       "        [-9.0376e-02, -1.2938e-01, -2.3329e-01],\n",
       "        [-5.6390e-02, -1.0258e-01, -2.2564e-01],\n",
       "        [-4.7880e-01, -3.3325e-01, -3.3433e-01],\n",
       "        [-6.2913e-01, -3.9859e-01, -4.0029e-01],\n",
       "        [-3.2168e-01, -3.2485e-01, -3.3331e-01],\n",
       "        [ 1.4368e-01,  5.3144e-02,  2.3713e-02],\n",
       "        [ 1.1566e-01,  2.7054e-02,  4.7842e-03],\n",
       "        [ 1.6723e-01,  3.0364e-02,  4.2877e-02],\n",
       "        [ 1.5771e-01,  3.7275e-02,  7.2650e-03],\n",
       "        [ 1.4257e-01,  2.2840e-02,  1.8097e-02],\n",
       "        [ 9.6043e-01,  8.0457e-01,  2.0836e-01],\n",
       "        [ 6.8305e-01, -8.8194e-01, -1.2100e+00],\n",
       "        [-6.9461e-01, -7.2107e-01, -8.2228e-01],\n",
       "        [-7.4713e-01, -7.8999e-01, -9.5398e-01],\n",
       "        [-2.2928e-01, -2.2928e-01, -2.2928e-01],\n",
       "        [-2.2976e-01, -2.2976e-01, -2.2976e-01],\n",
       "        [-2.2929e-01, -2.2929e-01, -2.2929e-01],\n",
       "        [-2.3266e-01, -2.3266e-01, -2.3266e-01],\n",
       "        [-2.2463e-01, -2.2463e-01, -2.2463e-01],\n",
       "        [ 7.5776e-01,  3.8238e-01,  1.2512e+00],\n",
       "        [-2.4477e-02, -3.3515e-02, -1.1522e-02],\n",
       "        [ 7.5391e-01,  3.7897e-01,  1.2469e+00],\n",
       "        [ 7.5535e-01,  3.7991e-01,  1.2488e+00],\n",
       "        [-8.7824e-01, -9.7769e-01, -2.6808e-01],\n",
       "        [-8.1012e-01, -8.5677e-01, -3.2296e-01],\n",
       "        [-7.3824e-01, -1.0784e+00, -1.4309e-01],\n",
       "        [-8.0552e-01, -1.0697e+00, -3.2415e-01],\n",
       "        [-7.8338e-01, -9.3548e-01, -2.4518e-01],\n",
       "        [-6.5562e-02, -6.5562e-02, -6.5563e-02],\n",
       "        [-4.2473e-02,  4.2389e-01, -6.9945e-01],\n",
       "        [-4.5212e-02, -4.3952e-02, -4.8867e-02],\n",
       "        [-4.7602e-02, -4.6346e-02, -5.1247e-02],\n",
       "        [ 3.2016e-01,  3.0790e-01,  3.0778e-01],\n",
       "        [ 3.1571e-01,  2.9893e-01,  2.9784e-01],\n",
       "        [ 3.2547e-01,  3.1000e-01,  3.1293e-01],\n",
       "        [ 3.1874e-01,  3.0041e-01,  3.0429e-01],\n",
       "        [ 3.2001e-01,  3.0411e-01,  3.0464e-01],\n",
       "        [ 1.6316e+00,  1.0938e+00,  6.3062e-01],\n",
       "        [-7.8731e-01, -1.0771e+00, -4.3616e-01],\n",
       "        [-7.0579e-01, -8.2881e-01, -9.3476e-01],\n",
       "        [-6.8393e-01, -8.8539e-01, -1.0589e+00]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "883d2b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T02:14:58.944357Z",
     "start_time": "2021-12-15T02:14:58.922513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3918e-02, -6.5509e-02, -6.5508e-02],\n",
       "        [-6.1593e-02, -6.3086e-02, -6.3083e-02],\n",
       "        [-6.0243e-02, -6.1826e-02, -6.1789e-02],\n",
       "        [-5.8619e-02, -5.9576e-02, -5.9744e-02],\n",
       "        [-6.0095e-02, -6.1593e-02, -6.1545e-02],\n",
       "        [-2.7701e-02, -1.0592e-01, -1.2154e-01],\n",
       "        [ 3.0270e-02,  2.0677e-01,  2.1936e-01],\n",
       "        [-1.1117e-01, -1.1473e-01, -1.1545e-01],\n",
       "        [-1.2863e-01, -1.3433e-01, -1.3547e-01],\n",
       "        [ 4.9474e-02,  6.6967e-02,  6.8180e-02],\n",
       "        [-6.2340e-02, -6.3985e-02, -6.4268e-02],\n",
       "        [-6.0818e-02, -6.3146e-02, -6.3147e-02],\n",
       "        [-5.8881e-02, -6.1055e-02, -6.1237e-02],\n",
       "        [-6.0675e-02, -6.2707e-02, -6.2889e-02],\n",
       "        [-4.8993e-01,  1.5602e-01, -1.4058e-01],\n",
       "        [ 2.3710e-01,  1.7655e-01,  1.5325e-01],\n",
       "        [-1.4635e-01, -1.1556e-01, -1.2970e-01],\n",
       "        [-1.7809e-01, -1.2917e-01, -1.5163e-01],\n",
       "        [ 5.1565e-02,  4.4704e-02,  4.2593e-02],\n",
       "        [-6.0993e-02, -6.2982e-02, -6.2998e-02],\n",
       "        [-6.2599e-02, -6.4588e-02, -6.4716e-02],\n",
       "        [-6.2901e-02, -6.4718e-02, -6.4850e-02],\n",
       "        [-3.6158e-01,  4.5303e-02, -1.6805e-01],\n",
       "        [-1.7216e-02, -7.7469e-02, -9.4859e-02],\n",
       "        [-2.1578e-01, -1.9584e-01, -2.0630e-01],\n",
       "        [-2.5695e-01, -2.2512e-01, -2.4181e-01],\n",
       "        [-3.1007e-02, -3.7416e-02, -3.8990e-02],\n",
       "        [-5.9726e-02, -6.1975e-02, -6.2149e-02],\n",
       "        [-6.0480e-02, -6.2799e-02, -6.2740e-02],\n",
       "        [-5.7095e-01, -9.2524e-03, -1.4006e-01],\n",
       "        [ 6.8273e-02, -1.0135e-02, -3.8227e-02],\n",
       "        [-1.2799e-01, -1.0117e-01, -1.0741e-01],\n",
       "        [-1.5907e-01, -1.1690e-01, -1.2672e-01],\n",
       "        [-1.2490e-02, -2.1349e-02, -2.3974e-02],\n",
       "        [-6.1847e-02, -6.4089e-02, -6.4178e-02],\n",
       "        [-5.2329e-01, -1.2058e-01, -1.3683e-01],\n",
       "        [-8.9153e-02, -2.4196e-01, -2.5938e-01],\n",
       "        [-2.0637e-01, -1.8629e-01, -1.8710e-01],\n",
       "        [-2.4736e-01, -2.1574e-01, -2.1702e-01],\n",
       "        [-7.9070e-02, -9.3761e-02, -9.5221e-02],\n",
       "        [-4.8169e-01,  2.9799e-02, -1.5264e-01],\n",
       "        [-1.9910e-02, -1.0936e-01, -1.2709e-01],\n",
       "        [-1.8529e-01, -1.6024e-01, -1.6918e-01],\n",
       "        [-2.2342e-01, -1.8374e-01, -1.9789e-01],\n",
       "        [-4.4958e-02, -5.4365e-02, -5.5959e-02],\n",
       "        [-1.2431e+00, -8.5791e-02, -9.4310e-02],\n",
       "        [-9.5113e-02, -1.3494e-01, -2.4105e-01],\n",
       "        [-6.6528e-02, -1.1180e-01, -2.3243e-01],\n",
       "        [-1.5968e+00, -8.6255e-02, -9.4105e-02],\n",
       "        [-6.5903e-01, -4.6612e-01, -4.6754e-01],\n",
       "        [-7.8088e-01, -5.0811e-01, -5.1011e-01],\n",
       "        [-1.1794e-01, -4.4162e-01, -4.7118e-01],\n",
       "        [-4.5192e-01, -4.5735e-01, -4.7182e-01],\n",
       "        [-3.3382e-01, -2.5418e-01, -2.5460e-01],\n",
       "        [-4.2792e-01, -3.0093e-01, -3.0159e-01],\n",
       "        [-4.6158e+00, -6.3943e+00,  5.1960e-01],\n",
       "        [-8.2872e-01, -2.0164e+00,  2.7521e-01],\n",
       "        [-1.2861e+00, -6.7656e-01,  4.8256e-01],\n",
       "        [-9.0732e-01, -1.5688e-01,  7.2044e-02],\n",
       "        [-1.1440e+00, -1.7093e+00,  2.6110e-01],\n",
       "        [-4.7790e-01, -7.3228e-01, -1.1803e+00],\n",
       "        [-7.1911e-01, -4.0918e-01, -6.7752e-01],\n",
       "        [-4.9399e-01, -7.5165e-01, -1.2054e+00],\n",
       "        [-4.9376e-01, -7.5144e-01, -1.2051e+00],\n",
       "        [-7.1013e-01, -4.5665e-01, -6.8537e-01],\n",
       "        [ 6.5536e-01,  5.1212e-01,  2.0013e-01],\n",
       "        [ 8.3534e-01, -7.2397e-01,  3.9028e-01],\n",
       "        [ 8.9184e-01, -4.0040e-01, -1.1656e-01],\n",
       "        [ 9.7566e-01,  4.8154e-01,  1.1114e-01],\n",
       "        [-1.7811e+00,  7.8609e-01, -1.2933e+00],\n",
       "        [ 1.5807e+00,  1.0519e+00, -9.5946e-01],\n",
       "        [-1.8149e+00,  7.8676e-01, -1.3206e+00],\n",
       "        [-1.8148e+00,  7.8698e-01, -1.3204e+00],\n",
       "        [ 1.5474e+00,  9.5322e-01, -9.6032e-01],\n",
       "        [ 5.4658e-01, -6.4953e-01,  1.8892e-01],\n",
       "        [ 4.1718e-01, -1.9785e+00, -1.1606e-01],\n",
       "        [ 3.3113e-01, -8.9527e-02, -6.2408e-02],\n",
       "        [-2.1762e+00,  5.1487e-01, -1.2113e+00],\n",
       "        [ 3.5715e-01,  3.2868e-01, -9.0851e-01],\n",
       "        [-2.2439e+00,  5.1785e-01, -1.2538e+00],\n",
       "        [-2.2461e+00,  5.1775e-01, -1.2551e+00],\n",
       "        [ 3.3628e-01,  2.6686e-01, -9.3106e-01],\n",
       "        [ 3.9272e-01,  4.6096e-01, -7.8624e-01],\n",
       "        [ 6.5759e-01, -7.2367e-01,  2.3905e-01],\n",
       "        [-1.8596e+00, -1.1120e-01, -1.3666e+00],\n",
       "        [ 6.7962e-01,  5.1462e-01, -1.3425e+00],\n",
       "        [-1.8929e+00, -1.2186e-01, -1.3936e+00],\n",
       "        [-1.8932e+00, -1.2200e-01, -1.3937e+00],\n",
       "        [ 6.8501e-01,  4.5029e-01, -1.3796e+00],\n",
       "        [ 2.8397e-01, -2.5417e+00, -6.4609e-01],\n",
       "        [-2.3501e+00, -9.7824e-01, -8.2085e-01],\n",
       "        [ 4.4362e-01,  1.0781e-02, -6.1748e-01],\n",
       "        [-2.4135e+00, -1.0105e+00, -8.4968e-01],\n",
       "        [-2.4159e+00, -1.0119e+00, -8.5061e-01],\n",
       "        [ 4.3629e-01, -6.5950e-02, -6.7024e-01],\n",
       "        [-2.1914e+00,  3.8623e-01, -1.3180e+00],\n",
       "        [ 4.6742e-01,  3.1294e-01, -1.0234e+00],\n",
       "        [-2.2453e+00,  3.8424e-01, -1.3545e+00],\n",
       "        [-2.2465e+00,  3.8404e-01, -1.3551e+00],\n",
       "        [ 4.6413e-01,  2.5393e-01, -1.0616e+00],\n",
       "        [-2.0233e+00, -4.3327e-01,  4.0682e-01],\n",
       "        [ 9.5530e-02,  9.5530e-02,  9.5530e-02],\n",
       "        [ 1.0009e-01,  1.0009e-01,  1.0009e-01],\n",
       "        [-2.0778e+00, -4.3881e-01,  4.1281e-01],\n",
       "        [-2.0286e+00, -4.3563e-01,  4.0583e-01],\n",
       "        [-2.0316e+00, -4.3719e-01,  4.0527e-01],\n",
       "        [ 8.4775e-02,  1.0765e-01,  1.1326e-01],\n",
       "        [ 7.6748e-02,  7.6748e-02,  7.6748e-02],\n",
       "        [-2.0822e+00, -4.4081e-01,  4.1186e-01],\n",
       "        [-2.0853e+00, -4.4234e-01,  4.1140e-01],\n",
       "        [-2.6040e-01, -3.9897e-01, -4.2636e-01],\n",
       "        [-2.8566e-01, -3.8659e-01, -4.1941e-01],\n",
       "        [-3.1272e-01, -4.1488e-01, -4.4057e-01],\n",
       "        [-2.5763e-01, -4.0483e-01, -3.9138e-01],\n",
       "        [-2.7190e-01, -4.0433e-01, -4.3733e-01],\n",
       "        [-2.7814e-01, -4.1033e-01, -4.1557e-01],\n",
       "        [ 8.6246e-01,  7.1627e-01,  1.5708e-01],\n",
       "        [ 6.1829e-01, -1.2553e+00, -1.6481e+00],\n",
       "        [-8.6431e-01, -8.9789e-01, -1.0264e+00],\n",
       "        [-9.1547e-01, -9.6653e-01, -1.1618e+00],\n",
       "        [-1.5812e-01, -5.3146e-01, -6.0136e-01],\n",
       "        [-2.4614e-01,  1.4631e+00,  2.4523e+00],\n",
       "        [-8.8151e-02,  1.1893e+00,  2.2268e+00],\n",
       "        [ 9.0993e-02,  1.7954e+00,  3.0063e+00],\n",
       "        [-2.3636e-01,  1.8579e+00,  1.4049e+00],\n",
       "        [-1.8859e-01,  1.6300e+00,  3.1889e+00],\n",
       "        [-1.2888e-01,  2.0659e+00,  2.2761e+00],\n",
       "        [ 6.2102e-01,  1.6374e-01,  1.2221e+00],\n",
       "        [-1.7804e-02, -2.7854e-02, -3.3995e-03],\n",
       "        [ 6.1637e-01,  1.5931e-01,  1.2173e+00],\n",
       "        [ 6.1848e-01,  1.6042e-01,  1.2205e+00],\n",
       "        [-1.1418e+00, -2.0796e+00,  2.6076e-01],\n",
       "        [-9.8858e-01, -9.1383e-01, -2.4471e-01],\n",
       "        [-8.4880e-01, -9.4706e-01, -2.4638e-01],\n",
       "        [-7.9078e-01, -8.3713e-01, -3.0632e-01],\n",
       "        [-7.0175e-01, -1.0353e+00, -1.1819e-01],\n",
       "        [-7.7669e-01, -1.0372e+00, -3.0208e-01],\n",
       "        [-7.5462e-01, -9.0467e-01, -2.2368e-01],\n",
       "        [-2.8709e-02, -2.8709e-02, -2.8712e-02],\n",
       "        [-3.5115e-02,  4.1045e-01, -6.6279e-01],\n",
       "        [-7.4798e-02, -7.1155e-02, -8.5368e-02],\n",
       "        [-7.4360e-02, -7.0817e-02, -8.4635e-02],\n",
       "        [-3.1079e-02,  3.5452e-01, -6.2443e-01],\n",
       "        [-3.7566e-01, -4.0858e-01, -4.0727e-01],\n",
       "        [-3.8371e-01, -4.0686e-01, -4.0710e-01],\n",
       "        [-3.8370e-01, -4.1528e-01, -4.1732e-01],\n",
       "        [-3.7745e-01, -4.0682e-01, -4.0125e-01],\n",
       "        [-3.8316e-01, -4.1772e-01, -4.1040e-01],\n",
       "        [-3.8086e-01, -4.1091e-01, -4.0993e-01],\n",
       "        [ 1.4384e+00,  9.4622e-01,  5.2230e-01],\n",
       "        [-8.4225e-01, -1.1413e+00, -4.7991e-01],\n",
       "        [-9.1252e-01, -1.0567e+00, -1.1809e+00],\n",
       "        [-9.3531e-01, -1.1658e+00, -1.3644e+00],\n",
       "        [-4.3367e-01, -5.0686e-01, -2.9068e-01]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eeae166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T07:35:52.983327Z",
     "start_time": "2021-12-15T07:35:52.856121Z"
    }
   },
   "outputs": [],
   "source": [
    "max_pooling = torch.nn.MaxPool1d(kernel_size = 3, stride=1)(bc) # Max Pooling\n",
    "avg_pooling = torch.nn.AvgPool1d(kernel_size = 3, stride=1)(bc) # Mean Pooling\n",
    "min_pooling = -(torch.nn.MaxPool1d(kernel_size = 3, stride=1)(-bc)) # MinPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f23bac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T07:38:44.316255Z",
     "start_time": "2021-12-15T07:38:44.278948Z"
    }
   },
   "outputs": [],
   "source": [
    "pool_concat = torch.cat([max_pooling,avg_pooling,min_pooling], axis=1)\n",
    "pool_concat = pool_concat.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88faca7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ea65fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T08:26:06.883422Z",
     "start_time": "2021-12-15T08:26:06.843935Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument weight in method wrapper__cudnn_batch_norm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-7b6147a7ade9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# model = AlphaNet(feat_num,30).to(\"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAlphaNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m108\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-7b6147a7ade9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2_neuron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument weight in method wrapper__cudnn_batch_norm)"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self, factor_num, fully_connect_layer_neural):\n",
    "        super(AlphaNet, self).__init__()\n",
    "        self.batch_dimension = factor_num * (factor_num - 1) + 4 * factor_num\n",
    "        self.fc1_neuron = (factor_num * (factor_num - 1) + 4 * factor_num) * 3\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.batch = nn.BatchNorm1d(self.batch_dimension, affine=True)\n",
    "        self.max_pooling = torch.nn.MaxPool1d(kernel_size = 3, stride=1)\n",
    "        self.avg_pooling = torch.nn.AvgPool1d(kernel_size = 3, stride=1)\n",
    "        self.fc1 = torch.nn.Linear(self.fc1_neuron, self.fc2_neuron)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(self.fc2_neuron, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.batch(x)\n",
    "        x1 =  self.max_pooling(x)\n",
    "        x2 =  self.avg_pooling(x)\n",
    "        x3 =  -self.max_pooling(-x)\n",
    "        x = torch.cat([max_pooling,avg_pooling,min_pooling], axis=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred\n",
    "\n",
    "# model = AlphaNet(feat_num,30).to(\"cpu\")\n",
    "summary(AlphaNet(feat_num,30), input_size=(108, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "192ad5d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T08:16:06.928629Z",
     "start_time": "2021-12-15T08:16:06.916407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet(\n",
      "  (batch): BatchNorm1d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (max_pooling): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avg_pooling): AvgPool1d(kernel_size=(3,), stride=(1,), padding=(0,))\n",
      "  (fc1): Linear(in_features=324, out_features=30, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (out): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Data.TensorDataset(trainx, trainy)\n",
    "test_dataset = Data.TensorDataset(testx, testy)\n",
    "batch_size = 512\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "alphanet = AlphaNet(feat_num, 30)\n",
    "# alphanet = alphanet.cuda()\n",
    "# alphanet = torch.nn.parallel.DataParallel(alphanet)\n",
    "print(alphanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac643691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T08:16:08.795017Z",
     "start_time": "2021-12-15T08:16:08.629563Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (53624916x1 and 324x30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1243bdfe53dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphanet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#         print(pred.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         print(\"epoch：\", epoch, \"的第\" \"个inputs\", data.data.size(), \"labels\", label.data.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-64e393dcec89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_pooling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_pooling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_pooling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (53624916x1 and 324x30)"
     ]
    }
   ],
   "source": [
    "total_length = trainx.shape[0]\n",
    "LR = 0.0001\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(alphanet.parameters(), lr=LR, alpha=0.9)\n",
    "epoch_num = 20\n",
    "\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    total_loss = 0\n",
    "    for _, (data, label) in enumerate(train_loader):\n",
    "        data = Variable(data).float()\n",
    "        label = Variable(label).float()\n",
    "        pred = alphanet(data)\n",
    "#         print(pred.size())\n",
    "#         print(\"epoch：\", epoch, \"的第\" \"个inputs\", data.data.size(), \"labels\", label.data.size())\n",
    "        #         label = label.unsqueeze(1)\n",
    "        loss = loss_function(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    total_loss = total_loss * batch_size / total_length\n",
    "    print('Epoch: ', epoch + 1, ' loss: ', total_loss)\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "for _, (data, label) in enumerate(test_loader):\n",
    "    data = Variable(data).float()\n",
    "    pred = alphanet(data)\n",
    "    pred_list.extend(pred.tolist())\n",
    "    label_list.extend(label.tolist())\n",
    "\n",
    "final = pd.concat([test_target, pd.DataFrame(pred_list)], axis=1)\n",
    "alpha_name = 'AlphaNetV1_Original_Input_1208'\n",
    "final.rename(columns={0: alpha_name, 'ticker': 'symbol'}, inplace=True)\n",
    "final = final.reindex(columns=['symbol', 'timestamp', alpha_name,'target'])\n",
    "final.set_index(['symbol', 'timestamp']).to_csv(output_path + \"result/\"+'%s_%s.csv' % (time_start, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb458d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:39:24.989733Z",
     "start_time": "2021-12-09T06:39:24.985112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
