{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f5acde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T23:39:17.177090Z",
     "start_time": "2021-12-28T23:39:17.163079Z"
    }
   },
   "outputs": [],
   "source": [
    "Alpha_Name = \"AlphaNet_Original_Input_5d_return\"\n",
    "start_time = \"2021-01-01\"\n",
    "forecast_months = 6 # months\n",
    "target = \"5d_ret\"\n",
    "feat_num = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483bd59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T23:39:21.124305Z",
     "start_time": "2021-12-28T23:39:17.180682Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from progressbar import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from os import walk\n",
    "import matplotlib.pyplot as plt\n",
    "path = '/home/wuwenjun/Data/' + Alpha_Name +'/'\n",
    "output_path = \"/home/wuwenjun/Alpha_Factor/\" + Alpha_Name + \"/result/\"\n",
    "model_path = \"/home/wuwenjun/Alpha_Factor/\" + Alpha_Name + \"/model/\"\n",
    "if os.path.exists(output_path) == False:\n",
    "    os.makedirs(output_path)\n",
    "if os.path.exists(model_path) == False:\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b692dba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T23:39:21.148715Z",
     "start_time": "2021-12-28T23:39:21.126986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 194042.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2015-01-01_2015-03-01.par',\n",
       " '2015-03-01_2015-06-01.par',\n",
       " '2015-06-01_2015-09-01.par',\n",
       " '2015-09-01_2016-01-01.par',\n",
       " '2016-01-01_2016-03-01.par',\n",
       " '2016-03-01_2016-06-01.par',\n",
       " '2016-06-01_2016-09-01.par',\n",
       " '2016-09-01_2017-01-01.par',\n",
       " '2017-01-01_2017-03-01.par',\n",
       " '2017-03-01_2017-06-01.par',\n",
       " '2017-06-01_2017-09-01.par',\n",
       " '2017-09-01_2018-01-01.par',\n",
       " '2018-01-01_2018-03-01.par',\n",
       " '2018-03-01_2018-06-01.par',\n",
       " '2018-06-01_2018-09-01.par',\n",
       " '2018-09-01_2019-01-01.par',\n",
       " '2019-01-01_2019-03-01.par',\n",
       " '2019-03-01_2019-06-01.par',\n",
       " '2019-06-01_2019-09-01.par',\n",
       " '2019-09-01_2020-01-01.par',\n",
       " '2020-01-01_2020-03-01.par',\n",
       " '2020-03-01_2020-06-01.par',\n",
       " '2020-06-01_2020-09-01.par',\n",
       " '2020-09-01_2021-01-01.par']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['2021-01-01_2021-03-01.par', '2021-03-01_2021-06-01.par']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_list = []\n",
    "data_path = path + \"Data/\"\n",
    "dataframe_list = pd.DataFrame()\n",
    "for f, _, i in walk(data_path):\n",
    "    for j in tqdm(i):\n",
    "        time_list.append(j)\n",
    "time_list.sort()     \n",
    "for count,item in enumerate(time_list):\n",
    "    if item.startswith(start_time):\n",
    "        train_timestamp = time_list[:count]\n",
    "        test_timestamp = time_list[count:count + forecast_months//3]\n",
    "        break\n",
    "display(train_timestamp)\n",
    "display(test_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c8dec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [01:12<00:34,  4.96s/it]"
     ]
    }
   ],
   "source": [
    "trainx , trainy , testx , testy = [] , [] , [],  []\n",
    "\n",
    "for train in tqdm(train_timestamp):\n",
    "    df = pd.read_parquet(path+ \"Final/\" + train).set_index([\"timestamp\",\"ticker\"])\n",
    "    trainx.append(df.drop(\"target\",axis=1))\n",
    "    trainy.append(df['target'])\n",
    "trainx = pd.concat(trainx,axis=0)\n",
    "trainy = pd.concat(trainy,axis=0)\n",
    "\n",
    "display(trainx)\n",
    "display(trainy)\n",
    "\n",
    "\n",
    "for test in tqdm(test_timestamp):\n",
    "    df = pd.read_parquet(path+ \"Final/\" + test).set_index([\"timestamp\",\"ticker\"])\n",
    "    testx.append(df.drop(\"target\",axis=1))\n",
    "    testy.append(df['target'])\n",
    "testx = pd.concat(testx,axis=0)\n",
    "testy = pd.concat(testy,axis=0)\n",
    "target_list = pd.DataFrame(testy.copy())\n",
    "display(testx)\n",
    "display(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0846171e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.259Z"
    }
   },
   "outputs": [],
   "source": [
    "trainx = torch.from_numpy(np.array(trainx))\n",
    "trainy = torch.from_numpy(np.array(trainy).reshape(-1,1))\n",
    "testx = torch.from_numpy(np.array(testx))\n",
    "testy = torch.from_numpy(np.array(testy).reshape(-1,1))\n",
    "print(\"trainx.shape: \" , trainx.shape)\n",
    "print(\"trainy.shape: \" , trainy.shape)\n",
    "print(\"testx.shape: \" , testx.shape)\n",
    "print(\"testy.shape: \" , testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c73212",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.262Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(trainx, trainy)\n",
    "test_dataset = Data.TensorDataset(testx, testy)\n",
    "batch_size = 1024\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=32,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=32,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef48be2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.265Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self, factor_num, fully_connect_layer_neural):\n",
    "        super(AlphaNet, self).__init__()\n",
    "        self.fc1_neuron = int((factor_num * (factor_num - 1)+ 4 * factor_num) * 3 * 2)\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.batch = torch.nn.BatchNorm1d(self.fc1_neuron)\n",
    "        self.fc1 = torch.nn.Linear(self.fc1_neuron, self.fc2_neuron)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(self.fc2_neuron, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred\n",
    "# device=torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cb2fa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alphanet = AlphaNet(feat_num, 30)\n",
    "alphanet = alphanet.cuda()\n",
    "# alphanet = torch.nn.parallel.DataParallel(alphanet)\n",
    "print(alphanet)\n",
    "total_length = trainx.shape[0]\n",
    "LR = 0.0001\n",
    "loss_function = nn.MSELoss().cuda()\n",
    "optimizer = optim.RMSprop(alphanet.parameters(), lr=LR, alpha=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma = 0.5)\n",
    "epoch_num = 30\n",
    "loss_list = []\n",
    "# for epoch in range(epoch_num):\n",
    "#     optimizer.step()\n",
    "#     scheduler.step()\n",
    "#     lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "# plt.plot(range(epoch_num),lr_list,color = 'r')\n",
    "\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    total_loss = 0\n",
    "    for _, (inputs, outputs) in enumerate(train_loader):\n",
    "        inputs = Variable(inputs).float().cuda()\n",
    "        outputs = Variable(outputs).float().cuda()\n",
    "        optimizer.zero_grad() # noticed:  the grad return to zero before starting the loop\n",
    "        \n",
    "        # forward + backward +update\n",
    "        pred = alphanet(inputs)\n",
    "        pred = pred.cuda()\n",
    "        loss = loss_function(pred, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        total_loss += loss.item()\n",
    "    total_loss = total_loss * batch_size / total_length\n",
    "    print('Epoch: ', epoch + 1, ' loss: ', total_loss)\n",
    "    loss_list.append(total_loss)\n",
    "torch.save(alphanet,model_path + test_timestamp[0].split(\"_\")[0] + \"_\" + test_timestamp[-1].split(\"_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e8b14",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.272Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list,color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac643691",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.275Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alphanet = alphanet.cpu()\n",
    "pred_list = []\n",
    "label_list = []\n",
    "for _, (data, label) in enumerate(test_loader):\n",
    "    data = Variable(data).float()\n",
    "    pred = alphanet(data)\n",
    "    pred_list.extend(pred.tolist())\n",
    "    label_list.extend(label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1127f6d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.278Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.DataFrame(pred_list)\n",
    "final = pd.concat([target_list.reset_index(),final],axis=1)\n",
    "final.rename(columns={0:Alpha_Name,'ticker': 'symbol'},inplace=True)\n",
    "# final.set_index([\"timestamp\",\"symbol\"],inplace=True)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532d5a9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.281Z"
    }
   },
   "outputs": [],
   "source": [
    "test_timestamp[0].split(\"_\")[0] + \"_\" + test_timestamp[-1].split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9637d68",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-28T23:39:18.284Z"
    }
   },
   "outputs": [],
   "source": [
    "final.to_parquet(output_path\n",
    "                + test_timestamp[0].split(\"_\")[0] + \"_\" + test_timestamp[-1].split(\"_\")[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
