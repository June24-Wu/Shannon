{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T05:27:13.173157Z",
     "start_time": "2021-11-24T05:27:10.023235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vwap</th>\n",
       "      <th>volume</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>turnover</th>\n",
       "      <th>free_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190923</td>\n",
       "      <td>1</td>\n",
       "      <td>15.34</td>\n",
       "      <td>15.47</td>\n",
       "      <td>15.18</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.3122</td>\n",
       "      <td>1403282.00</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>1.5038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190923</td>\n",
       "      <td>2</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.15</td>\n",
       "      <td>26.1471</td>\n",
       "      <td>603530.46</td>\n",
       "      <td>-2.4254</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>1.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190923</td>\n",
       "      <td>4</td>\n",
       "      <td>20.36</td>\n",
       "      <td>20.65</td>\n",
       "      <td>19.61</td>\n",
       "      <td>20.04</td>\n",
       "      <td>20.0171</td>\n",
       "      <td>29893.32</td>\n",
       "      <td>-4.7076</td>\n",
       "      <td>3.6188</td>\n",
       "      <td>5.9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190923</td>\n",
       "      <td>5</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.2947</td>\n",
       "      <td>111437.30</td>\n",
       "      <td>-2.0772</td>\n",
       "      <td>1.0533</td>\n",
       "      <td>1.3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190923</td>\n",
       "      <td>6</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.2993</td>\n",
       "      <td>136997.47</td>\n",
       "      <td>1.1278</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>1.5887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958151</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688168</td>\n",
       "      <td>52.80</td>\n",
       "      <td>53.30</td>\n",
       "      <td>52.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>52.5581</td>\n",
       "      <td>5919.73</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>2.0771</td>\n",
       "      <td>2.1589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958162</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688188</td>\n",
       "      <td>446.80</td>\n",
       "      <td>449.00</td>\n",
       "      <td>425.20</td>\n",
       "      <td>438.14</td>\n",
       "      <td>438.5992</td>\n",
       "      <td>4444.64</td>\n",
       "      <td>-1.6830</td>\n",
       "      <td>1.6540</td>\n",
       "      <td>1.6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958216</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688321</td>\n",
       "      <td>39.20</td>\n",
       "      <td>39.30</td>\n",
       "      <td>38.64</td>\n",
       "      <td>38.90</td>\n",
       "      <td>38.8391</td>\n",
       "      <td>14252.01</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.5631</td>\n",
       "      <td>0.6717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958221</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688333</td>\n",
       "      <td>199.87</td>\n",
       "      <td>201.01</td>\n",
       "      <td>192.01</td>\n",
       "      <td>200.34</td>\n",
       "      <td>196.4810</td>\n",
       "      <td>4126.57</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.9092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958246</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688388</td>\n",
       "      <td>136.00</td>\n",
       "      <td>136.85</td>\n",
       "      <td>130.45</td>\n",
       "      <td>134.93</td>\n",
       "      <td>134.5550</td>\n",
       "      <td>61087.12</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>3.6459</td>\n",
       "      <td>3.9295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1772680 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  ticker    open    high     low   close      vwap  \\\n",
       "0         20190923       1   15.34   15.47   15.18   15.38   15.3122   \n",
       "1         20190923       2   26.49   26.49   26.00   26.15   26.1471   \n",
       "2         20190923       4   20.36   20.65   19.61   20.04   20.0171   \n",
       "3         20190923       5    3.37    3.37    3.27    3.30    3.2947   \n",
       "4         20190923       6    5.34    5.40    5.21    5.38    5.2993   \n",
       "...            ...     ...     ...     ...     ...     ...       ...   \n",
       "1958151   20210923  688168   52.80   53.30   52.00   52.45   52.5581   \n",
       "1958162   20210923  688188  446.80  449.00  425.20  438.14  438.5992   \n",
       "1958216   20210923  688321   39.20   39.30   38.64   38.90   38.8391   \n",
       "1958221   20210923  688333  199.87  201.01  192.01  200.34  196.4810   \n",
       "1958246   20210923  688388  136.00  136.85  130.45  134.93  134.5550   \n",
       "\n",
       "             volume  pct_chg  turnover  free_turnover  \n",
       "0        1403282.00   0.2608    0.7428         1.5038  \n",
       "1         603530.46  -2.4254    0.6212         1.0882  \n",
       "2          29893.32  -4.7076    3.6188         5.9394  \n",
       "3         111437.30  -2.0772    1.0533         1.3495  \n",
       "4         136997.47   1.1278    1.0161         1.5887  \n",
       "...             ...      ...       ...            ...  \n",
       "1958151     5919.73   1.0792    2.0771         2.1589  \n",
       "1958162     4444.64  -1.6830    1.6540         1.6540  \n",
       "1958216    14252.01   0.0772    0.5631         0.6717  \n",
       "1958221     4126.57   0.6177    0.9092         0.9092  \n",
       "1958246    61087.12   0.3272    3.6459         3.9295  \n",
       "\n",
       "[1772680 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "data = pd.read_csv('alphanet_codetest_daily.csv')\n",
    "# 定义数据图片开始和结束的时间\n",
    "time_start = 20190801\n",
    "time_end = 20211001\n",
    "\n",
    "\n",
    "stock = pd.DataFrame(data.groupby('ticker')['timestamp'].count() == 487).reset_index()\n",
    "merge = data.merge(stock, on='ticker', how='left')\n",
    "merge = merge[merge['timestamp_y'] == True]\n",
    "merge['timestamp'] = merge['timestamp_x']\n",
    "merge = merge[['timestamp','ticker','open','high','low','close','vwap','volume','pct_chg','turnover','free_turnover']] # feature\n",
    "merge = merge[(merge['timestamp'] >= time_start) & (merge['timestamp'] <= time_end)]\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T05:27:31.951052Z",
     "start_time": "2021-11-24T05:27:13.174154Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xinfei\\AppData\\Local\\Temp/ipykernel_9316/2247197430.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  one_data['pct_change_shift'] = (one_data['close'].shift(-day_back) - one_data['close']) / one_data['close'] * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  (553277, 1, 9, 30)\n",
      "y.shape:  (553277, 1)\n"
     ]
    }
   ],
   "source": [
    "day_back = 3 # 回溯几天进行计算\n",
    "day = 30 # 一次提取几天的数,一般默认为30\n",
    "stride = 10 # 一次学习多少天\n",
    "\n",
    "\n",
    "x , y , x_delay = [] , [], [] # 初始数据集\n",
    "\n",
    "for count , ticker in enumerate(merge['ticker'].drop_duplicates()):\n",
    "#     print(count)\n",
    "    one_data = merge[merge['ticker'] == ticker]\n",
    "    one_data['pct_change_shift'] = (one_data['close'].shift(-day_back) - one_data['close']) / one_data['close'] * 100\n",
    "    one_data = one_data.set_index(['timestamp','ticker'])\n",
    "    one_data = one_data.dropna() # 丢弃因为回溯而产生的空值\n",
    "    array = np.array(one_data)\n",
    "\n",
    "    for i in range(0,array.shape[0] - day ,3): # 其中3 代表取数的步长，ex.每两天取一次数，步长为3\n",
    "        x.append(array[i:i+day,:-1].T)\n",
    "        y.append(array[i+day-1][-1])\n",
    "x  , y = np.array(x) , np.array(y).reshape(-1,1) # x = (153, 9, 30) , y = (153,1)\n",
    "x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2]) # x = (153, 1, 9, 30)\n",
    "print(\"x.shape: \",x.shape)\n",
    "print(\"y.shape: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T05:27:50.734900Z",
     "start_time": "2021-11-24T05:27:50.710884Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateC(l1):\n",
    "    if len(l1) == 1:\n",
    "        return []\n",
    "    v = [[l1[0],i] for i in l1[1:]]\n",
    "    l1 = l1[1:]\n",
    "    return v+generateC(l1)\n",
    "def generate_Num_and_ReversedNum(feat_nums):\n",
    "    list1 = list(range(feat_nums))\n",
    "    num = generateC(list1)\n",
    "    num_rev = []\n",
    "    for l in num:\n",
    "        l1 = l.copy()\n",
    "        l1.reverse()\n",
    "        num_rev.append(l1)\n",
    "    return num , num_rev\n",
    "def data_info(data,stride):\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length = data.shape[3] # 30\n",
    "    feat_num = data.shape[2] # 9\n",
    "    \"\"\"num:组合数对列表,num_rev:num的翻转列表\"\"\"\n",
    "    num , num_rev = generate_Num_and_ReversedNum(feat_num)\n",
    "    conv_feat = len(num)\n",
    "    # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "    if data_length % stride == 0:\n",
    "        step_list = list(range(0,data_length+stride,stride))\n",
    "    elif data_length % stride<=5:\n",
    "        mod = data_length % stride\n",
    "        step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "    else:\n",
    "        mod = data_length % stride\n",
    "        step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "    return data_length,feat_num,conv_feat,num,num_rev,step_list\n",
    "def ts_cov4d(data,stride):\n",
    "    '''计算4维数据的协方差'''\n",
    "    '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "    l = []\n",
    "    #计算的过程中务必保持keepdims=True\n",
    "    for i in range(len(step_list)-1):\n",
    "        start = step_list[i]\n",
    "        end = step_list[i+1]\n",
    "        sub_data1 = data[:,:,num,start:end] # (2000, 1, 36, 2, 10)\n",
    "        sub_data2 = data[:,:,num_rev,start:end]\n",
    "        mean1 = sub_data1.mean(axis = 4,keepdims = True) # (2000, 1, 36, 2, 1)\n",
    "        mean2 = sub_data2.mean(axis = 4,keepdims = True)\n",
    "        spread1 = sub_data1 - mean1 # (2000, 1, 36, 2, 10)\n",
    "        spread2 = sub_data2 - mean2\n",
    "        cov = ((spread1*spread2).sum(axis = 4,keepdims = True)/(sub_data1.shape[4] - 1)).mean(axis = 3,keepdims = True) # (2000, 1, 36, 1, 1)\n",
    "        l.append(cov)\n",
    "    corr = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,conv_feat,len(step_list)-1) # (2000, 1, 36, 3)\n",
    "    return torch.from_numpy(corr)\n",
    "def ts_corr4d(data,stride,conv1):\n",
    "    '''计算4维数据的相关系数'''\n",
    "    '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "    l = []\n",
    "    for i in range(len(step_list)-1):\n",
    "        start = step_list[i]\n",
    "        end = step_list[i+1]\n",
    "        sub_data1 = data[:,:,num,start:end]\n",
    "        sub_data2 = data[:,:,num_rev,start:end]\n",
    "        std1 = sub_data1.std(axis = 4,keepdims = True)\n",
    "        std2 = sub_data2.std(axis = 4,keepdims = True)\n",
    "        std = (std1*std2).mean(axis = 3,keepdims = True)\n",
    "        l.append(std)\n",
    "    std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,conv_feat,len(step_list)-1)\n",
    "#     cov = ts_cov4d(data,stride)\n",
    "    fct = (sub_data1.shape[4]-1)/sub_data1.shape[4]\n",
    "    return (conv1/torch.from_numpy(std))*fct\n",
    "def ts_stddev4d(data,stride):\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "    l = []\n",
    "    for i in range(len(step_list)-1):\n",
    "        start = step_list[i]\n",
    "        end = step_list[i+1]\n",
    "        sub_data1 = data[:,:,:,start:end]\n",
    "        std1 = sub_data1.std(axis = 3,keepdims = True)\n",
    "        l.append(std1)\n",
    "    std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "    return torch.from_numpy(std)\n",
    "def ts_zscore(data,stride):\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "    l = []\n",
    "    for i in range(len(step_list)-1):\n",
    "        start = step_list[i]\n",
    "        end = step_list[i+1]\n",
    "        sub_data1 = data[:,:,:,start:end]\n",
    "        mean = sub_data1.mean(axis = 3,keepdims = True)\n",
    "        std = sub_data1.std(axis = 3,keepdims = True)\n",
    "#         std[std == 0] = 1e-9\n",
    "        z_score = mean/std\n",
    "        l.append(z_score)\n",
    "    z_score = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "    return torch.from_numpy(z_score)\n",
    "def ts_return(data,stride):\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "    data[data == 0] = 1e-9\n",
    "    l = []\n",
    "    for i in range(len(step_list)-1):\n",
    "        start = step_list[i]\n",
    "        end = step_list[i+1]\n",
    "        sub_data1 = data[:,:,:,start:end]\n",
    "        ret = sub_data1[:,:,:,-1]/sub_data1[:,:,:,0] - 1\n",
    "        l.append(ret)\n",
    "    z_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "    z_data[z_data > 1] = 1\n",
    "    return torch.from_numpy(z_data)\n",
    "def ts_decaylinear(data,stride):\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "    l = []\n",
    "    for i in range(len(step_list)-1):\n",
    "        start = step_list[i]\n",
    "        end = step_list[i+1]\n",
    "        time_spread = end - start\n",
    "        weight = np.arange(1,time_spread+1)\n",
    "        weight = weight/(weight.sum())\n",
    "        sub_data1 = (data[:,:,:,start:end]*weight).mean(axis = 3,keepdims = True)\n",
    "        l.append(sub_data1)\n",
    "    decay_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "    return torch.from_numpy(decay_data)\n",
    "def ts_pool(data,stride,method):\n",
    "    if type(data) == torch.Tensor:\n",
    "        data = data.detach().numpy()\n",
    "    if data.shape[-1] <= stride:\n",
    "        step_list = [0,data.shape[-1]]\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "    l = []\n",
    "    for i in range(len(step_list)-1):\n",
    "        start = step_list[i]\n",
    "        end = step_list[i+1]\n",
    "        if method == 'max':\n",
    "            sub_data1 = data[:,:,:,start:end].max(axis = 3,keepdims = True)\n",
    "        if method == 'min':\n",
    "            sub_data1 = data[:,:,:,start:end].min(axis = 3,keepdims = True)\n",
    "        if method == 'mean':\n",
    "            sub_data1 = data[:,:,:,start:end].mean(axis = 3,keepdims = True)\n",
    "        l.append(sub_data1)\n",
    "    try:\n",
    "        pool_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list) - 1)\n",
    "    except:\n",
    "        pool_data = np.squeeze(np.array(l)).reshape(-1,feat_num,len(step_list) - 1)\n",
    "    return torch.from_numpy(pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T05:36:49.496251Z",
     "start_time": "2021-11-24T05:36:19.420835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74029173.36078541\n",
      "12930.02505032905\n",
      "0.1056851611111112\n",
      "185265.1201575766\n"
     ]
    }
   ],
   "source": [
    "conv = ts_cov4d(x,10).detach().numpy()\n",
    "# conv = nn.BatchNorm1d(36,affine=True)(conv)\n",
    "print(np.max(conv))\n",
    "print(np.mean(conv))\n",
    "print(np.median(conv))\n",
    "print(np.std(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T05:36:50.529488Z",
     "start_time": "2021-11-24T05:36:49.497248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298.94443\n",
      "-2.9307723e-09\n",
      "-0.06698045\n",
      "0.9999991\n"
     ]
    }
   ],
   "source": [
    "conv = nn.BatchNorm1d(36,affine=True)(torch.from_numpy(conv).to(torch.float))\n",
    "conv = conv.detach().numpy()\n",
    "print(np.max(conv))\n",
    "print(np.mean(conv))\n",
    "print(np.median(conv))\n",
    "print(np.std(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T01:20:31.071534Z",
     "start_time": "2021-11-24T01:20:07.312632Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_num = 9\n",
    "# x = x.detach().numpy()\n",
    "# x\n",
    "batch = nn.BatchNorm1d(36,affine=True)\n",
    "batch2 = nn.BatchNorm1d(9,affine=True)\n",
    "conv1 = ts_cov4d(x,10)\n",
    "# conv1 = ts_cov4d(x,10).to(torch.float)\n",
    "# bc1 = batch(conv1)\n",
    "conv2 = ts_corr4d(x,10,conv1).to(torch.float)\n",
    "bc2 = batch(conv2)\n",
    "bc1 = batch(conv1.to(torch.float))\n",
    "conv3 = ts_stddev4d(x,10).to(torch.float)\n",
    "bc3 = batch2(conv3)\n",
    "conv4 = ts_zscore(x,10).to(torch.float)\n",
    "bc4 = batch2(conv4)\n",
    "conv5 = ts_return(x,10).to(torch.float)\n",
    "bc5 = batch2(conv5)\n",
    "conv6 = ts_decaylinear(x,10).to(torch.float)\n",
    "bc6 = batch2(conv6)\n",
    "\n",
    "feat_cat = torch.cat([bc1,bc2,bc3,bc4,bc5,bc6],axis = 1) # 特征聚合\n",
    "shape = feat_cat.shape\n",
    "feat_cat = feat_cat.reshape(shape[0],1,shape[1],shape[2])\n",
    "# Pooling\n",
    "ts_max = ts_pool(feat_cat ,3,method = 'max')\n",
    "ts_max.shape\n",
    "ts_max = nn.BatchNorm1d(108,affine = True)(ts_max)\n",
    "ts_min = ts_pool(feat_cat ,3,method = 'min')\n",
    "ts_min = nn.BatchNorm1d(108,affine = True)(ts_min)\n",
    "ts_mean = ts_pool(feat_cat ,3,method = 'mean')\n",
    "ts_mean = nn.BatchNorm1d(108,affine = True)(ts_mean)\n",
    "data_pool = torch.cat([ts_max,ts_min,ts_mean],axis = 1)\n",
    "data_pool.shape\n",
    "data_pool = data_pool.flatten(start_dim = 1)\n",
    "data_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T09:05:18.371762Z",
     "start_time": "2021-11-23T09:05:18.366776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7850,  0.7623,  0.6012],\n",
       "        [ 0.9554,  0.5325,  0.8029],\n",
       "        [ 0.7221,  0.3724,  0.3186],\n",
       "        [ 0.8250,  0.4756,  0.5489],\n",
       "        [-0.4866,  0.2650, -0.3823],\n",
       "        [-0.1128, -0.5146, -0.5298],\n",
       "        [-0.5086,  0.2649, -0.3821],\n",
       "        [-0.5281,  0.1490, -0.3823],\n",
       "        [ 0.9237,  0.8145,  0.8038],\n",
       "        [ 0.9661,  0.7328,  0.8518],\n",
       "        [ 0.9912,  0.8580,  0.9577],\n",
       "        [-0.0221,  0.2592,  0.2861],\n",
       "        [ 0.4470,  0.0725,  0.2058],\n",
       "        [-0.0604,  0.2592,  0.2861],\n",
       "        [-0.0957,  0.0927,  0.2861],\n",
       "        [ 0.8798,  0.8886,  0.7226],\n",
       "        [ 0.9515,  0.9750,  0.8794],\n",
       "        [-0.3103, -0.2709, -0.2642],\n",
       "        [ 0.1433,  0.3720, -0.0887],\n",
       "        [-0.3422, -0.2709, -0.2642],\n",
       "        [-0.3711, -0.4249, -0.2643],\n",
       "        [ 0.9700,  0.9170,  0.9186],\n",
       "        [-0.0261, -0.2470,  0.2639],\n",
       "        [ 0.5815,  0.5743,  0.5845],\n",
       "        [-0.0647, -0.2470,  0.2638],\n",
       "        [-0.1004, -0.3466,  0.2638],\n",
       "        [-0.0897, -0.1791,  0.1458],\n",
       "        [ 0.4111,  0.4641,  0.2744],\n",
       "        [-0.1283, -0.1790,  0.1458],\n",
       "        [-0.1638, -0.3401,  0.1457],\n",
       "        [ 0.5286, -0.3278,  0.5692],\n",
       "        [ 0.9990,  1.0000,  1.0000],\n",
       "        [ 0.9961,  0.9736,  1.0000],\n",
       "        [ 0.5028, -0.3276,  0.5690],\n",
       "        [ 0.4780, -0.3419,  0.5692],\n",
       "        [ 0.9991,  0.9736,  1.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T09:11:07.501188Z",
     "start_time": "2021-11-23T09:11:07.308703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26152])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2[torch.isnan(conv2) == True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:39:19.673815Z",
     "start_time": "2021-11-23T08:39:19.673815Z"
    }
   },
   "outputs": [],
   "source": [
    "class Pooling(object):\n",
    "    def __init__(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        self.data = data.detach().numpy()\n",
    "        self.stride = stride\n",
    "        self.data_length = data.shape[3]\n",
    "        self.feat_num = data.shape[2] # 9\n",
    "        self.step_list = self.generate_Step_List(self.data_length,self.stride)\n",
    "        self.extracted_data = self.Extraction(self.data,self.feat_num,self.stride)\n",
    "    def Extraction(self,data,feat_num,stride):\n",
    "        print(\"------Start Pooling------\")\n",
    "        # Pooling\n",
    "        ts_max = self.ts_pool(feat_cat,self.stride,self.feat_num,self.step_list,method = 'max')\n",
    "        ts_max = nn.BatchNorm1d(108,affine = True)(ts_max)\n",
    "        ts_min = self.ts_pool(feat_cat ,self.stride,self.feat_num,self.step_list,method = 'min')\n",
    "        ts_min = nn.BatchNorm1d(108,affine = True)(ts_min)\n",
    "        ts_mean = self.ts_pool(feat_cat ,self.stride,self.feat_num,self.step_list,method = 'mean')\n",
    "        ts_mean = nn.BatchNorm1d(108,affine = True)(ts_mean)\n",
    "        data_pool = torch.cat([ts_max,ts_min,ts_mean],axis = 1)\n",
    "        data_pool = data_pool.flatten(start_dim = 1)\n",
    "        print(\"Pooling shape: \",data_pool.shape )\n",
    "        return data_pool\n",
    "    def generate_Step_List(self,data_length,stride):\n",
    "        # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "        if data_length % stride == 0:\n",
    "            step_list = list(range(0,data_length+stride,stride))\n",
    "        elif data_length % stride<=5:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "        else:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "        return step_list\n",
    "    def ts_pool(self,data,stride,feat_num,step_list,method):\n",
    "        if type(data) == torch.Tensor:\n",
    "            data = data.detach().numpy()\n",
    "        if data.shape[-1] <= stride:\n",
    "            step_list = [0,data.shape[-1]]\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            if method == 'max':\n",
    "                sub_data1 = data[:,:,:,start:end].max(axis = 3,keepdims = True)\n",
    "            if method == 'min':\n",
    "                sub_data1 = data[:,:,:,start:end].min(axis = 3,keepdims = True)\n",
    "            if method == 'mean':\n",
    "                sub_data1 = data[:,:,:,start:end].mean(axis = 3,keepdims = True)\n",
    "            l.append(sub_data1)\n",
    "        try:\n",
    "            pool_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list) - 1)\n",
    "        except:\n",
    "            pool_data = np.squeeze(np.array(l)).reshape(-1,feat_num,len(step_list) - 1)\n",
    "        return torch.from_numpy(pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:26:17.534933Z",
     "start_time": "2021-11-23T08:25:18.110980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Extraction------\n",
      "------Finished ts_cov4d----output shape:  torch.Size([553277, 36, 3])\n",
      "------Finished ts_corr4d----output shape:  torch.Size([553277, 36, 3])\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Input data dimensions should be [N,C,H,W]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/4003039903.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconvolutional\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolutional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeat_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvolutional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextracted_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpooling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_cat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpooling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextracted_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x.shape : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/1902248879.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, stride)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input data dimensions should be [N,C,H,W]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Input data dimensions should be [N,C,H,W]"
     ]
    }
   ],
   "source": [
    "convolutional = Convolutional(x,10)\n",
    "feat_cat = convolutional.extracted_data\n",
    "# pooling = Pooling(feat_cat,3)\n",
    "# x = pooling.extracted_data.detach().numpy()\n",
    "# print(\"x.shape : \",x.shape)\n",
    "# print(\"y.shape : \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:26:36.058780Z",
     "start_time": "2021-11-23T08:26:36.031679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:10:11.277116Z",
     "start_time": "2021-11-23T08:10:05.758394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500000, 324])\n",
      "1 torch.Size([53277, 324])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# x = np.random.uniform(10,100,(3124,1,9,30))\n",
    "# y = np.random.randn(3124,1)\n",
    "class Testdataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.label = torch.from_numpy(label)\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "trainset = Testdataset(x,y)\n",
    "trainloader = DataLoader(trainset,batch_size = 500000,shuffle = False)\n",
    "for i,data in enumerate(trainloader):\n",
    "    input_data,label = data\n",
    "    print(i,input_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:11:31.975588Z",
     "start_time": "2021-11-23T08:11:31.967587Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self,factor_num,fully_connect_layer_neural):\n",
    "        # super 父类，调用父类的构造，这一步必须有\n",
    "        # 第一个参数为定义类的名称，第二个为self\n",
    "        super(AlphaNet,self).__init__()\n",
    "        self.fc1_neuron = (factor_num * (factor_num -1) + 4 * factor_num)* 3\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(self.fc1_neuron,self.fc2_neuron)\n",
    "        self.out = nn.Linear(self.fc2_neuron,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:19:32.103499Z",
     "start_time": "2021-11-23T08:19:26.559024Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=324, out_features=30, bias=True)\n",
      "  (out): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "torch.Size([500000, 324])\n",
      "torch.Size([500000, 1])\n",
      "output.shape:  torch.Size([500000, 1])\n",
      "torch.Size([53277, 324])\n",
      "torch.Size([53277, 1])\n",
      "output.shape:  torch.Size([53277, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "alphanet = AlphaNet(9,30)\n",
    "print(alphanet)\n",
    "criterion = nn.MSELoss()\n",
    "LR = 0.0001\n",
    "optimizer = optim.RMSprop(alphanet.parameters(), lr=LR, alpha=0.9)\n",
    "epoch_num = 1\n",
    "loss_list = []\n",
    "for epoch in range(epoch_num):\n",
    "    train_loss = 0.0\n",
    "    for data,label in trainloader:\n",
    "        print(data.shape)\n",
    "        print(label.shape)\n",
    "        out_put = alphanet(data)\n",
    "        print(\"output.shape: \",out_put.shape)\n",
    "        loss = criterion(out_put,label.to(torch.float))\n",
    "#         optimizer.zero_grad()\n",
    "#         train_loss += loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     loss_list.append(train_loss.item())\n",
    "#     print(\"current epoch time:\",epoch+1,\"  Loss: \",train_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:19:34.235120Z",
     "start_time": "2021-11-23T08:19:34.222790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2231],\n",
       "        [-6.4079],\n",
       "        [ 2.9343],\n",
       "        ...,\n",
       "        [-5.6452],\n",
       "        [ 5.4701],\n",
       "        [ 8.9870]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:22:13.789805Z",
     "start_time": "2021-11-23T08:22:13.774883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0293, -0.0297, -0.0300],\n",
       "        [-0.0289, -0.0295, -0.0296],\n",
       "        [-0.0267, -0.0275, -0.0276],\n",
       "        [-0.0283, -0.0290, -0.0290],\n",
       "        [-0.9412,  0.2199, -0.3941],\n",
       "        [ 0.1667,  0.0964,  0.1174],\n",
       "        [-0.1594, -0.1389, -0.1490],\n",
       "        [-0.1582, -0.1341, -0.1445],\n",
       "        [-0.0286, -0.0293, -0.0294],\n",
       "        [-0.0290, -0.0301, -0.0301],\n",
       "        [-0.0296, -0.0305, -0.0306],\n",
       "        [-0.2876,  0.0312, -0.1063],\n",
       "        [ 0.0631, -0.0813, -0.0579],\n",
       "        [-0.2064, -0.2001, -0.2024],\n",
       "        [-0.2010, -0.1952, -0.1941],\n",
       "        [-0.0281, -0.0288, -0.0290],\n",
       "        [-0.0289, -0.0295, -0.0297],\n",
       "        [-0.6820, -0.4986, -0.2886],\n",
       "        [ 0.0165,  0.0476, -0.0471],\n",
       "        [-0.1274, -0.1228, -0.1192],\n",
       "        [-0.1268, -0.1252, -0.1153],\n",
       "        [-0.0290, -0.0300, -0.0301],\n",
       "        [-0.2610, -0.5075, -0.0564],\n",
       "        [-0.0936, -0.1729, -0.1752],\n",
       "        [-0.1782, -0.1809, -0.1733],\n",
       "        [-0.1725, -0.1779, -0.1643],\n",
       "        [-0.3640, -0.4248, -0.1332],\n",
       "        [-0.0183, -0.0662, -0.1118],\n",
       "        [-0.1782, -0.1779, -0.1730],\n",
       "        [-0.1736, -0.1768, -0.1652],\n",
       "        [ 0.9703, -0.8368,  0.4262],\n",
       "        [-0.1319, -0.1227, -0.2027],\n",
       "        [-0.1029, -0.0819, -0.1990],\n",
       "        [-0.1487, -0.2305, -0.1733],\n",
       "        [-0.1200, -0.2192, -0.1435],\n",
       "        [-0.2359, -0.2355, -0.2386],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [-0.1659, -0.1883, -0.2272],\n",
       "        [-0.1296, -0.2140, -0.2250],\n",
       "        [-0.1442, -0.2031, -0.2243],\n",
       "        [-0.1015, -0.2072, -0.2128],\n",
       "        [-0.1255, -0.2038, -0.2231],\n",
       "        [ 1.6719,  1.8246,  0.6909],\n",
       "        [-0.3366, -0.4896, -0.4972],\n",
       "        [-0.6046, -0.6021, -0.6677],\n",
       "        [-0.3969, -0.3849, -0.4496],\n",
       "        [ 0.0472,  0.0472,  0.0472],\n",
       "        [ 0.0477,  0.0477,  0.0477],\n",
       "        [ 0.0435,  0.0435,  0.0435],\n",
       "        [ 0.0453,  0.0453,  0.0453],\n",
       "        [ 0.0447,  0.0447,  0.0447],\n",
       "        [ 0.9649,  0.3233,  2.0686],\n",
       "        [ 0.1582,  0.0120, -0.0214],\n",
       "        [ 0.8354,  0.3252,  2.0695],\n",
       "        [ 0.7090,  0.1248,  2.0723],\n",
       "        [ 0.5210, -0.1865, -0.0688],\n",
       "        [ 0.9018, -0.4404, -0.0826],\n",
       "        [ 0.6724, -0.2895,  0.0389],\n",
       "        [ 0.9108, -0.2783, -0.0763],\n",
       "        [ 0.8369, -0.3597, -0.0092],\n",
       "        [-0.1596, -1.1646, -0.5345],\n",
       "        [ 0.0906,  0.0906,  0.0906],\n",
       "        [-0.2000, -1.1569, -0.5270],\n",
       "        [-0.2479, -1.0423, -0.5285],\n",
       "        [-0.0416, -0.0223, -0.0189],\n",
       "        [-0.0419, -0.0249, -0.0223],\n",
       "        [-0.0363, -0.0206, -0.0150],\n",
       "        [-0.0373, -0.0224, -0.0201],\n",
       "        [-0.0384, -0.0230, -0.0195],\n",
       "        [ 2.8606,  2.4485,  1.9322],\n",
       "        [ 1.0405,  0.0309, -0.2105],\n",
       "        [-0.6095, -0.6385, -0.6729],\n",
       "        [-0.4510, -0.4643, -0.4939]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:40:57.596472Z",
     "start_time": "2021-11-18T09:40:57.566191Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "\n",
    "\n",
    "# class AlphaNet(nn.Module):\n",
    "#     def __init__(self,factor_num,fully_connect_layer_neural):\n",
    "#         \"\"\" factor_num : 因子个数\n",
    "#             fully_connect_layer_neural: 全连接层神经元的数量\n",
    "#         \"\"\"\n",
    "#         super(AlphaNet,self).__init__()\n",
    "#         self.fc1_neuron = (factor_num * (factor_num -1) + 4 * factor_num)* 3\n",
    "#         self.fc2_neuron = fully_connect_layer_neural\n",
    "#         self.batchnorm = nn.BatchNorm2d(1,affine=True)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(self.fc1_neuron,self.fc2_neuron)\n",
    "#         self.out = nn.Linear(self.fc2_neuron,1)\n",
    "#         self.relu = nn.ReLU()\n",
    "#     def forward(self,data,num,num_rev):\n",
    "#         # Conv\n",
    "#         conv1 = self.ts_cov4d(data,10).to(torch.float)\n",
    "#         sigmoid1 = torch.sigmoid(conv1)\n",
    "#         bc1 = self.batchnorm(sigmoid1)\n",
    "#         conv2 = self.ts_corr4d(data,10).to(torch.float)\n",
    "#         bc2 = self.batchnorm(conv2)\n",
    "#         conv3 = self.ts_stddev4d(data,10).to(torch.float)\n",
    "#         sigmoid3 = torch.sigmoid(conv3)\n",
    "#         bc3 = self.batchnorm(sigmoid3)\n",
    "#         conv4 = self.ts_decaylinear(data,10).to(torch.float)\n",
    "#         sigmoid4 = torch.sigmoid(conv4)\n",
    "#         bc4 = self.batchnorm(sigmoid4)\n",
    "#         conv5 = self.ts_zscore(data,10).to(torch.float)\n",
    "#         bc5 = self.batchnorm(conv5)\n",
    "#         data_conv = torch.cat([bc1,bc2,bc3,bc4,bc5],axis = 2)\n",
    "#         # Pooling\n",
    "#         ts_max = self.ts_pool(data_conv,3,method = 'max')\n",
    "#         ts_max = self.batchnorm(ts_max)\n",
    "#         ts_min = self.ts_pool(data_conv,3,method = 'min')\n",
    "#         ts_min = self.batchnorm(ts_min)\n",
    "#         ts_mean = self.ts_pool(data_conv,3,method = 'mean')\n",
    "#         ts_mean = self.batchnorm(ts_mean)\n",
    "#         data_fin = torch.cat([ts_max,ts_min,ts_mean],axis = 2)\n",
    "#         data_fin = data_fin.flatten(start_dim = 1)\n",
    "#         input_size = data_fin.size(1)\n",
    "#         ful_connect = self.dropout(self.relu(self.fc1(data_fin)))\n",
    "#         output = self.out(ful_connect)\n",
    "#         return output.to(torch.float)\n",
    "#     # 为了cov 和 corr提取并行计算产生计算列表\n",
    "#     def generateC(l1):\n",
    "#         if len(l1) == 1:\n",
    "#             return []\n",
    "#         v = [[l1[0],i] for i in l1[1:]]\n",
    "#         l1 = l1[1:]\n",
    "#         return v+generateC(l1)\n",
    "#     def generate_Num_and_ReversedNum(feat_nums):\n",
    "#         list1 = list(range(feat_nums))\n",
    "#         num = generateC(list1)\n",
    "#         num_rev = []\n",
    "#         for l in num:\n",
    "#             l1 = l.copy()\n",
    "#             l1.reverse()\n",
    "#             num_rev.append(l1)\n",
    "#         return num , num_rev\n",
    "#     def data_info(data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length = data.shape[3] # 30\n",
    "#         feat_num = data.shape[2] # 9\n",
    "#         \"\"\"num:组合数对列表,num_rev:num的翻转列表\"\"\"\n",
    "#         num , num_rev = generate_Num_and_ReversedNum(feat_num)\n",
    "#         conv_feat = len(num)\n",
    "#         # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "#         if data_length % stride == 0:\n",
    "#             step_list = list(range(0,data_length+stride,stride))\n",
    "#         elif data_length % stride<=5:\n",
    "#             mod = data_length % stride\n",
    "#             step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "#         else:\n",
    "#             mod = data_length % stride\n",
    "#             step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "#         return data_length,feat_num,conv_feat,num,num_rev,step_list\n",
    "#     def ts_cov4d(self,data,stride):\n",
    "#         '''计算4维数据的协方差'''\n",
    "#         '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         #计算的过程中务必保持keepdims=True\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,num,start:end] # (2000, 1, 36, 2, 10)\n",
    "#             sub_data2 = data[:,:,num_rev,start:end]\n",
    "#             mean1 = sub_data1.mean(axis = 4,keepdims = True) # (2000, 1, 36, 2, 1)\n",
    "#             mean2 = sub_data2.mean(axis = 4,keepdims = True)\n",
    "#             spread1 = sub_data1 - mean1 # (2000, 1, 36, 2, 10)\n",
    "#             spread2 = sub_data2 - mean2\n",
    "#             cov = ((spread1*spread2).sum(axis = 4,keepdims = True)/(sub_data1.shape[4] - 1)).mean(axis = 3,keepdims = True) # (2000, 1, 36, 1, 1)\n",
    "#             l.append(cov)\n",
    "#         corr = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,conv_feat,len(step_list)-1) # (2000, 1, 36, 3)\n",
    "#         return torch.from_numpy(corr)\n",
    "#     def ts_corr4d(self,data,stride):\n",
    "#         '''计算4维数据的相关系数'''\n",
    "#         '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,num,start:end]\n",
    "#             sub_data2 = data[:,:,num_rev,start:end]\n",
    "#             std1 = sub_data1.std(axis = 4,keepdims = True)\n",
    "#             std2 = sub_data2.std(axis = 4,keepdims = True)\n",
    "#             std = (std1*std2).mean(axis = 3,keepdims = True)\n",
    "#             l.append(std)\n",
    "#         std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,conv_feat,len(step_list)-1)\n",
    "#         cov = self.ts_cov4d(data,stride)\n",
    "#         fct = (sub_data1.shape[4]-1)/sub_data1.shape[4]\n",
    "#         return (cov/torch.from_numpy(std))*fct\n",
    "#     def ts_stddev4d(self,data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,:,start:end]\n",
    "#             std1 = sub_data1.std(axis = 3,keepdims = True)\n",
    "#             l.append(std1)\n",
    "#         std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "#         return torch.from_numpy(std)\n",
    "#     def ts_zscore(self,data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,:,start:end]\n",
    "#             mean = sub_data1.mean(axis = 3,keepdims = True)\n",
    "#             std = sub_data1.std(axis = 3,keepdims = True)\n",
    "#             z_score = mean/std\n",
    "#             l.append(z_score)\n",
    "#         z_score = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "#         return torch.from_numpy(z_score)\n",
    "#     def ts_decaylinear(self,data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             time_spread = end - start\n",
    "#             weight = np.arange(1,time_spread+1)\n",
    "#             weight = weight/(weight.sum())\n",
    "#             sub_data1 = (data[:,:,:,start:end]*weight).mean(axis = 3,keepdims = True)\n",
    "#             l.append(sub_data1)\n",
    "#         decay_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "#         return torch.from_numpy(decay_data)\n",
    "#     def ts_pool(self,data,stride,method):\n",
    "#         if type(data) == torch.Tensor:\n",
    "#             data = data.detach().numpy()\n",
    "#         if data.shape[-1] <= stride:\n",
    "#             step_list = [0,data.shape[-1]]\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             if method == 'max':\n",
    "#                 sub_data1 = data[:,:,:,start:end].max(axis = 3,keepdims = True)\n",
    "#             if method == 'min':\n",
    "#                 sub_data1 = data[:,:,:,start:end].min(axis = 3,keepdims = True)\n",
    "#             if method == 'mean':\n",
    "#                 sub_data1 = data[:,:,:,start:end].mean(axis = 3,keepdims = True)\n",
    "#             l.append(sub_data1)\n",
    "#         try:\n",
    "#             pool_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list) - 1)\n",
    "#         except:\n",
    "#             pool_data = np.squeeze(np.array(l)).reshape(-1,1,feat_num,len(step_list) - 1)\n",
    "#         return torch.from_numpy(pool_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python383",
   "language": "python",
   "name": "python383"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
