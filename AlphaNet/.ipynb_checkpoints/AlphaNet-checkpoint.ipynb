{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T06:22:03.715745Z",
     "start_time": "2021-11-18T06:22:01.126705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vwap</th>\n",
       "      <th>volume</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>turnover</th>\n",
       "      <th>free_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190923</td>\n",
       "      <td>1</td>\n",
       "      <td>15.34</td>\n",
       "      <td>15.47</td>\n",
       "      <td>15.18</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.3122</td>\n",
       "      <td>1403282.00</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>1.5038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190923</td>\n",
       "      <td>2</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.15</td>\n",
       "      <td>26.1471</td>\n",
       "      <td>603530.46</td>\n",
       "      <td>-2.4254</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>1.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190923</td>\n",
       "      <td>4</td>\n",
       "      <td>20.36</td>\n",
       "      <td>20.65</td>\n",
       "      <td>19.61</td>\n",
       "      <td>20.04</td>\n",
       "      <td>20.0171</td>\n",
       "      <td>29893.32</td>\n",
       "      <td>-4.7076</td>\n",
       "      <td>3.6188</td>\n",
       "      <td>5.9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190923</td>\n",
       "      <td>5</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.2947</td>\n",
       "      <td>111437.30</td>\n",
       "      <td>-2.0772</td>\n",
       "      <td>1.0533</td>\n",
       "      <td>1.3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190923</td>\n",
       "      <td>6</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.2993</td>\n",
       "      <td>136997.47</td>\n",
       "      <td>1.1278</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>1.5887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958151</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688168</td>\n",
       "      <td>52.80</td>\n",
       "      <td>53.30</td>\n",
       "      <td>52.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>52.5581</td>\n",
       "      <td>5919.73</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>2.0771</td>\n",
       "      <td>2.1589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958162</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688188</td>\n",
       "      <td>446.80</td>\n",
       "      <td>449.00</td>\n",
       "      <td>425.20</td>\n",
       "      <td>438.14</td>\n",
       "      <td>438.5992</td>\n",
       "      <td>4444.64</td>\n",
       "      <td>-1.6830</td>\n",
       "      <td>1.6540</td>\n",
       "      <td>1.6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958216</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688321</td>\n",
       "      <td>39.20</td>\n",
       "      <td>39.30</td>\n",
       "      <td>38.64</td>\n",
       "      <td>38.90</td>\n",
       "      <td>38.8391</td>\n",
       "      <td>14252.01</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.5631</td>\n",
       "      <td>0.6717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958221</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688333</td>\n",
       "      <td>199.87</td>\n",
       "      <td>201.01</td>\n",
       "      <td>192.01</td>\n",
       "      <td>200.34</td>\n",
       "      <td>196.4810</td>\n",
       "      <td>4126.57</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.9092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958246</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688388</td>\n",
       "      <td>136.00</td>\n",
       "      <td>136.85</td>\n",
       "      <td>130.45</td>\n",
       "      <td>134.93</td>\n",
       "      <td>134.5550</td>\n",
       "      <td>61087.12</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>3.6459</td>\n",
       "      <td>3.9295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1772680 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  ticker    open    high     low   close      vwap  \\\n",
       "0         20190923       1   15.34   15.47   15.18   15.38   15.3122   \n",
       "1         20190923       2   26.49   26.49   26.00   26.15   26.1471   \n",
       "2         20190923       4   20.36   20.65   19.61   20.04   20.0171   \n",
       "3         20190923       5    3.37    3.37    3.27    3.30    3.2947   \n",
       "4         20190923       6    5.34    5.40    5.21    5.38    5.2993   \n",
       "...            ...     ...     ...     ...     ...     ...       ...   \n",
       "1958151   20210923  688168   52.80   53.30   52.00   52.45   52.5581   \n",
       "1958162   20210923  688188  446.80  449.00  425.20  438.14  438.5992   \n",
       "1958216   20210923  688321   39.20   39.30   38.64   38.90   38.8391   \n",
       "1958221   20210923  688333  199.87  201.01  192.01  200.34  196.4810   \n",
       "1958246   20210923  688388  136.00  136.85  130.45  134.93  134.5550   \n",
       "\n",
       "             volume  pct_chg  turnover  free_turnover  \n",
       "0        1403282.00   0.2608    0.7428         1.5038  \n",
       "1         603530.46  -2.4254    0.6212         1.0882  \n",
       "2          29893.32  -4.7076    3.6188         5.9394  \n",
       "3         111437.30  -2.0772    1.0533         1.3495  \n",
       "4         136997.47   1.1278    1.0161         1.5887  \n",
       "...             ...      ...       ...            ...  \n",
       "1958151     5919.73   1.0792    2.0771         2.1589  \n",
       "1958162     4444.64  -1.6830    1.6540         1.6540  \n",
       "1958216    14252.01   0.0772    0.5631         0.6717  \n",
       "1958221     4126.57   0.6177    0.9092         0.9092  \n",
       "1958246    61087.12   0.3272    3.6459         3.9295  \n",
       "\n",
       "[1772680 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('alphanet_codetest_daily.csv')\n",
    "# 定义数据图片开始和结束的时间\n",
    "time_start = 20190801\n",
    "time_end = 20211001\n",
    "\n",
    "\n",
    "stock = pd.DataFrame(data.groupby('ticker')['timestamp'].count() == 487).reset_index()\n",
    "merge = data.merge(stock, on='ticker', how='left')\n",
    "merge = merge[merge['timestamp_y'] == True]\n",
    "merge['timestamp'] = merge['timestamp_x']\n",
    "merge = merge[['timestamp','ticker','open','high','low','close','vwap','volume','pct_chg','turnover','free_turnover']] # feature\n",
    "merge = merge[(merge['timestamp'] >= time_start) & (merge['timestamp'] <= time_end)]\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:17:43.436843Z",
     "start_time": "2021-11-18T09:17:43.419901Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateC(l1):\n",
    "    if len(l1) == 1:\n",
    "        return []\n",
    "    v = [[l1[0],i] for i in l1[1:]]\n",
    "    l1 = l1[1:]\n",
    "    return v+generateC(l1)\n",
    "def generate_Num_and_ReversedNum(feat_nums):\n",
    "    list1 = list(range(feat_nums))\n",
    "    num = generateC(list1)\n",
    "    num_rev = []\n",
    "    for l in num:\n",
    "        l1 = l.copy()\n",
    "        l1.reverse()\n",
    "        num_rev.append(l1)\n",
    "    return num , num_rev\n",
    "def data_info(data,stride):\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length = data.shape[3] # 30\n",
    "    feat_num = data.shape[2] # 9\n",
    "    \"\"\"num:组合数对列表,num_rev:num的翻转列表\"\"\"\n",
    "    num , num_rev = generate_Num_and_ReversedNum(feat_num)\n",
    "    conv_feat = len(num)\n",
    "    # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "    if data_length % stride == 0:\n",
    "        step_list = list(range(0,data_length+stride,stride))\n",
    "    elif data_length % stride<=5:\n",
    "        mod = data_length % stride\n",
    "        step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "    else:\n",
    "        mod = data_length % stride\n",
    "        step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "    return data_length,feat_num,conv_feat,num,num_rev,step_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T06:30:05.264658Z",
     "start_time": "2021-11-18T06:29:46.527912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xinfei\\AppData\\Local\\Temp/ipykernel_16008/4237832295.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  one_data['pct_change_shift'] = (one_data['close'].shift(-day_back) - one_data['close']) / one_data['close'] * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  (553277, 1, 9, 30)\n",
      "y.shape:  (553277, 1)\n"
     ]
    }
   ],
   "source": [
    "day_back = 3 # 回溯几天进行计算\n",
    "day = 30 # 一次提取几天的数,一般默认为30\n",
    "stride = 10 # 一次学习多少天\n",
    "\n",
    "\n",
    "x , y , x_delay = [] , [], [] # 初始数据集\n",
    "\n",
    "for count , ticker in enumerate(merge['ticker'].drop_duplicates()):\n",
    "#     print(count)\n",
    "    one_data = merge[merge['ticker'] == ticker]\n",
    "    one_data['pct_change_shift'] = (one_data['close'].shift(-day_back) - one_data['close']) / one_data['close'] * 100\n",
    "    one_data = one_data.set_index(['timestamp','ticker'])\n",
    "    one_data = one_data.dropna() # 丢弃因为回溯而产生的空值\n",
    "    array = np.array(one_data)\n",
    "\n",
    "    for i in range(0,array.shape[0] - day ,3): # 其中3 代表取数的步长，ex.每两天取一次数，步长为3\n",
    "        x.append(array[i:i+day,:-1].T)\n",
    "        y.append(array[i+day-1][-1])\n",
    "x  , y = np.array(x) , np.array(y).reshape(-1,1) # x = (153, 9, 30) , y = (153,1)\n",
    "x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2]) # x = (153, 1, 9, 30)\n",
    "print(\"x.shape: \",x.shape)\n",
    "print(\"y.shape: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:17:46.204896Z",
     "start_time": "2021-11-18T09:17:46.188004Z"
    }
   },
   "outputs": [],
   "source": [
    "data_length,feat_num,conv_feat,num,num_rev,step_list = data_info(x,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:18:08.107275Z",
     "start_time": "2021-11-18T09:18:08.091789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T06:30:20.312426Z",
     "start_time": "2021-11-18T06:30:14.751673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500000, 1, 9, 30])\n",
      "1 torch.Size([53277, 1, 9, 30])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# x = np.random.uniform(10,100,(3124,1,9,30))\n",
    "# y = np.random.randn(3124,1)\n",
    "class Testdataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.label = torch.from_numpy(label)\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "trainset = Testdataset(x,y)\n",
    "trainloader = DataLoader(trainset,batch_size = 500000,shuffle = False)\n",
    "for i,data in enumerate(trainloader):\n",
    "    input_data,label = data\n",
    "    print(i,input_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T08:54:24.868832Z",
     "start_time": "2021-11-18T08:54:19.198544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for data,label in trainloader:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtraction(object):\n",
    "    def __init__(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        self.data = np.array(data)\n",
    "        self.stride = stride\n",
    "        self.data_length = data.shape[3]\n",
    "        self.feat_num = data.shape[2] # 9\n",
    "        self.num , self.num_rev = generate_Num_and_ReversedNum(self.feat_num)\n",
    "        self.conv_feat = len(self.num)\n",
    "        self.step_list = self.generate_Step_List(self.data_length,self.stride)\n",
    "        self.extracted_data = self.Extraction(self.data,self.feat_num,self.conv_feat,self.stride)\n",
    "    def Extraction(self,data,feat_num,conv_feat,stride):\n",
    "        batch = nn.BatchNorm1d(conv_feat,affine=True)\n",
    "        batch2 = nn.BatchNorm1d(feat_num,affine=True)\n",
    "        conv1 = self.ts_cov4d(self.data,self.stride,self.num,self.num_rev,self.step_list).to(torch.float)\n",
    "        bc1 = batch(conv1)\n",
    "        conv2 = self.ts_corr4d(self.data,self.stride,self.num,self.num_rev,self.step_list).to(torch.float)\n",
    "        bc2 = batch(conv2)\n",
    "        conv3 = ts_stddev4d(data,stride).to(torch.float)\n",
    "        bc3 = batch2(conv3)\n",
    "        conv4 = ts_zscore(data,stride).to(torch.float)\n",
    "        bc4 = batch2(conv4)\n",
    "        conv5 = ts_return(data,stride).to(torch.float)\n",
    "        bc5 = batch2(conv5)\n",
    "        conv6 = ts_decaylinear(data,stride).to(torch.float)\n",
    "        bc6 = batch2(conv6)\n",
    "\n",
    "        feat_cat = torch.cat([bc1,bc2,bc3,bc4,bc5,bc6],axis = 1) # 特征聚合\n",
    "        shape = feat_cat.shape\n",
    "        feat_cat = feat_cat.reshape(shape[0],1,shape[1],shape[2])\n",
    "        # Pooling\n",
    "        ts_max = ts_pool(feat_cat,3,method = 'max')\n",
    "        ts_max = nn.BatchNorm1d(108,affine = True)(ts_max)\n",
    "        ts_min = ts_pool(feat_cat ,3,method = 'min')\n",
    "        ts_min = nn.BatchNorm1d(108,affine = True)(ts_min)\n",
    "        ts_mean = ts_pool(feat_cat ,3,method = 'mean')\n",
    "        ts_mean = nn.BatchNorm1d(108,affine = True)(ts_mean)\n",
    "        data_pool = torch.cat([ts_max,ts_min,ts_mean],axis = 1)\n",
    "        data_pool.shape\n",
    "        data_pool = data_pool.flatten(start_dim = 1)\n",
    "        return data_pool\n",
    "    def generateC(self,l1):\n",
    "        if len(l1) == 1:\n",
    "            return []\n",
    "        v = [[l1[0],i] for i in l1[1:]]\n",
    "        l1 = l1[1:]\n",
    "        return v+generateC(l1)\n",
    "    def generate_Num_and_ReversedNum(self,feat_nums):\n",
    "        list1 = list(range(feat_nums))\n",
    "        num = generateC(list1)\n",
    "        num_rev = []\n",
    "        for l in num:\n",
    "            l1 = l.copy()\n",
    "            l1.reverse()\n",
    "            num_rev.append(l1)\n",
    "        return num , num_rev\n",
    "    def generate_Step_List(self,data_length,stride):\n",
    "        # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "        if data_length % stride == 0:\n",
    "            step_list = list(range(0,data_length+stride,stride))\n",
    "        elif data_length % stride<=5:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "        else:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "        return step_list\n",
    "    def ts_cov4d(self,data,stride,num,num_rev,step_list):\n",
    "        '''计算4维数据的协方差'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        l = []\n",
    "        #计算的过程中务必保持keepdims=True\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,num,start:end] # (2000, 1, 36, 2, 10)\n",
    "            sub_data2 = data[:,:,num_rev,start:end]\n",
    "            mean1 = sub_data1.mean(axis = 4,keepdims = True) # (2000, 1, 36, 2, 1)\n",
    "            mean2 = sub_data2.mean(axis = 4,keepdims = True)\n",
    "            spread1 = sub_data1 - mean1 # (2000, 1, 36, 2, 10)\n",
    "            spread2 = sub_data2 - mean2\n",
    "            cov = ((spread1*spread2).sum(axis = 4,keepdims = True)/(sub_data1.shape[4] - 1)).mean(axis = 3,keepdims = True) # (2000, 1, 36, 1, 1)\n",
    "            l.append(cov)\n",
    "        corr = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,self.conv_feat,len(step_list)-1) # (2000, 1, 36, 3)\n",
    "        return torch.from_numpy(corr)\n",
    "    def ts_corr4d(self,data,stride,num,num_rev,step_list):\n",
    "        '''计算4维数据的相关系数'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,num,start:end]\n",
    "            sub_data2 = data[:,:,num_rev,start:end]\n",
    "            std1 = sub_data1.std(axis = 4,keepdims = True)\n",
    "            std2 = sub_data2.std(axis = 4,keepdims = True)\n",
    "            std = (std1*std2).mean(axis = 3,keepdims = True)\n",
    "            l.append(std)\n",
    "        std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,self.conv_feat,len(step_list)-1)\n",
    "        cov = self.ts_cov4d(data,stride,num,num_rev,step_list)\n",
    "        fct = (sub_data1.shape[4]-1)/sub_data1.shape[4]\n",
    "        return (cov/torch.from_numpy(std))*fct\n",
    "    def ts_stddev4d(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            std1 = sub_data1.std(axis = 3,keepdims = True)\n",
    "            l.append(std1)\n",
    "        std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        return torch.from_numpy(std)\n",
    "    def ts_zscore(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            mean = sub_data1.mean(axis = 3,keepdims = True)\n",
    "            std = sub_data1.std(axis = 3,keepdims = True)\n",
    "            z_score = mean/std\n",
    "            l.append(z_score)\n",
    "        z_score = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        return torch.from_numpy(z_score)\n",
    "    def ts_return(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        data[data == 0] = 1e-9\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            ret = sub_data1[:,:,:,-1]/sub_data1[:,:,:,0] - 1\n",
    "            l.append(ret)\n",
    "        z_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        z_data[z_data > 1] = 1\n",
    "        return torch.from_numpy(z_data)\n",
    "    def ts_decaylinear(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            time_spread = end - start\n",
    "            weight = np.arange(1,time_spread+1)\n",
    "            weight = weight/(weight.sum())\n",
    "            sub_data1 = (data[:,:,:,start:end]*weight).mean(axis = 3,keepdims = True)\n",
    "            l.append(sub_data1)\n",
    "        decay_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        return torch.from_numpy(decay_data)\n",
    "    def ts_pool(self,data,stride,method):\n",
    "        if type(data) == torch.Tensor:\n",
    "            data = data.detach().numpy()\n",
    "        if data.shape[-1] <= stride:\n",
    "            step_list = [0,data.shape[-1]]\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            if method == 'max':\n",
    "                sub_data1 = data[:,:,:,start:end].max(axis = 3,keepdims = True)\n",
    "            if method == 'min':\n",
    "                sub_data1 = data[:,:,:,start:end].min(axis = 3,keepdims = True)\n",
    "            if method == 'mean':\n",
    "                sub_data1 = data[:,:,:,start:end].mean(axis = 3,keepdims = True)\n",
    "            l.append(sub_data1)\n",
    "        try:\n",
    "            pool_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list) - 1)\n",
    "        except:\n",
    "            pool_data = np.squeeze(np.array(l)).reshape(-1,feat_num,len(step_list) - 1)\n",
    "        return torch.from_numpy(pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self,factor_num,fully_connect_layer_neural):\n",
    "        \"\"\" factor_num : 因子个数\n",
    "            fully_connect_layer_neural: 全连接层神经元的数量\n",
    "        \"\"\"\n",
    "        super(AlphaNet,self).__init__()\n",
    "        self.fc1_neuron = factor_num * (factor_num -1) + 3 * factor_num\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.batchnorm = nn.BatchNorm2d(1,affine=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self.fc1_neuron,self.fc2_neuron)\n",
    "        self.out = nn.Linear(self.fc2_neuron,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,data,num,num_rev):\n",
    "        # Conv\n",
    "        conv1 = self.ts_cov4d(data,10).to(torch.float)\n",
    "        sigmoid1 = torch.sigmoid(conv1)\n",
    "        bc1 = self.batchnorm(sigmoid1)\n",
    "        conv2 = self.ts_corr4d(data,10).to(torch.float)\n",
    "        bc2 = self.batchnorm(conv2)\n",
    "        conv3 = self.ts_stddev4d(data,10).to(torch.float)\n",
    "        sigmoid3 = torch.sigmoid(conv3)\n",
    "        bc3 = self.batchnorm(sigmoid3)\n",
    "        conv4 = self.ts_decaylinear(data,10).to(torch.float)\n",
    "        sigmoid4 = torch.sigmoid(conv4)\n",
    "        bc4 = self.batchnorm(sigmoid4)\n",
    "        conv5 = self.ts_zscore(data,10).to(torch.float)\n",
    "        bc5 = self.batchnorm(conv5)\n",
    "        data_conv = torch.cat([bc1,bc2,bc3,bc4,bc5],axis = 2)\n",
    "        # Pooling\n",
    "        ts_max = self.ts_pool(data_conv,3,method = 'max')\n",
    "        ts_max = self.batchnorm(ts_max)\n",
    "        ts_min = self.ts_pool(data_conv,3,method = 'min')\n",
    "        ts_min = self.batchnorm(ts_min)\n",
    "        ts_mean = self.ts_pool(data_conv,3,method = 'mean')\n",
    "        ts_mean = self.batchnorm(ts_mean)\n",
    "        data_fin = torch.cat([ts_max,ts_min,ts_mean],axis = 2)\n",
    "        data_fin = data_fin.flatten(start_dim = 1)\n",
    "        input_size = data_fin.size(1)\n",
    "        ful_connect = self.dropout(self.relu(self.fc1(data_fin)))\n",
    "        output = self.out(ful_connect)\n",
    "        return output.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:40:57.596472Z",
     "start_time": "2021-11-18T09:40:57.566191Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self,factor_num,fully_connect_layer_neural):\n",
    "        \"\"\" factor_num : 因子个数\n",
    "            fully_connect_layer_neural: 全连接层神经元的数量\n",
    "        \"\"\"\n",
    "        super(AlphaNet,self).__init__()\n",
    "        self.fc1_neuron = factor_num * (factor_num -1) + 3 * factor_num\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.batchnorm = nn.BatchNorm2d(1,affine=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self.fc1_neuron,self.fc2_neuron)\n",
    "        self.out = nn.Linear(self.fc2_neuron,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,data,num,num_rev):\n",
    "        # Conv\n",
    "        conv1 = self.ts_cov4d(data,10).to(torch.float)\n",
    "        sigmoid1 = torch.sigmoid(conv1)\n",
    "        bc1 = self.batchnorm(sigmoid1)\n",
    "        conv2 = self.ts_corr4d(data,10).to(torch.float)\n",
    "        bc2 = self.batchnorm(conv2)\n",
    "        conv3 = self.ts_stddev4d(data,10).to(torch.float)\n",
    "        sigmoid3 = torch.sigmoid(conv3)\n",
    "        bc3 = self.batchnorm(sigmoid3)\n",
    "        conv4 = self.ts_decaylinear(data,10).to(torch.float)\n",
    "        sigmoid4 = torch.sigmoid(conv4)\n",
    "        bc4 = self.batchnorm(sigmoid4)\n",
    "        conv5 = self.ts_zscore(data,10).to(torch.float)\n",
    "        bc5 = self.batchnorm(conv5)\n",
    "        data_conv = torch.cat([bc1,bc2,bc3,bc4,bc5],axis = 2)\n",
    "        # Pooling\n",
    "        ts_max = self.ts_pool(data_conv,3,method = 'max')\n",
    "        ts_max = self.batchnorm(ts_max)\n",
    "        ts_min = self.ts_pool(data_conv,3,method = 'min')\n",
    "        ts_min = self.batchnorm(ts_min)\n",
    "        ts_mean = self.ts_pool(data_conv,3,method = 'mean')\n",
    "        ts_mean = self.batchnorm(ts_mean)\n",
    "        data_fin = torch.cat([ts_max,ts_min,ts_mean],axis = 2)\n",
    "        data_fin = data_fin.flatten(start_dim = 1)\n",
    "        input_size = data_fin.size(1)\n",
    "        ful_connect = self.dropout(self.relu(self.fc1(data_fin)))\n",
    "        output = self.out(ful_connect)\n",
    "        return output.to(torch.float)\n",
    "    # 为了cov 和 corr提取并行计算产生计算列表\n",
    "    def generateC(l1):\n",
    "        if len(l1) == 1:\n",
    "            return []\n",
    "        v = [[l1[0],i] for i in l1[1:]]\n",
    "        l1 = l1[1:]\n",
    "        return v+generateC(l1)\n",
    "    def generate_Num_and_ReversedNum(feat_nums):\n",
    "        list1 = list(range(feat_nums))\n",
    "        num = generateC(list1)\n",
    "        num_rev = []\n",
    "        for l in num:\n",
    "            l1 = l.copy()\n",
    "            l1.reverse()\n",
    "            num_rev.append(l1)\n",
    "        return num , num_rev\n",
    "    def data_info(data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length = data.shape[3] # 30\n",
    "        feat_num = data.shape[2] # 9\n",
    "        \"\"\"num:组合数对列表,num_rev:num的翻转列表\"\"\"\n",
    "        num , num_rev = generate_Num_and_ReversedNum(feat_num)\n",
    "        conv_feat = len(num)\n",
    "        # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "        if data_length % stride == 0:\n",
    "            step_list = list(range(0,data_length+stride,stride))\n",
    "        elif data_length % stride<=5:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "        else:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "        return data_length,feat_num,conv_feat,num,num_rev,step_list\n",
    "    def ts_cov4d(self,data,stride):\n",
    "        '''计算4维数据的协方差'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        #计算的过程中务必保持keepdims=True\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,num,start:end] # (2000, 1, 36, 2, 10)\n",
    "            sub_data2 = data[:,:,num_rev,start:end]\n",
    "            mean1 = sub_data1.mean(axis = 4,keepdims = True) # (2000, 1, 36, 2, 1)\n",
    "            mean2 = sub_data2.mean(axis = 4,keepdims = True)\n",
    "            spread1 = sub_data1 - mean1 # (2000, 1, 36, 2, 10)\n",
    "            spread2 = sub_data2 - mean2\n",
    "            cov = ((spread1*spread2).sum(axis = 4,keepdims = True)/(sub_data1.shape[4] - 1)).mean(axis = 3,keepdims = True) # (2000, 1, 36, 1, 1)\n",
    "            l.append(cov)\n",
    "        corr = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,conv_feat,len(step_list)-1) # (2000, 1, 36, 3)\n",
    "        return torch.from_numpy(corr)\n",
    "    def ts_corr4d(self,data,stride):\n",
    "        '''计算4维数据的相关系数'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,num,start:end]\n",
    "            sub_data2 = data[:,:,num_rev,start:end]\n",
    "            std1 = sub_data1.std(axis = 4,keepdims = True)\n",
    "            std2 = sub_data2.std(axis = 4,keepdims = True)\n",
    "            std = (std1*std2).mean(axis = 3,keepdims = True)\n",
    "            l.append(std)\n",
    "        std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,conv_feat,len(step_list)-1)\n",
    "        cov = self.ts_cov4d(data,stride)\n",
    "        fct = (sub_data1.shape[4]-1)/sub_data1.shape[4]\n",
    "        return (cov/torch.from_numpy(std))*fct\n",
    "    def ts_stddev4d(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            std1 = sub_data1.std(axis = 3,keepdims = True)\n",
    "            l.append(std1)\n",
    "        std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "        return torch.from_numpy(std)\n",
    "    def ts_zscore(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            mean = sub_data1.mean(axis = 3,keepdims = True)\n",
    "            std = sub_data1.std(axis = 3,keepdims = True)\n",
    "            z_score = mean/std\n",
    "            l.append(z_score)\n",
    "        z_score = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "        return torch.from_numpy(z_score)\n",
    "    def ts_decaylinear(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            time_spread = end - start\n",
    "            weight = np.arange(1,time_spread+1)\n",
    "            weight = weight/(weight.sum())\n",
    "            sub_data1 = (data[:,:,:,start:end]*weight).mean(axis = 3,keepdims = True)\n",
    "            l.append(sub_data1)\n",
    "        decay_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "        return torch.from_numpy(decay_data)\n",
    "    def ts_pool(self,data,stride,method):\n",
    "        if type(data) == torch.Tensor:\n",
    "            data = data.detach().numpy()\n",
    "        if data.shape[-1] <= stride:\n",
    "            step_list = [0,data.shape[-1]]\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            if method == 'max':\n",
    "                sub_data1 = data[:,:,:,start:end].max(axis = 3,keepdims = True)\n",
    "            if method == 'min':\n",
    "                sub_data1 = data[:,:,:,start:end].min(axis = 3,keepdims = True)\n",
    "            if method == 'mean':\n",
    "                sub_data1 = data[:,:,:,start:end].mean(axis = 3,keepdims = True)\n",
    "            l.append(sub_data1)\n",
    "        try:\n",
    "            pool_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list) - 1)\n",
    "        except:\n",
    "            pool_data = np.squeeze(np.array(l)).reshape(-1,1,feat_num,len(step_list) - 1)\n",
    "        return torch.from_numpy(pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:42:34.018194Z",
     "start_time": "2021-11-18T09:40:57.963592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet(\n",
      "  (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=99, out_features=30, bias=True)\n",
      "  (out): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xinfei\\AppData\\Local\\Temp/ipykernel_16008/986201398.py:144: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z_score = mean/std\n",
      "C:\\Users\\Xinfei\\AppData\\Local\\Temp/ipykernel_16008/986201398.py:144: RuntimeWarning: invalid value encountered in true_divide\n",
      "  z_score = mean/std\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (500000x297 and 99x30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16008/947512202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mout_put\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malphanet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_rev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_put\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\python383\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16008/986201398.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data, num, num_rev)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mdata_fin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_fin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0minput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_fin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mful_connect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mful_connect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\python383\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\python383\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\python383\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (500000x297 and 99x30)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "alphanet = AlphaNet(9,30)\n",
    "print(alphanet)\n",
    "criterion = nn.MSELoss()\n",
    "LR = 0.0001\n",
    "optimizer = optim.RMSprop(alphanet.parameters(), lr=LR, alpha=0.9)\n",
    "epoch_num = 20\n",
    "loss_list = []\n",
    "for epoch in range(epoch_num ):\n",
    "    train_loss = 0.0\n",
    "    for data,label in trainloader:\n",
    "        out_put = alphanet(data.detach().numpy(),num,num_rev)\n",
    "        loss = criterion(out_put,label.to(torch.float))\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(train_loss.item())\n",
    "    print(\"current epoch time:\",epoch+1,\"  Loss: \",train_loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python383",
   "language": "python",
   "name": "python383"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
