{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T07:19:18.373899Z",
     "start_time": "2021-11-23T07:19:14.133827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vwap</th>\n",
       "      <th>volume</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>turnover</th>\n",
       "      <th>free_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190923</td>\n",
       "      <td>1</td>\n",
       "      <td>15.34</td>\n",
       "      <td>15.47</td>\n",
       "      <td>15.18</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.3122</td>\n",
       "      <td>1403282.00</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>1.5038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190923</td>\n",
       "      <td>2</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.15</td>\n",
       "      <td>26.1471</td>\n",
       "      <td>603530.46</td>\n",
       "      <td>-2.4254</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>1.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190923</td>\n",
       "      <td>4</td>\n",
       "      <td>20.36</td>\n",
       "      <td>20.65</td>\n",
       "      <td>19.61</td>\n",
       "      <td>20.04</td>\n",
       "      <td>20.0171</td>\n",
       "      <td>29893.32</td>\n",
       "      <td>-4.7076</td>\n",
       "      <td>3.6188</td>\n",
       "      <td>5.9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190923</td>\n",
       "      <td>5</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.2947</td>\n",
       "      <td>111437.30</td>\n",
       "      <td>-2.0772</td>\n",
       "      <td>1.0533</td>\n",
       "      <td>1.3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190923</td>\n",
       "      <td>6</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.2993</td>\n",
       "      <td>136997.47</td>\n",
       "      <td>1.1278</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>1.5887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958151</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688168</td>\n",
       "      <td>52.80</td>\n",
       "      <td>53.30</td>\n",
       "      <td>52.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>52.5581</td>\n",
       "      <td>5919.73</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>2.0771</td>\n",
       "      <td>2.1589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958162</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688188</td>\n",
       "      <td>446.80</td>\n",
       "      <td>449.00</td>\n",
       "      <td>425.20</td>\n",
       "      <td>438.14</td>\n",
       "      <td>438.5992</td>\n",
       "      <td>4444.64</td>\n",
       "      <td>-1.6830</td>\n",
       "      <td>1.6540</td>\n",
       "      <td>1.6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958216</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688321</td>\n",
       "      <td>39.20</td>\n",
       "      <td>39.30</td>\n",
       "      <td>38.64</td>\n",
       "      <td>38.90</td>\n",
       "      <td>38.8391</td>\n",
       "      <td>14252.01</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.5631</td>\n",
       "      <td>0.6717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958221</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688333</td>\n",
       "      <td>199.87</td>\n",
       "      <td>201.01</td>\n",
       "      <td>192.01</td>\n",
       "      <td>200.34</td>\n",
       "      <td>196.4810</td>\n",
       "      <td>4126.57</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.9092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958246</th>\n",
       "      <td>20210923</td>\n",
       "      <td>688388</td>\n",
       "      <td>136.00</td>\n",
       "      <td>136.85</td>\n",
       "      <td>130.45</td>\n",
       "      <td>134.93</td>\n",
       "      <td>134.5550</td>\n",
       "      <td>61087.12</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>3.6459</td>\n",
       "      <td>3.9295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1772680 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  ticker    open    high     low   close      vwap  \\\n",
       "0         20190923       1   15.34   15.47   15.18   15.38   15.3122   \n",
       "1         20190923       2   26.49   26.49   26.00   26.15   26.1471   \n",
       "2         20190923       4   20.36   20.65   19.61   20.04   20.0171   \n",
       "3         20190923       5    3.37    3.37    3.27    3.30    3.2947   \n",
       "4         20190923       6    5.34    5.40    5.21    5.38    5.2993   \n",
       "...            ...     ...     ...     ...     ...     ...       ...   \n",
       "1958151   20210923  688168   52.80   53.30   52.00   52.45   52.5581   \n",
       "1958162   20210923  688188  446.80  449.00  425.20  438.14  438.5992   \n",
       "1958216   20210923  688321   39.20   39.30   38.64   38.90   38.8391   \n",
       "1958221   20210923  688333  199.87  201.01  192.01  200.34  196.4810   \n",
       "1958246   20210923  688388  136.00  136.85  130.45  134.93  134.5550   \n",
       "\n",
       "             volume  pct_chg  turnover  free_turnover  \n",
       "0        1403282.00   0.2608    0.7428         1.5038  \n",
       "1         603530.46  -2.4254    0.6212         1.0882  \n",
       "2          29893.32  -4.7076    3.6188         5.9394  \n",
       "3         111437.30  -2.0772    1.0533         1.3495  \n",
       "4         136997.47   1.1278    1.0161         1.5887  \n",
       "...             ...      ...       ...            ...  \n",
       "1958151     5919.73   1.0792    2.0771         2.1589  \n",
       "1958162     4444.64  -1.6830    1.6540         1.6540  \n",
       "1958216    14252.01   0.0772    0.5631         0.6717  \n",
       "1958221     4126.57   0.6177    0.9092         0.9092  \n",
       "1958246    61087.12   0.3272    3.6459         3.9295  \n",
       "\n",
       "[1772680 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "data = pd.read_csv('alphanet_codetest_daily.csv')\n",
    "# 定义数据图片开始和结束的时间\n",
    "time_start = 20190801\n",
    "time_end = 20211001\n",
    "\n",
    "\n",
    "stock = pd.DataFrame(data.groupby('ticker')['timestamp'].count() == 487).reset_index()\n",
    "merge = data.merge(stock, on='ticker', how='left')\n",
    "merge = merge[merge['timestamp_y'] == True]\n",
    "merge['timestamp'] = merge['timestamp_x']\n",
    "merge = merge[['timestamp','ticker','open','high','low','close','vwap','volume','pct_chg','turnover','free_turnover']] # feature\n",
    "merge = merge[(merge['timestamp'] >= time_start) & (merge['timestamp'] <= time_end)]\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:17:43.436843Z",
     "start_time": "2021-11-18T09:17:43.419901Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateC(l1):\n",
    "    if len(l1) == 1:\n",
    "        return []\n",
    "    v = [[l1[0],i] for i in l1[1:]]\n",
    "    l1 = l1[1:]\n",
    "    return v+generateC(l1)\n",
    "def generate_Num_and_ReversedNum(feat_nums):\n",
    "    list1 = list(range(feat_nums))\n",
    "    num = generateC(list1)\n",
    "    num_rev = []\n",
    "    for l in num:\n",
    "        l1 = l.copy()\n",
    "        l1.reverse()\n",
    "        num_rev.append(l1)\n",
    "    return num , num_rev\n",
    "def data_info(data,stride):\n",
    "    if len(data.shape)!=4:\n",
    "        raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "    data_length = data.shape[3] # 30\n",
    "    feat_num = data.shape[2] # 9\n",
    "    \"\"\"num:组合数对列表,num_rev:num的翻转列表\"\"\"\n",
    "    num , num_rev = generate_Num_and_ReversedNum(feat_num)\n",
    "    conv_feat = len(num)\n",
    "    # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "    if data_length % stride == 0:\n",
    "        step_list = list(range(0,data_length+stride,stride))\n",
    "    elif data_length % stride<=5:\n",
    "        mod = data_length % stride\n",
    "        step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "    else:\n",
    "        mod = data_length % stride\n",
    "        step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "    return data_length,feat_num,conv_feat,num,num_rev,step_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T07:19:37.731098Z",
     "start_time": "2021-11-23T07:19:18.640312Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xinfei\\AppData\\Local\\Temp/ipykernel_13480/2247197430.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  one_data['pct_change_shift'] = (one_data['close'].shift(-day_back) - one_data['close']) / one_data['close'] * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  (553277, 1, 9, 30)\n",
      "y.shape:  (553277, 1)\n"
     ]
    }
   ],
   "source": [
    "day_back = 3 # 回溯几天进行计算\n",
    "day = 30 # 一次提取几天的数,一般默认为30\n",
    "stride = 10 # 一次学习多少天\n",
    "\n",
    "\n",
    "x , y , x_delay = [] , [], [] # 初始数据集\n",
    "\n",
    "for count , ticker in enumerate(merge['ticker'].drop_duplicates()):\n",
    "#     print(count)\n",
    "    one_data = merge[merge['ticker'] == ticker]\n",
    "    one_data['pct_change_shift'] = (one_data['close'].shift(-day_back) - one_data['close']) / one_data['close'] * 100\n",
    "    one_data = one_data.set_index(['timestamp','ticker'])\n",
    "    one_data = one_data.dropna() # 丢弃因为回溯而产生的空值\n",
    "    array = np.array(one_data)\n",
    "\n",
    "    for i in range(0,array.shape[0] - day ,3): # 其中3 代表取数的步长，ex.每两天取一次数，步长为3\n",
    "        x.append(array[i:i+day,:-1].T)\n",
    "        y.append(array[i+day-1][-1])\n",
    "x  , y = np.array(x) , np.array(y).reshape(-1,1) # x = (153, 9, 30) , y = (153,1)\n",
    "x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2]) # x = (153, 1, 9, 30)\n",
    "print(\"x.shape: \",x.shape)\n",
    "print(\"y.shape: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T07:49:15.745003Z",
     "start_time": "2021-11-23T07:49:10.064698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500000, 1, 9, 30])\n",
      "1 torch.Size([53277, 1, 9, 30])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T07:26:07.825577Z",
     "start_time": "2021-11-23T07:26:07.713574Z"
    }
   },
   "outputs": [],
   "source": [
    "class Convolutional(object):\n",
    "    def __init__(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        self.data = np.array(data)\n",
    "        self.stride = stride\n",
    "        self.data_length = data.shape[3]\n",
    "        self.feat_num = data.shape[2] # 9\n",
    "        self.num , self.num_rev = self.generate_Num_and_ReversedNum(self.feat_num)\n",
    "        self.conv_feat = len(self.num)\n",
    "        self.step_list = self.generate_Step_List(self.data_length,self.stride)\n",
    "        self.extracted_data = self.Extraction(self.data,self.feat_num,self.conv_feat,self.stride)\n",
    "    def Extraction(self,data,feat_num,conv_feat,stride):\n",
    "        print(\"------Start Extraction------\")\n",
    "        batch = nn.BatchNorm1d(conv_feat,affine=True)\n",
    "        batch2 = nn.BatchNorm1d(feat_num,affine=True)\n",
    "        conv1 = self.ts_cov4d(self.data,self.stride,self.num,self.num_rev,self.step_list).to(torch.float)\n",
    "        bc1 = batch(conv1)\n",
    "        conv2 = self.ts_corr4d(self.data,self.stride,self.num,self.num_rev,self.step_list).to(torch.float)\n",
    "        bc2 = batch(conv2)\n",
    "        conv3 = self.ts_stddev4d(self.data,self.stride,self.feat_num,self.step_list).to(torch.float)\n",
    "        bc3 = batch2(conv3)\n",
    "        conv4 = self.ts_zscore(self.data,self.stride,self.feat_num,self.step_list).to(torch.float)\n",
    "        bc4 = batch2(conv4)\n",
    "        conv5 = self.ts_return(self.data,self.stride,self.feat_num,self.step_list).to(torch.float)\n",
    "        bc5 = batch2(conv5)\n",
    "        conv6 = self.ts_decaylinear(self.data,self.stride,self.feat_num,self.step_list).to(torch.float)\n",
    "        bc6 = batch2(conv6)\n",
    "\n",
    "        feat_cat = torch.cat([bc1,bc2,bc3,bc4,bc5,bc6],axis = 1) # 特征聚合\n",
    "        shape = feat_cat.shape\n",
    "        feat_cat = feat_cat.reshape(shape[0],1,shape[1],shape[2])\n",
    "        print(\"Convolutional shape: \", feat_cat.shape)\n",
    "        return feat_cat\n",
    "    def generateC(self,l1):\n",
    "        if len(l1) == 1:\n",
    "            return []\n",
    "        v = [[l1[0],i] for i in l1[1:]]\n",
    "        l1 = l1[1:]\n",
    "        return v+ self.generateC(l1)\n",
    "    def generate_Num_and_ReversedNum(self,feat_nums):\n",
    "        list1 = list(range(feat_nums))\n",
    "        num = self.generateC(list1)\n",
    "        num_rev = []\n",
    "        for l in num:\n",
    "            l1 = l.copy()\n",
    "            l1.reverse()\n",
    "            num_rev.append(l1)\n",
    "        return num , num_rev\n",
    "    def generate_Step_List(self,data_length,stride):\n",
    "        # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "        if data_length % stride == 0:\n",
    "            step_list = list(range(0,data_length+stride,stride))\n",
    "        elif data_length % stride<=5:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "        else:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "        return step_list\n",
    "    def ts_cov4d(self,data,stride,num,num_rev,step_list):\n",
    "        '''计算4维数据的协方差'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        l = []\n",
    "        #计算的过程中务必保持keepdims=True\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,num,start:end] # (2000, 1, 36, 2, 10)\n",
    "            sub_data2 = data[:,:,num_rev,start:end]\n",
    "            mean1 = sub_data1.mean(axis = 4,keepdims = True) # (2000, 1, 36, 2, 1)\n",
    "            mean2 = sub_data2.mean(axis = 4,keepdims = True)\n",
    "            spread1 = sub_data1 - mean1 # (2000, 1, 36, 2, 10)\n",
    "            spread2 = sub_data2 - mean2\n",
    "            cov = ((spread1*spread2).sum(axis = 4,keepdims = True)/(sub_data1.shape[4] - 1)).mean(axis = 3,keepdims = True) # (2000, 1, 36, 1, 1)\n",
    "            l.append(cov)\n",
    "        corr = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,self.conv_feat,len(step_list)-1) # (2000, 1, 36, 3)\n",
    "        final = torch.from_numpy(corr)\n",
    "        print(\"------Finished ts_cov4d----output shape: \",final.shape)\n",
    "        return final\n",
    "    def ts_corr4d(self,data,stride,num,num_rev,step_list):\n",
    "        '''计算4维数据的相关系数'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,num,start:end]\n",
    "            sub_data2 = data[:,:,num_rev,start:end]\n",
    "            std1 = sub_data1.std(axis = 4,keepdims = True)\n",
    "            std2 = sub_data2.std(axis = 4,keepdims = True)\n",
    "            std = (std1*std2).mean(axis = 3,keepdims = True)\n",
    "            l.append(std)\n",
    "        std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,self.conv_feat,len(step_list)-1)\n",
    "        cov = self.ts_cov4d(data,stride,num,num_rev,step_list)\n",
    "        fct = (sub_data1.shape[4]-1)/sub_data1.shape[4]\n",
    "        final = (cov/torch.from_numpy(std))*fct\n",
    "        print(\"------Finished ts_corr4d----output shape: \",final.shape)\n",
    "        return final\n",
    "    def ts_stddev4d(self,data,stride,feat_num,step_list):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            std1 = sub_data1.std(axis = 3,keepdims = True)\n",
    "            l.append(std1)\n",
    "        std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        final = torch.from_numpy(std)\n",
    "        print(\"------Finished ts_stddev4d----output shape: \",final.shape)\n",
    "        return final\n",
    "    def ts_zscore(self,data,stride,feat_num,step_list):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            mean = sub_data1.mean(axis = 3,keepdims = True)\n",
    "            std = sub_data1.std(axis = 3,keepdims = True)\n",
    "            std[std == 0] = 1e-9\n",
    "            z_score = mean/std\n",
    "            l.append(z_score)\n",
    "        z_score = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        z_score[z_score >= 6] = 6\n",
    "        final = torch.from_numpy(z_score)\n",
    "        print(\"------Finished ts_zscore----output shape: \",final.shape)\n",
    "        return final\n",
    "    def ts_return(self,data,stride,feat_num,step_list):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data[data == 0] = 1e-9\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            sub_data1 = data[:,:,:,start:end]\n",
    "            ret = sub_data1[:,:,:,-1]/sub_data1[:,:,:,0] - 1\n",
    "            l.append(ret)\n",
    "        z_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        z_data[z_data > 1] = 1\n",
    "        final = torch.from_numpy(z_data)\n",
    "        print(\"------Finished ts_return----output shape: \",final.shape)\n",
    "        return final\n",
    "    def ts_decaylinear(self,data,stride,feat_num,step_list):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            time_spread = end - start\n",
    "            weight = np.arange(1,time_spread+1)\n",
    "            weight = weight/(weight.sum())\n",
    "            sub_data1 = (data[:,:,:,start:end]*weight).mean(axis = 3,keepdims = True)\n",
    "            l.append(sub_data1)\n",
    "        decay_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list)-1)\n",
    "        final = torch.from_numpy(decay_data)\n",
    "        print(\"------Finished ts_decaylinear----output shape: \",final.shape)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T07:35:05.679431Z",
     "start_time": "2021-11-23T07:35:05.665080Z"
    }
   },
   "outputs": [],
   "source": [
    "class Pooling(object):\n",
    "    def __init__(self,data,stride):\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        self.data = data.detach().numpy()\n",
    "        self.stride = stride\n",
    "        self.data_length = data.shape[3]\n",
    "        self.feat_num = data.shape[2] # 9\n",
    "        self.step_list = self.generate_Step_List(self.data_length,self.stride)\n",
    "        self.extracted_data = self.Extraction(self.data,self.feat_num,self.stride)\n",
    "    def Extraction(self,data,feat_num,stride):\n",
    "        print(\"------Start Pooling------\")\n",
    "        # Pooling\n",
    "        ts_max = self.ts_pool(feat_cat,self.stride,self.feat_num,self.step_list,method = 'max')\n",
    "        ts_max = nn.BatchNorm1d(108,affine = True)(ts_max)\n",
    "        ts_min = self.ts_pool(feat_cat ,self.stride,self.feat_num,self.step_list,method = 'min')\n",
    "        ts_min = nn.BatchNorm1d(108,affine = True)(ts_min)\n",
    "        ts_mean = self.ts_pool(feat_cat ,self.stride,self.feat_num,self.step_list,method = 'mean')\n",
    "        ts_mean = nn.BatchNorm1d(108,affine = True)(ts_mean)\n",
    "        data_pool = torch.cat([ts_max,ts_min,ts_mean],axis = 1)\n",
    "        data_pool = data_pool.flatten(start_dim = 1)\n",
    "        print(\"Pooling shape: \",data_pool.shape )\n",
    "        return data_pool\n",
    "    def generate_Step_List(self,data_length,stride):\n",
    "        # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "        if data_length % stride == 0:\n",
    "            step_list = list(range(0,data_length+stride,stride))\n",
    "        elif data_length % stride<=5:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "        else:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "        return step_list\n",
    "    def ts_pool(self,data,stride,feat_num,step_list,method):\n",
    "        if type(data) == torch.Tensor:\n",
    "            data = data.detach().numpy()\n",
    "        if data.shape[-1] <= stride:\n",
    "            step_list = [0,data.shape[-1]]\n",
    "        if len(data.shape)!=4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in range(len(step_list)-1):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i+1]\n",
    "            if method == 'max':\n",
    "                sub_data1 = data[:,:,:,start:end].max(axis = 3,keepdims = True)\n",
    "            if method == 'min':\n",
    "                sub_data1 = data[:,:,:,start:end].min(axis = 3,keepdims = True)\n",
    "            if method == 'mean':\n",
    "                sub_data1 = data[:,:,:,start:end].mean(axis = 3,keepdims = True)\n",
    "            l.append(sub_data1)\n",
    "        try:\n",
    "            pool_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,feat_num,len(step_list) - 1)\n",
    "        except:\n",
    "            pool_data = np.squeeze(np.array(l)).reshape(-1,feat_num,len(step_list) - 1)\n",
    "        return torch.from_numpy(pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T07:27:26.945257Z",
     "start_time": "2021-11-23T07:26:08.031014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Extraction------\n",
      "------Finished ts_cov4d----output shape:  torch.Size([553277, 36, 3])\n",
      "------Finished ts_cov4d----output shape:  torch.Size([553277, 36, 3])\n",
      "------Finished ts_corr4d----output shape:  torch.Size([553277, 36, 3])\n",
      "------Finished ts_stddev4d----output shape:  torch.Size([553277, 9, 3])\n",
      "------Finished ts_zscore----output shape:  torch.Size([553277, 9, 3])\n",
      "------Finished ts_return----output shape:  torch.Size([553277, 9, 3])\n",
      "------Finished ts_decaylinear----output shape:  torch.Size([553277, 9, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0293, -0.0297, -0.0300],\n",
       "          [-0.0289, -0.0295, -0.0296],\n",
       "          [-0.0267, -0.0275, -0.0276],\n",
       "          ...,\n",
       "          [ 1.0405,  0.0309, -0.2105],\n",
       "          [-0.6095, -0.6385, -0.6729],\n",
       "          [-0.4510, -0.4643, -0.4939]]],\n",
       "\n",
       "\n",
       "        [[[-0.0273, -0.0302, -0.0295],\n",
       "          [-0.0274, -0.0299, -0.0291],\n",
       "          [-0.0252, -0.0278, -0.0271],\n",
       "          ...,\n",
       "          [ 0.4642, -0.3460, -0.4206],\n",
       "          [-0.6190, -0.6597, -0.6927],\n",
       "          [-0.4621, -0.4813, -0.5171]]],\n",
       "\n",
       "\n",
       "        [[[-0.0285, -0.0300, -0.0295],\n",
       "          [-0.0282, -0.0297, -0.0292],\n",
       "          [-0.0265, -0.0276, -0.0271],\n",
       "          ...,\n",
       "          [ 0.2850,  0.1975, -0.2451],\n",
       "          [-0.6309, -0.6641, -0.7205],\n",
       "          [-0.4745, -0.4834, -0.5499]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0862,  0.1368,  0.0555],\n",
       "          [ 0.0856,  0.2772,  0.0539],\n",
       "          [ 0.0712,  0.1389,  0.0632],\n",
       "          ...,\n",
       "          [ 0.8861,  1.7153,  1.5340],\n",
       "          [ 0.6498,  0.3044,  0.3005],\n",
       "          [ 0.1520, -0.0424, -0.0446]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4287,  0.2017,  0.1211],\n",
       "          [ 0.4494,  0.2587,  0.1173],\n",
       "          [ 0.3822,  0.2551,  0.0937],\n",
       "          ...,\n",
       "          [ 2.4399,  0.9777,  0.3860],\n",
       "          [ 0.7595,  0.0741,  0.3169],\n",
       "          [ 0.2137, -0.1720, -0.0353]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2652,  0.0493,  0.0500],\n",
       "          [ 0.3215,  0.1189,  0.0803],\n",
       "          [ 0.2125,  0.0413,  0.0308],\n",
       "          ...,\n",
       "          [ 0.2213, -0.4516,  0.9947],\n",
       "          [ 0.4617,  0.1007,  0.3846],\n",
       "          [ 0.0461, -0.1570,  0.0028]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutional = Convolutional(x,10)\n",
    "feat_cat = convolutional.extracted_data\n",
    "pooling = Pooling(feat_cat,3)\n",
    "x = pooling.extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# x = np.random.uniform(10,100,(3124,1,9,30))\n",
    "# y = np.random.randn(3124,1)\n",
    "class Testdataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.label = torch.from_numpy(label)\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "trainset = Testdataset(x,y)\n",
    "trainloader = DataLoader(trainset,batch_size = 500000,shuffle = False)\n",
    "for i,data in enumerate(trainloader):\n",
    "    input_data,label = data\n",
    "    print(i,input_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T07:48:39.326734Z",
     "start_time": "2021-11-23T07:48:39.316789Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self，factor_num，fully_connect_layer_neural):\n",
    "        # super 父类，调用父类的构造，这一步必须有\n",
    "        # 第一个参数为定义类的名称，第二个为self\n",
    "        super(LinerModel,self).__init__()\n",
    "         \n",
    "        self.fc1_neuron = (factor_num * (factor_num -1) + 4 * factor_num)* 3\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(fc1_neuron,fc2_neuron)\n",
    "        self.out = nn.Linear(self.fc2_neuron,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T08:04:47.900750Z",
     "start_time": "2021-11-23T08:04:47.888810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=324, out_features=30, bias=True)\n",
      "  (out): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "alphanet = AlphaNet(9,30)\n",
    "print(alphanet)\n",
    "criterion = nn.MSELoss()\n",
    "LR = 0.0001\n",
    "optimizer = optim.RMSprop(alphanet.parameters(), lr=LR, alpha=0.9)\n",
    "epoch_num = 20\n",
    "loss_list = []\n",
    "for epoch in range(epoch_num ):\n",
    "    train_loss = 0.0\n",
    "    for data,label in trainloader:\n",
    "        out_put = alphanet(data.detach().numpy())\n",
    "        loss = criterion(out_put,label.to(torch.float))\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(train_loss.item())\n",
    "    print(\"current epoch time:\",epoch+1,\"  Loss: \",train_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T09:40:57.596472Z",
     "start_time": "2021-11-18T09:40:57.566191Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "\n",
    "\n",
    "# class AlphaNet(nn.Module):\n",
    "#     def __init__(self,factor_num,fully_connect_layer_neural):\n",
    "#         \"\"\" factor_num : 因子个数\n",
    "#             fully_connect_layer_neural: 全连接层神经元的数量\n",
    "#         \"\"\"\n",
    "#         super(AlphaNet,self).__init__()\n",
    "#         self.fc1_neuron = (factor_num * (factor_num -1) + 4 * factor_num)* 3\n",
    "#         self.fc2_neuron = fully_connect_layer_neural\n",
    "#         self.batchnorm = nn.BatchNorm2d(1,affine=True)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(self.fc1_neuron,self.fc2_neuron)\n",
    "#         self.out = nn.Linear(self.fc2_neuron,1)\n",
    "#         self.relu = nn.ReLU()\n",
    "#     def forward(self,data,num,num_rev):\n",
    "#         # Conv\n",
    "#         conv1 = self.ts_cov4d(data,10).to(torch.float)\n",
    "#         sigmoid1 = torch.sigmoid(conv1)\n",
    "#         bc1 = self.batchnorm(sigmoid1)\n",
    "#         conv2 = self.ts_corr4d(data,10).to(torch.float)\n",
    "#         bc2 = self.batchnorm(conv2)\n",
    "#         conv3 = self.ts_stddev4d(data,10).to(torch.float)\n",
    "#         sigmoid3 = torch.sigmoid(conv3)\n",
    "#         bc3 = self.batchnorm(sigmoid3)\n",
    "#         conv4 = self.ts_decaylinear(data,10).to(torch.float)\n",
    "#         sigmoid4 = torch.sigmoid(conv4)\n",
    "#         bc4 = self.batchnorm(sigmoid4)\n",
    "#         conv5 = self.ts_zscore(data,10).to(torch.float)\n",
    "#         bc5 = self.batchnorm(conv5)\n",
    "#         data_conv = torch.cat([bc1,bc2,bc3,bc4,bc5],axis = 2)\n",
    "#         # Pooling\n",
    "#         ts_max = self.ts_pool(data_conv,3,method = 'max')\n",
    "#         ts_max = self.batchnorm(ts_max)\n",
    "#         ts_min = self.ts_pool(data_conv,3,method = 'min')\n",
    "#         ts_min = self.batchnorm(ts_min)\n",
    "#         ts_mean = self.ts_pool(data_conv,3,method = 'mean')\n",
    "#         ts_mean = self.batchnorm(ts_mean)\n",
    "#         data_fin = torch.cat([ts_max,ts_min,ts_mean],axis = 2)\n",
    "#         data_fin = data_fin.flatten(start_dim = 1)\n",
    "#         input_size = data_fin.size(1)\n",
    "#         ful_connect = self.dropout(self.relu(self.fc1(data_fin)))\n",
    "#         output = self.out(ful_connect)\n",
    "#         return output.to(torch.float)\n",
    "#     # 为了cov 和 corr提取并行计算产生计算列表\n",
    "#     def generateC(l1):\n",
    "#         if len(l1) == 1:\n",
    "#             return []\n",
    "#         v = [[l1[0],i] for i in l1[1:]]\n",
    "#         l1 = l1[1:]\n",
    "#         return v+generateC(l1)\n",
    "#     def generate_Num_and_ReversedNum(feat_nums):\n",
    "#         list1 = list(range(feat_nums))\n",
    "#         num = generateC(list1)\n",
    "#         num_rev = []\n",
    "#         for l in num:\n",
    "#             l1 = l.copy()\n",
    "#             l1.reverse()\n",
    "#             num_rev.append(l1)\n",
    "#         return num , num_rev\n",
    "#     def data_info(data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length = data.shape[3] # 30\n",
    "#         feat_num = data.shape[2] # 9\n",
    "#         \"\"\"num:组合数对列表,num_rev:num的翻转列表\"\"\"\n",
    "#         num , num_rev = generate_Num_and_ReversedNum(feat_num)\n",
    "#         conv_feat = len(num)\n",
    "#         # 构建步长列表，如果数据长度不能整除，则取剩下长度，如果剩下长度小于5，则与上一步结合一起\n",
    "#         if data_length % stride == 0:\n",
    "#             step_list = list(range(0,data_length+stride,stride))\n",
    "#         elif data_length % stride<=5:\n",
    "#             mod = data_length % stride\n",
    "#             step_list = list(range(0,data_length-stride,stride))+[data_length]\n",
    "#         else:\n",
    "#             mod = data_length % stride\n",
    "#             step_list = list(range(0,data_length+stride-mod,stride))+[data_length]\n",
    "#         return data_length,feat_num,conv_feat,num,num_rev,step_list\n",
    "#     def ts_cov4d(self,data,stride):\n",
    "#         '''计算4维数据的协方差'''\n",
    "#         '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         #计算的过程中务必保持keepdims=True\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,num,start:end] # (2000, 1, 36, 2, 10)\n",
    "#             sub_data2 = data[:,:,num_rev,start:end]\n",
    "#             mean1 = sub_data1.mean(axis = 4,keepdims = True) # (2000, 1, 36, 2, 1)\n",
    "#             mean2 = sub_data2.mean(axis = 4,keepdims = True)\n",
    "#             spread1 = sub_data1 - mean1 # (2000, 1, 36, 2, 10)\n",
    "#             spread2 = sub_data2 - mean2\n",
    "#             cov = ((spread1*spread2).sum(axis = 4,keepdims = True)/(sub_data1.shape[4] - 1)).mean(axis = 3,keepdims = True) # (2000, 1, 36, 1, 1)\n",
    "#             l.append(cov)\n",
    "#         corr = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,conv_feat,len(step_list)-1) # (2000, 1, 36, 3)\n",
    "#         return torch.from_numpy(corr)\n",
    "#     def ts_corr4d(self,data,stride):\n",
    "#         '''计算4维数据的相关系数'''\n",
    "#         '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,num,start:end]\n",
    "#             sub_data2 = data[:,:,num_rev,start:end]\n",
    "#             std1 = sub_data1.std(axis = 4,keepdims = True)\n",
    "#             std2 = sub_data2.std(axis = 4,keepdims = True)\n",
    "#             std = (std1*std2).mean(axis = 3,keepdims = True)\n",
    "#             l.append(std)\n",
    "#         std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,conv_feat,len(step_list)-1)\n",
    "#         cov = self.ts_cov4d(data,stride)\n",
    "#         fct = (sub_data1.shape[4]-1)/sub_data1.shape[4]\n",
    "#         return (cov/torch.from_numpy(std))*fct\n",
    "#     def ts_stddev4d(self,data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,:,start:end]\n",
    "#             std1 = sub_data1.std(axis = 3,keepdims = True)\n",
    "#             l.append(std1)\n",
    "#         std = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "#         return torch.from_numpy(std)\n",
    "#     def ts_zscore(self,data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             sub_data1 = data[:,:,:,start:end]\n",
    "#             mean = sub_data1.mean(axis = 3,keepdims = True)\n",
    "#             std = sub_data1.std(axis = 3,keepdims = True)\n",
    "#             z_score = mean/std\n",
    "#             l.append(z_score)\n",
    "#         z_score = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "#         return torch.from_numpy(z_score)\n",
    "#     def ts_decaylinear(self,data,stride):\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             time_spread = end - start\n",
    "#             weight = np.arange(1,time_spread+1)\n",
    "#             weight = weight/(weight.sum())\n",
    "#             sub_data1 = (data[:,:,:,start:end]*weight).mean(axis = 3,keepdims = True)\n",
    "#             l.append(sub_data1)\n",
    "#         decay_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list)-1)\n",
    "#         return torch.from_numpy(decay_data)\n",
    "#     def ts_pool(self,data,stride,method):\n",
    "#         if type(data) == torch.Tensor:\n",
    "#             data = data.detach().numpy()\n",
    "#         if data.shape[-1] <= stride:\n",
    "#             step_list = [0,data.shape[-1]]\n",
    "#         if len(data.shape)!=4:\n",
    "#             raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "#         data_length , feat_num , conv_feat, num , num_rev,step_list= data_info(data,stride)\n",
    "#         l = []\n",
    "#         for i in range(len(step_list)-1):\n",
    "#             start = step_list[i]\n",
    "#             end = step_list[i+1]\n",
    "#             if method == 'max':\n",
    "#                 sub_data1 = data[:,:,:,start:end].max(axis = 3,keepdims = True)\n",
    "#             if method == 'min':\n",
    "#                 sub_data1 = data[:,:,:,start:end].min(axis = 3,keepdims = True)\n",
    "#             if method == 'mean':\n",
    "#                 sub_data1 = data[:,:,:,start:end].mean(axis = 3,keepdims = True)\n",
    "#             l.append(sub_data1)\n",
    "#         try:\n",
    "#             pool_data = np.squeeze(np.array(l)).transpose(1,2,0).reshape(-1,1,feat_num,len(step_list) - 1)\n",
    "#         except:\n",
    "#             pool_data = np.squeeze(np.array(l)).reshape(-1,1,feat_num,len(step_list) - 1)\n",
    "#         return torch.from_numpy(pool_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python383",
   "language": "python",
   "name": "python383"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
