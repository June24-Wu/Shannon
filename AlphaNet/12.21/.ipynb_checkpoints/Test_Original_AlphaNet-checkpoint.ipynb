{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6c7e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T01:29:08.800927Z",
     "start_time": "2021-12-21T01:29:06.883532Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from progressbar import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12fa8df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T01:29:25.341117Z",
     "start_time": "2021-12-21T01:29:25.309350Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 166746.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2015-01-01_2015-03-01.par',\n",
       " '2015-03-01_2015-06-01.par',\n",
       " '2015-06-01_2015-09-01.par',\n",
       " '2015-09-01_2016-01-01.par',\n",
       " '2016-01-01_2016-03-01.par',\n",
       " '2016-03-01_2016-06-01.par',\n",
       " '2016-06-01_2016-09-01.par',\n",
       " '2016-09-01_2017-01-01.par',\n",
       " '2017-01-01_2017-03-01.par',\n",
       " '2017-03-01_2017-06-01.par',\n",
       " '2017-06-01_2017-09-01.par',\n",
       " '2017-09-01_2018-01-01.par',\n",
       " '2018-01-01_2018-03-01.par',\n",
       " '2018-03-01_2018-06-01.par',\n",
       " '2018-06-01_2018-09-01.par',\n",
       " '2018-09-01_2019-01-01.par',\n",
       " '2019-01-01_2019-03-01.par',\n",
       " '2019-03-01_2019-06-01.par',\n",
       " '2019-06-01_2019-09-01.par',\n",
       " '2019-09-01_2020-01-01.par',\n",
       " '2020-01-01_2020-03-01.par',\n",
       " '2020-03-01_2020-06-01.par',\n",
       " '2020-06-01_2020-09-01.par',\n",
       " '2020-09-01_2021-01-01.par',\n",
       " '2021-01-01_2021-03-01.par',\n",
       " '2021-03-01_2021-06-01.par']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_list = []\n",
    "path = \"/home/wuwenjun/Data/AlphaNet_Original_Input_12.14/\"\n",
    "data_path = path + \"Data/\"\n",
    "dataframe_list = pd.DataFrame()\n",
    "for f, _, i in walk(data_path):\n",
    "    for j in tqdm(i):\n",
    "        time_list.append(j)\n",
    "time_list.sort()     \n",
    "time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af85ab8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T01:30:10.953616Z",
     "start_time": "2021-12-21T01:30:10.043261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ticker</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-03-02 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1056.57</td>\n",
       "      <td>1069.36</td>\n",
       "      <td>1030.28</td>\n",
       "      <td>1049.46</td>\n",
       "      <td>1048.958727</td>\n",
       "      <td>1553290.86</td>\n",
       "      <td>-2.0557</td>\n",
       "      <td>1.5791</td>\n",
       "      <td>...</td>\n",
       "      <td>999.02</td>\n",
       "      <td>1006.12</td>\n",
       "      <td>991.91</td>\n",
       "      <td>994.04</td>\n",
       "      <td>998.467965</td>\n",
       "      <td>793570.14</td>\n",
       "      <td>-0.5686</td>\n",
       "      <td>0.8067</td>\n",
       "      <td>1.5996</td>\n",
       "      <td>-0.039914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-03-03 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1040.94</td>\n",
       "      <td>1058.70</td>\n",
       "      <td>1038.09</td>\n",
       "      <td>1043.07</td>\n",
       "      <td>1048.127398</td>\n",
       "      <td>816874.77</td>\n",
       "      <td>-0.6093</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>...</td>\n",
       "      <td>996.88</td>\n",
       "      <td>1001.15</td>\n",
       "      <td>985.51</td>\n",
       "      <td>996.88</td>\n",
       "      <td>992.861827</td>\n",
       "      <td>1018797.00</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>1.0357</td>\n",
       "      <td>2.0536</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-03-04 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1050.17</td>\n",
       "      <td>1080.02</td>\n",
       "      <td>1044.49</td>\n",
       "      <td>1052.31</td>\n",
       "      <td>1062.856831</td>\n",
       "      <td>1263029.64</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>1.2840</td>\n",
       "      <td>...</td>\n",
       "      <td>993.33</td>\n",
       "      <td>993.33</td>\n",
       "      <td>965.62</td>\n",
       "      <td>966.33</td>\n",
       "      <td>977.343699</td>\n",
       "      <td>1059476.29</td>\n",
       "      <td>-3.0649</td>\n",
       "      <td>1.0771</td>\n",
       "      <td>2.1356</td>\n",
       "      <td>0.012482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-03-05 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1055.15</td>\n",
       "      <td>1090.67</td>\n",
       "      <td>1045.20</td>\n",
       "      <td>1090.67</td>\n",
       "      <td>1068.974555</td>\n",
       "      <td>1242170.32</td>\n",
       "      <td>3.6462</td>\n",
       "      <td>1.2628</td>\n",
       "      <td>...</td>\n",
       "      <td>967.75</td>\n",
       "      <td>974.86</td>\n",
       "      <td>959.23</td>\n",
       "      <td>964.20</td>\n",
       "      <td>966.138529</td>\n",
       "      <td>814973.04</td>\n",
       "      <td>-0.2206</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>1.6427</td>\n",
       "      <td>0.051852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-03-06 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1094.23</td>\n",
       "      <td>1109.86</td>\n",
       "      <td>1078.60</td>\n",
       "      <td>1092.10</td>\n",
       "      <td>1097.580776</td>\n",
       "      <td>1555846.33</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>1.5817</td>\n",
       "      <td>...</td>\n",
       "      <td>959.23</td>\n",
       "      <td>961.36</td>\n",
       "      <td>944.30</td>\n",
       "      <td>950.70</td>\n",
       "      <td>951.110671</td>\n",
       "      <td>828604.85</td>\n",
       "      <td>-1.4001</td>\n",
       "      <td>0.8424</td>\n",
       "      <td>1.6702</td>\n",
       "      <td>0.114435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084595</th>\n",
       "      <td>2015-05-25 09:30:00</td>\n",
       "      <td>603869</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.780000</td>\n",
       "      <td>4018.00</td>\n",
       "      <td>10.0176</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>...</td>\n",
       "      <td>35.81</td>\n",
       "      <td>38.40</td>\n",
       "      <td>34.16</td>\n",
       "      <td>37.47</td>\n",
       "      <td>36.109200</td>\n",
       "      <td>160994.72</td>\n",
       "      <td>5.1052</td>\n",
       "      <td>29.7807</td>\n",
       "      <td>29.7807</td>\n",
       "      <td>0.184948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084596</th>\n",
       "      <td>2015-05-26 09:30:00</td>\n",
       "      <td>603869</td>\n",
       "      <td>20.66</td>\n",
       "      <td>20.66</td>\n",
       "      <td>20.66</td>\n",
       "      <td>20.66</td>\n",
       "      <td>20.660000</td>\n",
       "      <td>7902.89</td>\n",
       "      <td>10.0106</td>\n",
       "      <td>1.4619</td>\n",
       "      <td>...</td>\n",
       "      <td>37.47</td>\n",
       "      <td>41.22</td>\n",
       "      <td>35.40</td>\n",
       "      <td>41.22</td>\n",
       "      <td>39.505000</td>\n",
       "      <td>148059.99</td>\n",
       "      <td>10.0080</td>\n",
       "      <td>27.3881</td>\n",
       "      <td>27.3881</td>\n",
       "      <td>0.042755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084597</th>\n",
       "      <td>2015-05-27 09:30:00</td>\n",
       "      <td>603869</td>\n",
       "      <td>22.73</td>\n",
       "      <td>22.73</td>\n",
       "      <td>22.73</td>\n",
       "      <td>22.73</td>\n",
       "      <td>22.730000</td>\n",
       "      <td>12550.00</td>\n",
       "      <td>10.0194</td>\n",
       "      <td>2.3215</td>\n",
       "      <td>...</td>\n",
       "      <td>42.10</td>\n",
       "      <td>45.34</td>\n",
       "      <td>41.68</td>\n",
       "      <td>45.34</td>\n",
       "      <td>43.759500</td>\n",
       "      <td>124814.65</td>\n",
       "      <td>9.9951</td>\n",
       "      <td>23.0882</td>\n",
       "      <td>23.0882</td>\n",
       "      <td>-0.141776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084598</th>\n",
       "      <td>2015-05-28 09:30:00</td>\n",
       "      <td>603869</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>110751.34</td>\n",
       "      <td>9.9868</td>\n",
       "      <td>20.4867</td>\n",
       "      <td>...</td>\n",
       "      <td>48.88</td>\n",
       "      <td>49.87</td>\n",
       "      <td>45.51</td>\n",
       "      <td>49.87</td>\n",
       "      <td>48.565200</td>\n",
       "      <td>111196.68</td>\n",
       "      <td>9.9912</td>\n",
       "      <td>20.5691</td>\n",
       "      <td>20.5691</td>\n",
       "      <td>-0.217903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084599</th>\n",
       "      <td>2015-05-29 09:30:00</td>\n",
       "      <td>603869</td>\n",
       "      <td>24.50</td>\n",
       "      <td>27.50</td>\n",
       "      <td>23.52</td>\n",
       "      <td>27.50</td>\n",
       "      <td>26.186600</td>\n",
       "      <td>288583.12</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>53.3820</td>\n",
       "      <td>...</td>\n",
       "      <td>53.51</td>\n",
       "      <td>54.86</td>\n",
       "      <td>44.88</td>\n",
       "      <td>44.90</td>\n",
       "      <td>53.317900</td>\n",
       "      <td>158381.54</td>\n",
       "      <td>-9.9659</td>\n",
       "      <td>29.2974</td>\n",
       "      <td>29.2974</td>\n",
       "      <td>-0.025579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165509 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  ticker        0        1        2        3  \\\n",
       "5       2015-03-02 09:30:00       1  1056.57  1069.36  1030.28  1049.46   \n",
       "6       2015-03-03 09:30:00       1  1040.94  1058.70  1038.09  1043.07   \n",
       "7       2015-03-04 09:30:00       1  1050.17  1080.02  1044.49  1052.31   \n",
       "8       2015-03-05 09:30:00       1  1055.15  1090.67  1045.20  1090.67   \n",
       "9       2015-03-06 09:30:00       1  1094.23  1109.86  1078.60  1092.10   \n",
       "...                     ...     ...      ...      ...      ...      ...   \n",
       "4084595 2015-05-25 09:30:00  603869    18.78    18.78    18.78    18.78   \n",
       "4084596 2015-05-26 09:30:00  603869    20.66    20.66    20.66    20.66   \n",
       "4084597 2015-05-27 09:30:00  603869    22.73    22.73    22.73    22.73   \n",
       "4084598 2015-05-28 09:30:00  603869    25.00    25.00    25.00    25.00   \n",
       "4084599 2015-05-29 09:30:00  603869    24.50    27.50    23.52    27.50   \n",
       "\n",
       "                   4           5        6        7  ...     261      262  \\\n",
       "5        1048.958727  1553290.86  -2.0557   1.5791  ...  999.02  1006.12   \n",
       "6        1048.127398   816874.77  -0.6093   0.8304  ...  996.88  1001.15   \n",
       "7        1062.856831  1263029.64   0.8856   1.2840  ...  993.33   993.33   \n",
       "8        1068.974555  1242170.32   3.6462   1.2628  ...  967.75   974.86   \n",
       "9        1097.580776  1555846.33   0.1303   1.5817  ...  959.23   961.36   \n",
       "...              ...         ...      ...      ...  ...     ...      ...   \n",
       "4084595    18.780000     4018.00  10.0176   0.7432  ...   35.81    38.40   \n",
       "4084596    20.660000     7902.89  10.0106   1.4619  ...   37.47    41.22   \n",
       "4084597    22.730000    12550.00  10.0194   2.3215  ...   42.10    45.34   \n",
       "4084598    25.000000   110751.34   9.9868  20.4867  ...   48.88    49.87   \n",
       "4084599    26.186600   288583.12  10.0000  53.3820  ...   53.51    54.86   \n",
       "\n",
       "            263     264         265         266      267      268      269  \\\n",
       "5        991.91  994.04  998.467965   793570.14  -0.5686   0.8067   1.5996   \n",
       "6        985.51  996.88  992.861827  1018797.00   0.2859   1.0357   2.0536   \n",
       "7        965.62  966.33  977.343699  1059476.29  -3.0649   1.0771   2.1356   \n",
       "8        959.23  964.20  966.138529   814973.04  -0.2206   0.8285   1.6427   \n",
       "9        944.30  950.70  951.110671   828604.85  -1.4001   0.8424   1.6702   \n",
       "...         ...     ...         ...         ...      ...      ...      ...   \n",
       "4084595   34.16   37.47   36.109200   160994.72   5.1052  29.7807  29.7807   \n",
       "4084596   35.40   41.22   39.505000   148059.99  10.0080  27.3881  27.3881   \n",
       "4084597   41.68   45.34   43.759500   124814.65   9.9951  23.0882  23.0882   \n",
       "4084598   45.51   49.87   48.565200   111196.68   9.9912  20.5691  20.5691   \n",
       "4084599   44.88   44.90   53.317900   158381.54  -9.9659  29.2974  29.2974   \n",
       "\n",
       "           target  \n",
       "5       -0.039914  \n",
       "6        0.001431  \n",
       "7        0.012482  \n",
       "8        0.051852  \n",
       "9        0.114435  \n",
       "...           ...  \n",
       "4084595  0.184948  \n",
       "4084596  0.042755  \n",
       "4084597 -0.141776  \n",
       "4084598 -0.217903  \n",
       "4084599 -0.025579  \n",
       "\n",
       "[165509 rows x 273 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(data_path+time_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af06909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self, factor_num, fully_connect_layer_neural):\n",
    "        super(AlphaNet, self).__init__()\n",
    "        self.fc1_neuron = (factor_num * (factor_num - 1) + 4 * factor_num) * 3\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.fc1 = torch.nn.Linear(self.fc1_neuron, self.fc2_neuron)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(self.fc2_neuron, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414ca857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:11:46.802092Z",
     "start_time": "2021-12-09T07:10:25.395682Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:21<00:00, 10.16s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_train_data(time_start, time_end):\n",
    "#     train_frame = dataframe_list[dataframe_list['timestamp'] < pd.to_datetime(str(time_start))]\n",
    "    train_frame = dataframe_list[(dataframe_list['timestamp'] > pd.to_datetime(str(20200630)))\n",
    "                                & (dataframe_list['timestamp'] < pd.to_datetime(str(time_start)))]\n",
    "    train_frame.set_index([\"timestamp\", \"ticker\"], inplace=True)\n",
    "\n",
    "    # Train X and Train Y\n",
    "    trainx, trainy = [], []\n",
    "    trainx = np.array(train_frame.drop(\"target\", axis=1))\n",
    "    trainx = trainx.reshape(trainx.shape[0], 1, day, -1)  # x = (153,1,30,9)\n",
    "    trainx = trainx.transpose(0, 1, 3, 2)  # x = (2555577, 1, 9, 30)\n",
    "    trainy = np.array(train_frame['target']).reshape(-1, 1)  # x = (153,1,9,30)\n",
    "\n",
    "    feat_num = trainx.shape[2]  # 9\n",
    "    del train_frame\n",
    "    print(\"trainx.shape: \", trainx.shape)\n",
    "    print(\"trainy.shape: \", trainy.shape)\n",
    "    return trainx, trainy, feat_num\n",
    "\n",
    "\n",
    "def get_test_data(time_start, time_end):\n",
    "    test_frame = dataframe_list[(dataframe_list['timestamp'] > pd.to_datetime(str(time_start)))\n",
    "                                & (dataframe_list['timestamp'] < pd.to_datetime(str(time_end)))]\n",
    "    test_frame.set_index([\"timestamp\", \"ticker\"], inplace=True)\n",
    "\n",
    "    # Test X and Test Y\n",
    "\n",
    "    test_target = pd.DataFrame(test_frame['target'])\n",
    "    testy = np.array(test_target).reshape(-1, 1)\n",
    "\n",
    "    testx = np.array(test_frame.drop(\"target\", axis=1))\n",
    "    testx = testx.reshape(testx.shape[0], 1, day, -1)  # x = (153,1,30,9)\n",
    "    testx = testx.transpose(0, 1, 3, 2)  # x = (2555577, 1, 9, 30)\n",
    "    del test_frame\n",
    "\n",
    "    print(\"testx.shape: \", testx.shape)\n",
    "    print(\"testy.shape: \", testy.shape)\n",
    "    test_target.reset_index(inplace=True)\n",
    "    return testx, testy, test_target\n",
    "\n",
    "output_path = \"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/\"\n",
    "day = 30\n",
    "stride = 10\n",
    "\n",
    "# Read Data\n",
    "data_path = \"/home/wuwenjun/Data/AlphaNet_Original_Input/\"\n",
    "dataframe_list = pd.DataFrame()\n",
    "for f, _, i in walk(data_path):\n",
    "    for j in tqdm(i):\n",
    "        dataframe_list = pd.concat([dataframe_list, pd.read_parquet(f + j)], axis=0)\n",
    "dataframe_list['timestamp'] = pd.to_datetime(dataframe_list['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d194768b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:16:37.329353Z",
     "start_time": "2021-12-09T07:11:46.804447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainx.shape:  (459371, 1, 11, 30)\n",
      "trainy.shape:  (459371, 1)\n",
      "testx.shape:  (451184, 1, 11, 30)\n",
      "testy.shape:  (451184, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Extraction------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:26<00:00, 28.72s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_cov4d----output shape:  torch.Size([459371, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:52<00:00, 17.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_corr4d----output shape:  torch.Size([459371, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_stddev4d----output shape:  torch.Size([459371, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_zscore----output shape:  torch.Size([459371, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 41.35it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_return----output shape:  torch.Size([459371, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_decaylinear----output shape:  torch.Size([459371, 11, 3])\n",
      "Convolutional shape:  torch.Size([459371, 1, 154, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Pooling------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling shape:  torch.Size([459371, 462])\n",
      "trainx.shape :  (459371, 462)\n",
      "trainy.shape :  (459371, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Extraction------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:47<00:00, 15.83s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_cov4d----output shape:  torch.Size([451184, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:47<00:00, 15.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_corr4d----output shape:  torch.Size([451184, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_stddev4d----output shape:  torch.Size([451184, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_zscore----output shape:  torch.Size([451184, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 59.28it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_return----output shape:  torch.Size([451184, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_decaylinear----output shape:  torch.Size([451184, 11, 3])\n",
      "Convolutional shape:  torch.Size([451184, 1, 154, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Pooling------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling shape:  torch.Size([451184, 462])\n",
      "testx.shape :  (451184, 462)\n",
      "testy.shape :  (451184, 1)\n",
      "trainx size:  torch.Size([459371, 462])\n",
      "trainy size:  torch.Size([459371, 1])\n",
      "testx size:  torch.Size([451184, 462])\n",
      "testy size:  torch.Size([451184, 1])\n"
     ]
    }
   ],
   "source": [
    "time_start = 20210101\n",
    "time_end = 20210630\n",
    "trainx, trainy, feat_num = get_train_data(time_start, time_end)\n",
    "testx, testy, test_target = get_test_data(time_start, time_end)\n",
    "del dataframe_list\n",
    "\"\"\"Convolutional \"\"\"\n",
    "convolutional = Convolutional(trainx, 10)\n",
    "feat_cat = convolutional.extracted_data\n",
    "pooling = Pooling(feat_cat, 3)\n",
    "trainx = pooling.extracted_data.detach().numpy()\n",
    "print(\"trainx.shape : \", trainx.shape)\n",
    "print(\"trainy.shape : \", trainy.shape)\n",
    "\n",
    "convolutional = Convolutional(testx, 10)\n",
    "feat_cat = convolutional.extracted_data\n",
    "pooling = Pooling(feat_cat, 3)\n",
    "testx = pooling.extracted_data.detach().numpy()\n",
    "print(\"testx.shape : \", testx.shape)\n",
    "print(\"testy.shape : \", testy.shape)\n",
    "\n",
    "trainx, trainy, testx, testy = torch.from_numpy(trainx), torch.from_numpy(trainy), torch.from_numpy(\n",
    "    testx), torch.from_numpy(testy)\n",
    "print('trainx size: ', trainx.size())\n",
    "print('trainy size: ', trainy.size())\n",
    "print('testx size: ', testx.size())\n",
    "print('testy size: ', testy.size())\n",
    "torch.save(trainx, output_path + \"/trainx/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "torch.save(trainy, output_path + \"/trainy/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "torch.save(testx, output_path + \"/testx/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "torch.save(testy, output_path + \"/testy/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "test_target.set_index([\"timestamp\",\"ticker\"]).to_csv(output_path + \"/test_target/\" + '%s_%s.csv' % (time_start, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b582c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T04:55:17.921432Z",
     "start_time": "2021-12-09T04:55:13.000115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainx size:  torch.Size([2961314, 462])\n",
      "trainy size:  torch.Size([2961314, 1])\n",
      "testx size:  torch.Size([436426, 462])\n",
      "testy size:  torch.Size([436426, 1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ticker</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.013562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-02 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.018012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-03 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.040197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-04 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-05 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436421</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>688188</td>\n",
       "      <td>-0.035886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436422</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>2960</td>\n",
       "      <td>0.012141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436423</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>603115</td>\n",
       "      <td>0.031416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436424</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>688321</td>\n",
       "      <td>0.018588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436425</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>300787</td>\n",
       "      <td>-0.142691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436426 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  ticker    target\n",
       "0       2019-07-01 09:30:00       1 -0.013562\n",
       "1       2019-07-02 09:30:00       1 -0.018012\n",
       "2       2019-07-03 09:30:00       1 -0.040197\n",
       "3       2019-07-04 09:30:00       1 -0.023555\n",
       "4       2019-07-05 09:30:00       1 -0.025090\n",
       "...                     ...     ...       ...\n",
       "436421  2019-12-31 09:30:00  688188 -0.035886\n",
       "436422  2019-12-31 09:30:00    2960  0.012141\n",
       "436423  2019-12-31 09:30:00  603115  0.031416\n",
       "436424  2019-12-31 09:30:00  688321  0.018588\n",
       "436425  2019-12-31 09:30:00  300787 -0.142691\n",
       "\n",
       "[436426 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/trainx/20190630_20200101.pt\")\n",
    "trainy = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/trainy/20190630_20200101.pt\")\n",
    "testx = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/testx/20190630_20200101.pt\")\n",
    "testy = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/testy/20190630_20200101.pt\")\n",
    "test_target = pd.read_csv(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/test_target/20190630_20200101.csv\")\n",
    "print('trainx size: ', trainx.size())\n",
    "print('trainy size: ', trainy.size())\n",
    "print('testx size: ', testx.size())\n",
    "print('testy size: ', testy.size())\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "210a8769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:32:13.260476Z",
     "start_time": "2021-12-09T07:32:12.506093Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainx = trainx.cuda()\n",
    "trainy = trainy.cuda()\n",
    "testx = testx.cuda()\n",
    "testy = testy.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2b2a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:29:37.122164Z",
     "start_time": "2021-12-09T07:29:37.117457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([459371, 462])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac643691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:33:29.134601Z",
     "start_time": "2021-12-09T07:33:29.003997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet(\n",
      "  (fc1): Linear(in_features=462, out_features=30, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (out): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5d55b6109233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "train_dataset = Data.TensorDataset(trainx, trainy)\n",
    "test_dataset = Data.TensorDataset(testx, testy)\n",
    "batch_size = 512\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "alphanet = AlphaNet(feat_num, 30)\n",
    "alphanet = alphanet.cuda()\n",
    "# alphanet = torch.nn.parallel.DataParallel(alphanet)\n",
    "print(alphanet)\n",
    "total_length = trainx.shape[0]\n",
    "LR = 0.0001\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(alphanet.parameters(), lr=LR, alpha=0.9)\n",
    "epoch_num = 20\n",
    "\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    total_loss = 0\n",
    "    for _, (data, label) in enumerate(train_loader):\n",
    "        data = Variable(data).float()\n",
    "        label = Variable(label).float()\n",
    "        pred = alphanet(data)\n",
    "        print(pred.size())\n",
    "        print(\"epoch：\", epoch, \"的第\" \"个inputs\", data.data.size(), \"labels\", label.data.size())\n",
    "        #         label = label.unsqueeze(1)\n",
    "#         loss = loss_function(pred, label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss += loss.item()\n",
    "#     total_loss = total_loss * batch_size / total_length\n",
    "#     print('Epoch: ', epoch + 1, ' loss: ', total_loss)\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "for _, (data, label) in enumerate(test_loader):\n",
    "    data = Variable(data).float()\n",
    "    pred = alphanet(data)\n",
    "    pred_list.extend(pred.tolist())\n",
    "    label_list.extend(label.tolist())\n",
    "\n",
    "final = pd.concat([test_target, pd.DataFrame(pred_list)], axis=1)\n",
    "alpha_name = 'AlphaNetV1_Original_Input_1208'\n",
    "final.rename(columns={0: alpha_name, 'ticker': 'symbol'}, inplace=True)\n",
    "final = final.reindex(columns=['symbol', 'timestamp', alpha_name,'target'])\n",
    "final.set_index(['symbol', 'timestamp']).to_csv(output_path + \"result/\"+'%s_%s.csv' % (time_start, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb458d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:39:24.989733Z",
     "start_time": "2021-12-09T06:39:24.985112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
