{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6c7e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:10:25.392705Z",
     "start_time": "2021-12-09T07:10:24.173320Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from progressbar import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414ca857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:11:46.802092Z",
     "start_time": "2021-12-09T07:10:25.395682Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:21<00:00, 10.16s/it]\n"
     ]
    }
   ],
   "source": [
    "class Convolutional(object):\n",
    "    def __init__(self, data, stride):\n",
    "        if len(data.shape) != 4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        self.data = np.array(data)\n",
    "        self.stride = stride\n",
    "        self.data_length = data.shape[3]\n",
    "        self.feat_num = data.shape[2]  # 9\n",
    "        self.num, self.num_rev = self.generate_Num_and_ReversedNum(self.feat_num)\n",
    "        self.conv_feat = len(self.num)\n",
    "        self.step_list = self.generate_Step_List(self.data_length, self.stride)\n",
    "        self.extracted_data = self.Extraction(self.data, self.feat_num, self.conv_feat, self.stride)\n",
    "\n",
    "    def Extraction(self, data, feat_num, conv_feat, stride):\n",
    "        print(\"------Start Extraction------\")\n",
    "        batch = nn.BatchNorm1d(conv_feat, affine=True)\n",
    "        batch2 = nn.BatchNorm1d(feat_num, affine=True)\n",
    "        conv1 = self.ts_cov4d(self.data, self.stride, self.num, self.num_rev, self.step_list)\n",
    "        conv2 = self.ts_corr4d(self.data, self.stride, self.num, self.num_rev, self.step_list, conv1)\n",
    "        conv2 = torch.tanh(conv2)\n",
    "        bc1 = batch(conv1.to(torch.float))\n",
    "        bc2 = batch(conv2.to(torch.float))\n",
    "        conv3 = self.ts_stddev4d(self.data, self.stride, self.feat_num, self.step_list).to(torch.float)\n",
    "        bc3 = batch2(conv3)\n",
    "        conv4 = self.ts_zscore(self.data, self.stride, self.feat_num, self.step_list).to(torch.float)\n",
    "        bc4 = batch2(conv4)\n",
    "        conv5 = self.ts_return(self.data, self.stride, self.feat_num, self.step_list).to(torch.float)\n",
    "        bc5 = batch2(conv5)\n",
    "        conv6 = self.ts_decaylinear(self.data, self.stride, self.feat_num, self.step_list).to(torch.float)\n",
    "        bc6 = batch2(conv6)\n",
    "\n",
    "        feat_cat = torch.cat([bc1, bc2, bc3, bc4, bc5, bc6], axis=1)  # ì??÷??o?\n",
    "        shape = feat_cat.shape\n",
    "        feat_cat = feat_cat.reshape(shape[0], 1, shape[1], shape[2])\n",
    "        print(\"Convolutional shape: \", feat_cat.shape)\n",
    "        return feat_cat\n",
    "\n",
    "    def generateC(self, l1):\n",
    "        if len(l1) == 1:\n",
    "            return []\n",
    "        v = [[l1[0], i] for i in l1[1:]]\n",
    "        l1 = l1[1:]\n",
    "        return v + self.generateC(l1)\n",
    "\n",
    "    def generate_Num_and_ReversedNum(self, feat_nums):\n",
    "        list1 = list(range(feat_nums))\n",
    "        num = self.generateC(list1)\n",
    "        num_rev = []\n",
    "        for l in num:\n",
    "            l1 = l.copy()\n",
    "            l1.reverse()\n",
    "            num_rev.append(l1)\n",
    "        return num, num_rev\n",
    "\n",
    "    def generate_Step_List(self, data_length, stride):\n",
    "        # 11?¨2?3¤áD±í￡?è?1?êy?Y3¤?è2??ü??3y￡??òè?ê￡??3¤?è￡?è?1?ê￡??3¤?èD?óú5￡??òó?é?ò?2??áo?ò??e\n",
    "        if data_length % stride == 0:\n",
    "            step_list = list(range(0, data_length + stride, stride))\n",
    "        elif data_length % stride <= 5:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0, data_length - stride, stride)) + [data_length]\n",
    "        else:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0, data_length + stride - mod, stride)) + [data_length]\n",
    "        return step_list\n",
    "\n",
    "    \"\"\" Main Extraction\"\"\"\n",
    "\n",
    "    def ts_cov4d(self, data, stride, num, num_rev, step_list):\n",
    "        '''????4??êy?Yμ?D-·?2?'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        l = []\n",
    "        # ????μ?1y3ì?D??±?±￡3?keepdims=True\n",
    "        for i in tqdm(range(len(step_list) - 1)):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i + 1]\n",
    "            sub_data1 = data[:, :, num, start:end]  # (2000, 1, 36, 2, 10)\n",
    "            sub_data2 = data[:, :, num_rev, start:end]\n",
    "            mean1 = sub_data1.mean(axis=4, keepdims=True)  # (2000, 1, 36, 2, 1)\n",
    "            mean2 = sub_data2.mean(axis=4, keepdims=True)\n",
    "            spread1 = sub_data1 - mean1  # (2000, 1, 36, 2, 10)\n",
    "            spread2 = sub_data2 - mean2\n",
    "            cov = ((spread1 * spread2).sum(axis=4, keepdims=True) / (sub_data1.shape[4] - 1)).mean(axis=3,\n",
    "                                                                                                   keepdims=True)  # (2000, 1, 36, 1, 1)\n",
    "            l.append(cov)\n",
    "        corr = np.squeeze(np.array(l)).transpose(1, 2, 0).reshape(-1, self.conv_feat,\n",
    "                                                                  len(step_list) - 1)  # (2000, 1, 36, 3)\n",
    "        final = torch.from_numpy(corr)\n",
    "        print(\"------Finished ts_cov4d----output shape: \", final.shape)\n",
    "        return final\n",
    "\n",
    "    def ts_corr4d(self, data, stride, num, num_rev, step_list, cov):\n",
    "        '''????4??êy?Yμ??à1??μêy'''\n",
    "        '''data:[N,C,H,W],,W:price length,N:batch size'''\n",
    "        l = []\n",
    "        for i in tqdm(range(len(step_list) - 1)):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i + 1]\n",
    "            sub_data1 = data[:, :, num, start:end]\n",
    "            sub_data2 = data[:, :, num_rev, start:end]\n",
    "            std1 = sub_data1.std(axis=4, keepdims=True)\n",
    "            std2 = sub_data2.std(axis=4, keepdims=True)\n",
    "            std = (std1 * std2).mean(axis=3, keepdims=True)\n",
    "            del std1, std2  # êí·??ú′?\n",
    "            l.append(std)\n",
    "        std = np.squeeze(np.array(l)).transpose(1, 2, 0).reshape(-1, self.conv_feat, len(step_list) - 1)\n",
    "        std[std == 0] = 1e-9\n",
    "        fct = (sub_data1.shape[4] - 1) / sub_data1.shape[4]\n",
    "        final = cov / torch.from_numpy(std) * fct\n",
    "        del fct, std\n",
    "        print(\"------Finished ts_corr4d----output shape: \", final.shape)\n",
    "        return final\n",
    "\n",
    "    def ts_stddev4d(self, data, stride, feat_num, step_list):\n",
    "        if len(data.shape) != 4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in tqdm(range(len(step_list) - 1)):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i + 1]\n",
    "            sub_data1 = data[:, :, :, start:end]\n",
    "            std1 = sub_data1.std(axis=3, keepdims=True)\n",
    "            l.append(std1)\n",
    "            del std1\n",
    "        std = np.squeeze(np.array(l)).transpose(1, 2, 0).reshape(-1, feat_num, len(step_list) - 1)\n",
    "        print(\"------Finished ts_stddev4d----output shape: \", torch.from_numpy(std).shape)\n",
    "        return torch.from_numpy(std)\n",
    "\n",
    "    def ts_zscore(self, data, stride, feat_num, step_list):\n",
    "        if len(data.shape) != 4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in tqdm(range(len(step_list) - 1)):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i + 1]\n",
    "            sub_data1 = data[:, :, :, start:end]\n",
    "            mean = sub_data1.mean(axis=3, keepdims=True)\n",
    "            std = sub_data1.std(axis=3, keepdims=True)\n",
    "            std[std == 0] = 1e-9\n",
    "            z_score = mean / std\n",
    "            l.append(z_score)\n",
    "        z_score = np.squeeze(np.array(l)).transpose(1, 2, 0).reshape(-1, feat_num, len(step_list) - 1)\n",
    "        #         z_score[z_score >= 6] = 6\n",
    "        print(\"------Finished ts_zscore----output shape: \", torch.from_numpy(z_score).shape)\n",
    "        return torch.from_numpy(z_score)\n",
    "\n",
    "    def ts_return(self, data, stride, feat_num, step_list):\n",
    "        if len(data.shape) != 4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        data[data == 0] = 1e-9\n",
    "        l = []\n",
    "        for i in tqdm(range(len(step_list) - 1)):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i + 1]\n",
    "            sub_data1 = data[:, :, :, start:end]\n",
    "            ret = sub_data1[:, :, :, -1] / sub_data1[:, :, :, 0] - 1\n",
    "            l.append(ret)\n",
    "        z_data = np.squeeze(np.array(l)).transpose(1, 2, 0).reshape(-1, feat_num, len(step_list) - 1)\n",
    "        z_data[z_data > 1] = 1\n",
    "        print(\"------Finished ts_return----output shape: \", torch.from_numpy(z_data).shape)\n",
    "        return torch.from_numpy(z_data)\n",
    "\n",
    "    def ts_decaylinear(self, data, stride, feat_num, step_list):\n",
    "        if len(data.shape) != 4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in tqdm(range(len(step_list) - 1)):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i + 1]\n",
    "            time_spread = end - start\n",
    "            weight = np.arange(1, time_spread + 1)\n",
    "            weight = weight / (weight.sum())\n",
    "            sub_data1 = (data[:, :, :, start:end] * weight).mean(axis=3, keepdims=True)\n",
    "            l.append(sub_data1)\n",
    "        decay_data = np.squeeze(np.array(l)).transpose(1, 2, 0).reshape(-1, feat_num, len(step_list) - 1)\n",
    "        final = torch.from_numpy(decay_data)\n",
    "        print(\"------Finished ts_decaylinear----output shape: \", final.shape)\n",
    "        return final\n",
    "\n",
    "\n",
    "class Pooling(object):\n",
    "    def __init__(self, data, stride):\n",
    "        if len(data.shape) != 4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        self.data = data.detach().numpy()\n",
    "        self.stride = stride\n",
    "        self.data_length = data.shape[3]\n",
    "        self.feat_num = data.shape[2]  # 9\n",
    "        self.step_list = self.generate_Step_List(self.data_length, self.stride)\n",
    "        self.extracted_data = self.Extraction(self.data, self.feat_num, self.stride)\n",
    "\n",
    "    def Extraction(self, data, feat_num, stride):\n",
    "        print(\"------Start Pooling------\")\n",
    "        # Pooling\n",
    "        ts_max = self.ts_pool(data, self.stride, self.feat_num, self.step_list, method='max')\n",
    "        ts_max = nn.BatchNorm1d(self.feat_num, affine=True)(ts_max)\n",
    "        ts_min = self.ts_pool(data, self.stride, self.feat_num, self.step_list, method='min')\n",
    "        ts_min = nn.BatchNorm1d(self.feat_num, affine=True)(ts_min)\n",
    "        ts_mean = self.ts_pool(data, self.stride, self.feat_num, self.step_list, method='mean')\n",
    "        ts_mean = nn.BatchNorm1d(self.feat_num, affine=True)(ts_mean)\n",
    "        data_pool = torch.cat([ts_max, ts_min, ts_mean], axis=1)\n",
    "        data_pool = data_pool.flatten(start_dim=1)\n",
    "        print(\"Pooling shape: \", data_pool.shape)\n",
    "        return data_pool\n",
    "\n",
    "    def generate_Step_List(self, data_length, stride):\n",
    "        if data_length % stride == 0:\n",
    "            step_list = list(range(0, data_length + stride, stride))\n",
    "        elif data_length % stride <= 5:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0, data_length - stride, stride)) + [data_length]\n",
    "        else:\n",
    "            mod = data_length % stride\n",
    "            step_list = list(range(0, data_length + stride - mod, stride)) + [data_length]\n",
    "        return step_list\n",
    "\n",
    "    def ts_pool(self, data, stride, feat_num, step_list, method):\n",
    "        if type(data) == torch.Tensor:\n",
    "            data = data.detach().numpy()\n",
    "        if data.shape[-1] <= stride:\n",
    "            step_list = [0, data.shape[-1]]\n",
    "        if len(data.shape) != 4:\n",
    "            raise Exception('Input data dimensions should be [N,C,H,W]')\n",
    "        l = []\n",
    "        for i in tqdm(range(len(step_list) - 1)):\n",
    "            start = step_list[i]\n",
    "            end = step_list[i + 1]\n",
    "            if method == 'max':\n",
    "                sub_data1 = data[:, :, :, start:end].max(axis=3, keepdims=True)\n",
    "            if method == 'min':\n",
    "                sub_data1 = data[:, :, :, start:end].min(axis=3, keepdims=True)\n",
    "            if method == 'mean':\n",
    "                sub_data1 = data[:, :, :, start:end].mean(axis=3, keepdims=True)\n",
    "            l.append(sub_data1)\n",
    "        try:\n",
    "            pool_data = np.squeeze(np.array(l)).transpose(1, 2, 0).reshape(-1, feat_num, len(step_list) - 1)\n",
    "        except:\n",
    "            pool_data = np.squeeze(np.array(l)).reshape(-1, feat_num, len(step_list) - 1)\n",
    "        return torch.from_numpy(pool_data)\n",
    "\n",
    "\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self, factor_num, fully_connect_layer_neural):\n",
    "        # super ??àà￡?μ÷ó???ààμ?11?ì￡??aò?2?±?D?óD\n",
    "        # μúò???2?êy?a?¨ò?ààμ???3?￡?μú?t???aself\n",
    "        super(AlphaNet, self).__init__()\n",
    "        self.fc1_neuron = (factor_num * (factor_num - 1) + 4 * factor_num) * 3\n",
    "        self.fc2_neuron = fully_connect_layer_neural\n",
    "        self.fc1 = torch.nn.Linear(self.fc1_neuron, self.fc2_neuron)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(self.fc2_neuron, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.out(x)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def get_train_data(time_start, time_end):\n",
    "#     train_frame = dataframe_list[dataframe_list['timestamp'] < pd.to_datetime(str(time_start))]\n",
    "    train_frame = dataframe_list[(dataframe_list['timestamp'] > pd.to_datetime(str(20200630)))\n",
    "                                & (dataframe_list['timestamp'] < pd.to_datetime(str(time_start)))]\n",
    "    train_frame.set_index([\"timestamp\", \"ticker\"], inplace=True)\n",
    "\n",
    "    # Train X and Train Y\n",
    "    trainx, trainy = [], []\n",
    "    trainx = np.array(train_frame.drop(\"target\", axis=1))\n",
    "    trainx = trainx.reshape(trainx.shape[0], 1, day, -1)  # x = (153,1,30,9)\n",
    "    trainx = trainx.transpose(0, 1, 3, 2)  # x = (2555577, 1, 9, 30)\n",
    "    trainy = np.array(train_frame['target']).reshape(-1, 1)  # x = (153,1,9,30)\n",
    "\n",
    "    feat_num = trainx.shape[2]  # 9\n",
    "    del train_frame\n",
    "    print(\"trainx.shape: \", trainx.shape)\n",
    "    print(\"trainy.shape: \", trainy.shape)\n",
    "    return trainx, trainy, feat_num\n",
    "\n",
    "\n",
    "def get_test_data(time_start, time_end):\n",
    "    test_frame = dataframe_list[(dataframe_list['timestamp'] > pd.to_datetime(str(time_start)))\n",
    "                                & (dataframe_list['timestamp'] < pd.to_datetime(str(time_end)))]\n",
    "    test_frame.set_index([\"timestamp\", \"ticker\"], inplace=True)\n",
    "\n",
    "    # Test X and Test Y\n",
    "\n",
    "    test_target = pd.DataFrame(test_frame['target'])\n",
    "    testy = np.array(test_target).reshape(-1, 1)\n",
    "\n",
    "    testx = np.array(test_frame.drop(\"target\", axis=1))\n",
    "    testx = testx.reshape(testx.shape[0], 1, day, -1)  # x = (153,1,30,9)\n",
    "    testx = testx.transpose(0, 1, 3, 2)  # x = (2555577, 1, 9, 30)\n",
    "    del test_frame\n",
    "\n",
    "    print(\"testx.shape: \", testx.shape)\n",
    "    print(\"testy.shape: \", testy.shape)\n",
    "    test_target.reset_index(inplace=True)\n",
    "    return testx, testy, test_target\n",
    "\n",
    "output_path = \"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/\"\n",
    "day = 30\n",
    "stride = 10\n",
    "\n",
    "# Read Data\n",
    "data_path = \"/home/wuwenjun/Data/AlphaNet_Original_Input/\"\n",
    "dataframe_list = pd.DataFrame()\n",
    "for f, _, i in walk(data_path):\n",
    "    for j in tqdm(i):\n",
    "        dataframe_list = pd.concat([dataframe_list, pd.read_parquet(f + j)], axis=0)\n",
    "dataframe_list['timestamp'] = pd.to_datetime(dataframe_list['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d194768b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:16:37.329353Z",
     "start_time": "2021-12-09T07:11:46.804447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainx.shape:  (459371, 1, 11, 30)\n",
      "trainy.shape:  (459371, 1)\n",
      "testx.shape:  (451184, 1, 11, 30)\n",
      "testy.shape:  (451184, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Extraction------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:26<00:00, 28.72s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_cov4d----output shape:  torch.Size([459371, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:52<00:00, 17.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_corr4d----output shape:  torch.Size([459371, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_stddev4d----output shape:  torch.Size([459371, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_zscore----output shape:  torch.Size([459371, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 41.35it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_return----output shape:  torch.Size([459371, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_decaylinear----output shape:  torch.Size([459371, 11, 3])\n",
      "Convolutional shape:  torch.Size([459371, 1, 154, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Pooling------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling shape:  torch.Size([459371, 462])\n",
      "trainx.shape :  (459371, 462)\n",
      "trainy.shape :  (459371, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Extraction------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:47<00:00, 15.83s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_cov4d----output shape:  torch.Size([451184, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:47<00:00, 15.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_corr4d----output shape:  torch.Size([451184, 55, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_stddev4d----output shape:  torch.Size([451184, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_zscore----output shape:  torch.Size([451184, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 59.28it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_return----output shape:  torch.Size([451184, 11, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Finished ts_decaylinear----output shape:  torch.Size([451184, 11, 3])\n",
      "Convolutional shape:  torch.Size([451184, 1, 154, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Start Pooling------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling shape:  torch.Size([451184, 462])\n",
      "testx.shape :  (451184, 462)\n",
      "testy.shape :  (451184, 1)\n",
      "trainx size:  torch.Size([459371, 462])\n",
      "trainy size:  torch.Size([459371, 1])\n",
      "testx size:  torch.Size([451184, 462])\n",
      "testy size:  torch.Size([451184, 1])\n"
     ]
    }
   ],
   "source": [
    "time_start = 20210101\n",
    "time_end = 20210630\n",
    "trainx, trainy, feat_num = get_train_data(time_start, time_end)\n",
    "testx, testy, test_target = get_test_data(time_start, time_end)\n",
    "del dataframe_list\n",
    "\"\"\"Convolutional \"\"\"\n",
    "convolutional = Convolutional(trainx, 10)\n",
    "feat_cat = convolutional.extracted_data\n",
    "pooling = Pooling(feat_cat, 3)\n",
    "trainx = pooling.extracted_data.detach().numpy()\n",
    "print(\"trainx.shape : \", trainx.shape)\n",
    "print(\"trainy.shape : \", trainy.shape)\n",
    "\n",
    "convolutional = Convolutional(testx, 10)\n",
    "feat_cat = convolutional.extracted_data\n",
    "pooling = Pooling(feat_cat, 3)\n",
    "testx = pooling.extracted_data.detach().numpy()\n",
    "print(\"testx.shape : \", testx.shape)\n",
    "print(\"testy.shape : \", testy.shape)\n",
    "\n",
    "trainx, trainy, testx, testy = torch.from_numpy(trainx), torch.from_numpy(trainy), torch.from_numpy(\n",
    "    testx), torch.from_numpy(testy)\n",
    "print('trainx size: ', trainx.size())\n",
    "print('trainy size: ', trainy.size())\n",
    "print('testx size: ', testx.size())\n",
    "print('testy size: ', testy.size())\n",
    "torch.save(trainx, output_path + \"/trainx/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "torch.save(trainy, output_path + \"/trainy/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "torch.save(testx, output_path + \"/testx/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "torch.save(testy, output_path + \"/testy/\" + '%s_%s.pt' % (time_start, time_end))\n",
    "test_target.set_index([\"timestamp\",\"ticker\"]).to_csv(output_path + \"/test_target/\" + '%s_%s.csv' % (time_start, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b582c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T04:55:17.921432Z",
     "start_time": "2021-12-09T04:55:13.000115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainx size:  torch.Size([2961314, 462])\n",
      "trainy size:  torch.Size([2961314, 1])\n",
      "testx size:  torch.Size([436426, 462])\n",
      "testy size:  torch.Size([436426, 1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ticker</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.013562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-02 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.018012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-03 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.040197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-04 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-05 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436421</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>688188</td>\n",
       "      <td>-0.035886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436422</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>2960</td>\n",
       "      <td>0.012141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436423</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>603115</td>\n",
       "      <td>0.031416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436424</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>688321</td>\n",
       "      <td>0.018588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436425</th>\n",
       "      <td>2019-12-31 09:30:00</td>\n",
       "      <td>300787</td>\n",
       "      <td>-0.142691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436426 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  ticker    target\n",
       "0       2019-07-01 09:30:00       1 -0.013562\n",
       "1       2019-07-02 09:30:00       1 -0.018012\n",
       "2       2019-07-03 09:30:00       1 -0.040197\n",
       "3       2019-07-04 09:30:00       1 -0.023555\n",
       "4       2019-07-05 09:30:00       1 -0.025090\n",
       "...                     ...     ...       ...\n",
       "436421  2019-12-31 09:30:00  688188 -0.035886\n",
       "436422  2019-12-31 09:30:00    2960  0.012141\n",
       "436423  2019-12-31 09:30:00  603115  0.031416\n",
       "436424  2019-12-31 09:30:00  688321  0.018588\n",
       "436425  2019-12-31 09:30:00  300787 -0.142691\n",
       "\n",
       "[436426 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/trainx/20190630_20200101.pt\")\n",
    "trainy = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/trainy/20190630_20200101.pt\")\n",
    "testx = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/testx/20190630_20200101.pt\")\n",
    "testy = torch.load(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/testy/20190630_20200101.pt\")\n",
    "test_target = pd.read_csv(\"/home/wuwenjun/Alpha_Factor/AlphaNetV1_Original_Input_1208/test_target/20190630_20200101.csv\")\n",
    "print('trainx size: ', trainx.size())\n",
    "print('trainy size: ', trainy.size())\n",
    "print('testx size: ', testx.size())\n",
    "print('testy size: ', testy.size())\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "210a8769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:32:13.260476Z",
     "start_time": "2021-12-09T07:32:12.506093Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainx = trainx.cuda()\n",
    "trainy = trainy.cuda()\n",
    "testx = testx.cuda()\n",
    "testy = testy.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2b2a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:29:37.122164Z",
     "start_time": "2021-12-09T07:29:37.117457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([459371, 462])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac643691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T07:33:29.134601Z",
     "start_time": "2021-12-09T07:33:29.003997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaNet(\n",
      "  (fc1): Linear(in_features=462, out_features=30, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (out): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5d55b6109233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "train_dataset = Data.TensorDataset(trainx, trainy)\n",
    "test_dataset = Data.TensorDataset(testx, testy)\n",
    "batch_size = 512\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "alphanet = AlphaNet(feat_num, 30)\n",
    "alphanet = alphanet.cuda()\n",
    "# alphanet = torch.nn.parallel.DataParallel(alphanet)\n",
    "print(alphanet)\n",
    "total_length = trainx.shape[0]\n",
    "LR = 0.0001\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(alphanet.parameters(), lr=LR, alpha=0.9)\n",
    "epoch_num = 20\n",
    "\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    total_loss = 0\n",
    "    for _, (data, label) in enumerate(train_loader):\n",
    "        data = Variable(data).float()\n",
    "        label = Variable(label).float()\n",
    "        pred = alphanet(data)\n",
    "        print(pred.size())\n",
    "        print(\"epoch：\", epoch, \"的第\" \"个inputs\", data.data.size(), \"labels\", label.data.size())\n",
    "        #         label = label.unsqueeze(1)\n",
    "#         loss = loss_function(pred, label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss += loss.item()\n",
    "#     total_loss = total_loss * batch_size / total_length\n",
    "#     print('Epoch: ', epoch + 1, ' loss: ', total_loss)\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "for _, (data, label) in enumerate(test_loader):\n",
    "    data = Variable(data).float()\n",
    "    pred = alphanet(data)\n",
    "    pred_list.extend(pred.tolist())\n",
    "    label_list.extend(label.tolist())\n",
    "\n",
    "final = pd.concat([test_target, pd.DataFrame(pred_list)], axis=1)\n",
    "alpha_name = 'AlphaNetV1_Original_Input_1208'\n",
    "final.rename(columns={0: alpha_name, 'ticker': 'symbol'}, inplace=True)\n",
    "final = final.reindex(columns=['symbol', 'timestamp', alpha_name,'target'])\n",
    "final.set_index(['symbol', 'timestamp']).to_csv(output_path + \"result/\"+'%s_%s.csv' % (time_start, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb458d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:39:24.989733Z",
     "start_time": "2021-12-09T06:39:24.985112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
